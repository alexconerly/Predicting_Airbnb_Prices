{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythondata",
   "display_name": "PythonData",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# In this file, we pull in postgres data after the collinearity feature reduction adjustment and use Scikit-learn's random forest permutation feature importance method to reduce the features with weak predictive power.  Finally, we run the same Deep Neural Network tests as we did in the baseline tests again to see the new results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PostGres Download Duration: 1.8154549598693848 seconds\n"
     ]
    }
   ],
   "source": [
    "# Download raw data from postgres for stage 1 ETL\n",
    "\n",
    "conn_string = 'postgres://whnpmxwsiccrtg:53c453893549d2b1e6a4ff92e626a2a08ebcaff66678e50d33e3742f66e3e4f4@ec2-52-4-171-132.compute-1.amazonaws.com/d2ajro4cjr10lb'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "start_time = time.time()\n",
    "merge1 = pd.read_sql_query('select * from \"merged_no_cal\"',con=conn)\n",
    "print(\"PostGres Download Duration: {} seconds\".format(time.time() - start_time))\n",
    "conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the object type columns.\n",
    "objects = merge1.dtypes[merge1.dtypes == 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False, drop='if_binary')\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "objects = merge1.dtypes[merge1.dtypes == 'object'].index.tolist()\n",
    "encode_df = pd.DataFrame(enc.fit_transform(merge1[objects]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(objects)\n",
    "encode_df.head()\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "merge1 = merge1.merge(encode_df,left_index=True, right_index=True)\n",
    "merge1 = merge1.drop(columns=objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge1.loc[(merge1['host_listings_count']<101),'host_listings_count'] = 0\n",
    "# merge1.loc[(merge1['host_listings_count']>100),'host_listings_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = merge1[\"price\"].values\n",
    "X = merge1.drop(\"price\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "source": [
    "# Perform RFR to evaluate feature importance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances using rfpimp and RFR\n",
    "# import the regressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Instantiate the Decision Tree Regression model:\n",
    "random_forest_regression_model = RandomForestRegressor(n_estimators = 64, random_state = 78, max_depth=32) \n",
    "random_forest_regression_model.fit(X_train, y_train)\n",
    "\n",
    "X_columns = merge1.drop(columns ='price').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['host_is_superhost', 'host_listings_count', 'host_identity_verified',\n",
       "       'accommodates', 'bathrooms', 'bedrooms', 'security_deposit',\n",
       "       'cleaning_fee', 'guests_included', 'minimum_nights',\n",
       "       ...\n",
       "       'bed_type_Couch', 'bed_type_Futon', 'bed_type_Pull-out Sofa',\n",
       "       'bed_type_Real Bed', 'cancellation_policy_flexible',\n",
       "       'cancellation_policy_moderate', 'cancellation_policy_strict',\n",
       "       'cancellation_policy_strict_14_with_grace_period',\n",
       "       'cancellation_policy_super_strict_30',\n",
       "       'cancellation_policy_super_strict_60'],\n",
       "      dtype='object', length=255)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = merge1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/alexconerly/opt/anaconda3/envs/PythonData/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Measuring feature importance using permutation via rfpimp library\n",
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "\n",
    "# Need to declare new X_train that is df instead of arrays\n",
    "X_train_df = pd.DataFrame(X_train, columns=X_columns)\n",
    "y_train_df = pd.DataFrame(y_train, columns=['price'])\n",
    "def r2(random_forest_regression_model, X_train, y_train):\n",
    "    return r2_score(y_train_df, random_forest_regression_model.predict(X_train_df))\n",
    "\n",
    "perm_importances_rfpimp = permutation_importances(random_forest_regression_model, X_train_df, y_train_df, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 Importance\n",
       "Feature                                                    \n",
       "bathrooms                                          0.411502\n",
       "cleaning_fee                                       0.209221\n",
       "bedrooms                                           0.156889\n",
       "reviews_per_month                                  0.118686\n",
       "host_listings_count                                0.104551\n",
       "accommodates                                       0.082397\n",
       "neighbourhood_cleansed_District 19                 0.044240\n",
       "essentials                                         0.043518\n",
       "availability_365                                   0.041841\n",
       "security_deposit                                   0.041451\n",
       "number_of_reviews                                  0.038421\n",
       "days_host                                          0.034477\n",
       "cancellation_policy_strict_14_with_grace_period    0.018085\n",
       "availability_30                                    0.017035\n",
       "guests_included                                    0.017007\n",
       "maximum_nights                                     0.015571\n",
       "minimum_nights                                     0.013769\n",
       "review_scores_rating                               0.012291\n",
       "room_type_Entire home/apt                          0.012108\n",
       "Kitchen_Grouped                                    0.010341\n",
       "elevator                                           0.008025\n",
       "free_parking_on_premises                           0.007630\n",
       "free_street_parking                                0.006106\n",
       "neighbourhood_cleansed_District 18                 0.005976\n",
       "family/kid_friendly                                0.005829\n",
       "neighbourhood_cleansed_District 17                 0.005529\n",
       "hair_dryer                                         0.004275\n",
       "fire_extinguisher                                  0.004173\n",
       "lock_on_bedroom_door                               0.003819\n",
       "instant_bookable                                   0.003527\n",
       "cancellation_policy_super_strict_30                0.003258\n",
       "property_type_Loft                                 0.002904\n",
       "smoke_detector                                     0.002846\n",
       "internet                                           0.002726\n",
       "shampoo                                            0.002699\n",
       "long_term_stays_allowed                            0.002664\n",
       "cable_tv                                           0.002513\n",
       "extra_pillows_and_blankets                         0.002501\n",
       "safety_card                                        0.002482\n",
       "neighbourhood_cleansed_District 24                 0.002444\n",
       "host_identity_verified                             0.002392\n",
       "laptop_friendly_workspace                          0.002374\n",
       "host_is_superhost                                  0.002355\n",
       "cancellation_policy_flexible                       0.002256\n",
       "property_type_Townhouse                            0.002255\n",
       "first_aid_kit                                      0.002223\n",
       "suitable_for_events                                0.002218\n",
       "neighbourhood_cleansed_District 21                 0.002189\n",
       "iron                                               0.002183\n",
       "indoor_fireplace                                   0.002152\n",
       "neighbourhood_cleansed_District 6                  0.002112\n",
       "keypad                                             0.002026\n",
       "pool                                               0.001990\n",
       "private_entrance                                   0.001977\n",
       "hot_tub                                            0.001941\n",
       "bathtub                                            0.001915\n",
       "24-hour_check-in                                   0.001915\n",
       "property_type_Apartment                            0.001816\n",
       "property_type_House                                0.001785\n",
       "self_check-in                                      0.001773\n",
       "paid_parking_off_premises                          0.001731\n",
       "luggage_dropoff_allowed                            0.001726\n",
       "carbon_monoxide_detector                           0.001724\n",
       "hot_water                                          0.001717\n",
       "bed_linens                                         0.001592\n",
       "neighbourhood_cleansed_District 1                  0.001551\n",
       "cancellation_policy_moderate                       0.001547\n",
       "pets_allowed                                       0.001396\n",
       "bbq_grill                                          0.001318\n",
       "full_kitchen                                       0.001309\n",
       "smart_lock                                         0.001297\n",
       "gym                                                0.001257\n",
       "garden_or_backyard                                 0.001090\n",
       "patio_or_balcony                                   0.001036\n",
       "property_type_Condominium                          0.001031\n",
       "neighbourhood_cleansed_District 5                  0.001025\n",
       "hangers                                            0.000999\n",
       "babysitter_recommendations                         0.000865\n",
       "lockbox                                            0.000823\n",
       "high_chair                                         0.000808\n",
       "Laundry_Grouped                                    0.000724\n",
       "changing_table                                     0.000712\n",
       "breakfast                                          0.000705\n",
       "neighbourhood_cleansed_District 20                 0.000695\n",
       "waterfront                                         0.000679\n",
       "kitchen                                            0.000620\n",
       "host_greets_you                                    0.000615\n",
       "private_living_room                                0.000550\n",
       "pets_live_on_this_property                         0.000536\n",
       "property_type_Serviced apartment                   0.000529\n",
       "neighbourhood_cleansed_District 34                 0.000519\n",
       "heating                                            0.000498\n",
       "ethernet_connection                                0.000490\n",
       "doorman                                            0.000483\n",
       "wheelchair_accessible                              0.000476\n",
       "neighbourhood_cleansed_District 8                  0.000472\n",
       "crib                                               0.000462\n",
       "neighbourhood_cleansed_District 25                 0.000437\n",
       "pack_’n_play/travel_crib                           0.000428\n",
       "room-darkening_shades                              0.000417\n",
       "wide_hallway_clearance                             0.000416\n",
       "dogs                                               0.000416\n",
       "step-free_access                                   0.000409\n",
       "game_console                                       0.000396\n",
       "mobile_hoist                                       0.000385\n",
       "smoking_allowed                                    0.000382\n",
       "smart_tv                                           0.000380\n",
       "wifi                                               0.000375\n",
       "neighbourhood_cleansed_District 7                  0.000359\n",
       "cancellation_policy_super_strict_60                0.000350\n",
       "cleaning_before_checkout                           0.000347\n",
       "other                                              0.000330\n",
       "well-lit_path_to_entrance                          0.000311\n",
       "children’s_books_and_toys                          0.000306\n",
       "Bathroom_Grouped_Binary                            0.000274\n",
       "property_type_Guesthouse                           0.000273\n",
       "neighbourhood_cleansed_District 22                 0.000264\n",
       "toilet_paper                                       0.000257\n",
       "single_level_home                                  0.000255\n",
       "neighbourhood_cleansed_District 15                 0.000244\n",
       "stair_gates                                        0.000230\n",
       "neighbourhood_cleansed_District 3                  0.000225\n",
       "property_type_Bungalow                             0.000222\n",
       "memory_foam_mattress                               0.000220\n",
       "property_type_Bed and breakfast                    0.000203\n",
       "hot_water_kettle                                   0.000198\n",
       "neighbourhood_cleansed_District 2                  0.000197\n",
       "bedroom_comforts                                   0.000183\n",
       "en_suite_bathroom                                  0.000183\n",
       "buzzer/wireless_intercom                           0.000170\n",
       "tv                                                 0.000168\n",
       "accessible-height_toilet                           0.000156\n",
       "room_type_Shared room                              0.000154\n",
       "property_type_Resort                               0.000154\n",
       "neighbourhood_cleansed_District 13                 0.000153\n",
       "outlet_covers                                      0.000146\n",
       "body_soap                                          0.000130\n",
       "children’s_dinnerware                              0.000121\n",
       "flat_path_to_front_door                            0.000116\n",
       "cats                                               0.000104\n",
       "fireplace_guards                                   0.000095\n",
       "disabled_parking_spot                              0.000092\n",
       "pocket_wifi                                        0.000090\n",
       "property_type_Villa                                0.000087\n",
       "property_type_Guest suite                          0.000086\n",
       "neighbourhood_cleansed_District 10                 0.000083\n",
       "paid_parking_on_premises                           0.000076\n",
       "wide_doorway                                       0.000067\n",
       "netflix                                            0.000063\n",
       "printer                                            0.000060\n",
       "handheld_shower_head                               0.000058\n",
       "accessible-height_bed                              0.000058\n",
       "neighbourhood_cleansed_District 35                 0.000057\n",
       "wide_clearance_to_shower                           0.000052\n",
       "baby_bath                                          0.000051\n",
       "neighbourhood_cleansed_District 23                 0.000049\n",
       "neighbourhood_cleansed_District 11                 0.000048\n",
       "neighbourhood_cleansed_District 4                  0.000047\n",
       "wide_clearance_to_bed                              0.000045\n",
       "wide_entryway                                      0.000036\n",
       "neighbourhood_cleansed_District 33                 0.000035\n",
       "neighbourhood_cleansed_District 16                 0.000031\n",
       "window_guards                                      0.000026\n",
       "building_staff                                     0.000025\n",
       "_toilet                                            0.000025\n",
       "neighbourhood_cleansed_District 14                 0.000025\n",
       "bed_type_Real Bed                                  0.000025\n",
       "neighbourhood_cleansed_District 31                 0.000020\n",
       "ev_charger                                         0.000020\n",
       "neighbourhood_cleansed_District 27                 0.000016\n",
       "neighbourhood_cleansed_District 12                 0.000015\n",
       "air_purifier                                       0.000015\n",
       "lake_access                                        0.000015\n",
       "property_type_Camper/RV                            0.000014\n",
       "property_type_Cottage                              0.000012\n",
       "baby_monitor                                       0.000011\n",
       "firm_mattress                                      0.000011\n",
       "neighbourhood_cleansed_District 9                  0.000010\n",
       "air_conditioning                                   0.000010\n",
       "bed_type_Pull-out Sofa                             0.000008\n",
       "neighbourhood_cleansed_District 29                 0.000006\n",
       "ceiling_fan                                        0.000005\n",
       "neighbourhood_cleansed_District 30                 0.000005\n",
       "property_type_Cabin                                0.000004\n",
       "property_type_Tiny house                           0.000004\n",
       "shower_chair                                       0.000004\n",
       "neighbourhood_cleansed_District 28                 0.000003\n",
       "bed_type_Airbed                                    0.000003\n",
       "property_type_Hostel                               0.000003\n",
       "neighbourhood_cleansed_District 32                 0.000002\n",
       "property_type_Hotel                                0.000002\n",
       "bed_type_Futon                                     0.000002\n",
       "fixed_grab_bars_for_shower                         0.000002\n",
       "sound_system                                       0.000002\n",
       "espresso_machine                                   0.000002\n",
       "neighbourhood_cleansed_District 26                 0.000001\n",
       "bathtub_with_bath_chair                            0.000001\n",
       "outdoor_parking                                    0.000001\n",
       "breakfast_table                                    0.000001\n",
       "fixed_grab_bars_for_toilet                         0.000001\n",
       "property_type_Boutique hotel                       0.000001\n",
       "dvd_player                                         0.000001\n",
       "murphy_bed                                         0.000001\n",
       "kitchenette                                        0.000001\n",
       "roll-in_shower                                     0.000001\n",
       "property_type_Yurt                                 0.000001\n",
       "private_bathroom                                   0.000000\n",
       "central_air_conditioning                           0.000000\n",
       "gas_oven                                           0.000000\n",
       "mini_fridge                                        0.000000\n",
       "beachfront                                         0.000000\n",
       "other_pets                                         0.000000\n",
       "fire_pit                                           0.000000\n",
       "walk-in_shower                                     0.000000\n",
       "ground_floor_access                                0.000000\n",
       "ski-in/ski-out                                     0.000000\n",
       "convection_oven                                    0.000000\n",
       "sun_loungers                                       0.000000\n",
       "standing_valet                                     0.000000\n",
       "pool_with_pool_hoist                               0.000000\n",
       "property_type_Chalet                               0.000000\n",
       "property_type_Treehouse                            0.000000\n",
       "bed_type_Couch                                     0.000000\n",
       "cancellation_policy_strict                         0.000000\n",
       "jetted_tub                                         0.000000\n",
       "mudroom                                            0.000000\n",
       "high-resolution_computer_monitor                   0.000000\n",
       "beach_view                                         0.000000\n",
       "property_type_Aparthotel                           0.000000\n",
       "formal_dining_area                                 0.000000\n",
       "soaking_tub                                        0.000000\n",
       "wine_cooler                                        0.000000\n",
       "double_oven                                        0.000000\n",
       "steam_oven                                         0.000000\n",
       "terrace                                            0.000000\n",
       "alfresco_bathtub                                   0.000000\n",
       "day_bed                                            0.000000\n",
       "shared_pool                                        0.000000\n",
       "warming_drawer                                     0.000000\n",
       "property_type_Barn                                -0.000000\n",
       "balcony                                           -0.000000\n",
       "heated_floors                                     -0.000000\n",
       "rain_shower                                       -0.000000\n",
       "hammock                                           -0.000000\n",
       "amazon_echo                                       -0.000000\n",
       "property_type_Bus                                 -0.000000\n",
       "hbo_go                                            -0.000000\n",
       "property_type_Farm stay                           -0.000000\n",
       "property_type_Nature lodge                        -0.000000\n",
       "electric_profiling_bed                            -0.000000\n",
       "outdoor_seating                                   -0.000000\n",
       "table_corner_guards                               -0.000000\n",
       "property_type_Other                               -0.000000\n",
       "pillow-top_mattress                               -0.000001\n",
       "beach_essentials                                  -0.000002"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n    </tr>\n    <tr>\n      <th>Feature</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bathrooms</th>\n      <td>0.411502</td>\n    </tr>\n    <tr>\n      <th>cleaning_fee</th>\n      <td>0.209221</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>0.156889</td>\n    </tr>\n    <tr>\n      <th>reviews_per_month</th>\n      <td>0.118686</td>\n    </tr>\n    <tr>\n      <th>host_listings_count</th>\n      <td>0.104551</td>\n    </tr>\n    <tr>\n      <th>accommodates</th>\n      <td>0.082397</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 19</th>\n      <td>0.044240</td>\n    </tr>\n    <tr>\n      <th>essentials</th>\n      <td>0.043518</td>\n    </tr>\n    <tr>\n      <th>availability_365</th>\n      <td>0.041841</td>\n    </tr>\n    <tr>\n      <th>security_deposit</th>\n      <td>0.041451</td>\n    </tr>\n    <tr>\n      <th>number_of_reviews</th>\n      <td>0.038421</td>\n    </tr>\n    <tr>\n      <th>days_host</th>\n      <td>0.034477</td>\n    </tr>\n    <tr>\n      <th>cancellation_policy_strict_14_with_grace_period</th>\n      <td>0.018085</td>\n    </tr>\n    <tr>\n      <th>availability_30</th>\n      <td>0.017035</td>\n    </tr>\n    <tr>\n      <th>guests_included</th>\n      <td>0.017007</td>\n    </tr>\n    <tr>\n      <th>maximum_nights</th>\n      <td>0.015571</td>\n    </tr>\n    <tr>\n      <th>minimum_nights</th>\n      <td>0.013769</td>\n    </tr>\n    <tr>\n      <th>review_scores_rating</th>\n      <td>0.012291</td>\n    </tr>\n    <tr>\n      <th>room_type_Entire home/apt</th>\n      <td>0.012108</td>\n    </tr>\n    <tr>\n      <th>Kitchen_Grouped</th>\n      <td>0.010341</td>\n    </tr>\n    <tr>\n      <th>elevator</th>\n      <td>0.008025</td>\n    </tr>\n    <tr>\n      <th>free_parking_on_premises</th>\n      <td>0.007630</td>\n    </tr>\n    <tr>\n      <th>free_street_parking</th>\n      <td>0.006106</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 18</th>\n      <td>0.005976</td>\n    </tr>\n    <tr>\n      <th>family/kid_friendly</th>\n      <td>0.005829</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 17</th>\n      <td>0.005529</td>\n    </tr>\n    <tr>\n      <th>hair_dryer</th>\n      <td>0.004275</td>\n    </tr>\n    <tr>\n      <th>fire_extinguisher</th>\n      <td>0.004173</td>\n    </tr>\n    <tr>\n      <th>lock_on_bedroom_door</th>\n      <td>0.003819</td>\n    </tr>\n    <tr>\n      <th>instant_bookable</th>\n      <td>0.003527</td>\n    </tr>\n    <tr>\n      <th>cancellation_policy_super_strict_30</th>\n      <td>0.003258</td>\n    </tr>\n    <tr>\n      <th>property_type_Loft</th>\n      <td>0.002904</td>\n    </tr>\n    <tr>\n      <th>smoke_detector</th>\n      <td>0.002846</td>\n    </tr>\n    <tr>\n      <th>internet</th>\n      <td>0.002726</td>\n    </tr>\n    <tr>\n      <th>shampoo</th>\n      <td>0.002699</td>\n    </tr>\n    <tr>\n      <th>long_term_stays_allowed</th>\n      <td>0.002664</td>\n    </tr>\n    <tr>\n      <th>cable_tv</th>\n      <td>0.002513</td>\n    </tr>\n    <tr>\n      <th>extra_pillows_and_blankets</th>\n      <td>0.002501</td>\n    </tr>\n    <tr>\n      <th>safety_card</th>\n      <td>0.002482</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 24</th>\n      <td>0.002444</td>\n    </tr>\n    <tr>\n      <th>host_identity_verified</th>\n      <td>0.002392</td>\n    </tr>\n    <tr>\n      <th>laptop_friendly_workspace</th>\n      <td>0.002374</td>\n    </tr>\n    <tr>\n      <th>host_is_superhost</th>\n      <td>0.002355</td>\n    </tr>\n    <tr>\n      <th>cancellation_policy_flexible</th>\n      <td>0.002256</td>\n    </tr>\n    <tr>\n      <th>property_type_Townhouse</th>\n      <td>0.002255</td>\n    </tr>\n    <tr>\n      <th>first_aid_kit</th>\n      <td>0.002223</td>\n    </tr>\n    <tr>\n      <th>suitable_for_events</th>\n      <td>0.002218</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 21</th>\n      <td>0.002189</td>\n    </tr>\n    <tr>\n      <th>iron</th>\n      <td>0.002183</td>\n    </tr>\n    <tr>\n      <th>indoor_fireplace</th>\n      <td>0.002152</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 6</th>\n      <td>0.002112</td>\n    </tr>\n    <tr>\n      <th>keypad</th>\n      <td>0.002026</td>\n    </tr>\n    <tr>\n      <th>pool</th>\n      <td>0.001990</td>\n    </tr>\n    <tr>\n      <th>private_entrance</th>\n      <td>0.001977</td>\n    </tr>\n    <tr>\n      <th>hot_tub</th>\n      <td>0.001941</td>\n    </tr>\n    <tr>\n      <th>bathtub</th>\n      <td>0.001915</td>\n    </tr>\n    <tr>\n      <th>24-hour_check-in</th>\n      <td>0.001915</td>\n    </tr>\n    <tr>\n      <th>property_type_Apartment</th>\n      <td>0.001816</td>\n    </tr>\n    <tr>\n      <th>property_type_House</th>\n      <td>0.001785</td>\n    </tr>\n    <tr>\n      <th>self_check-in</th>\n      <td>0.001773</td>\n    </tr>\n    <tr>\n      <th>paid_parking_off_premises</th>\n      <td>0.001731</td>\n    </tr>\n    <tr>\n      <th>luggage_dropoff_allowed</th>\n      <td>0.001726</td>\n    </tr>\n    <tr>\n      <th>carbon_monoxide_detector</th>\n      <td>0.001724</td>\n    </tr>\n    <tr>\n      <th>hot_water</th>\n      <td>0.001717</td>\n    </tr>\n    <tr>\n      <th>bed_linens</th>\n      <td>0.001592</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 1</th>\n      <td>0.001551</td>\n    </tr>\n    <tr>\n      <th>cancellation_policy_moderate</th>\n      <td>0.001547</td>\n    </tr>\n    <tr>\n      <th>pets_allowed</th>\n      <td>0.001396</td>\n    </tr>\n    <tr>\n      <th>bbq_grill</th>\n      <td>0.001318</td>\n    </tr>\n    <tr>\n      <th>full_kitchen</th>\n      <td>0.001309</td>\n    </tr>\n    <tr>\n      <th>smart_lock</th>\n      <td>0.001297</td>\n    </tr>\n    <tr>\n      <th>gym</th>\n      <td>0.001257</td>\n    </tr>\n    <tr>\n      <th>garden_or_backyard</th>\n      <td>0.001090</td>\n    </tr>\n    <tr>\n      <th>patio_or_balcony</th>\n      <td>0.001036</td>\n    </tr>\n    <tr>\n      <th>property_type_Condominium</th>\n      <td>0.001031</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 5</th>\n      <td>0.001025</td>\n    </tr>\n    <tr>\n      <th>hangers</th>\n      <td>0.000999</td>\n    </tr>\n    <tr>\n      <th>babysitter_recommendations</th>\n      <td>0.000865</td>\n    </tr>\n    <tr>\n      <th>lockbox</th>\n      <td>0.000823</td>\n    </tr>\n    <tr>\n      <th>high_chair</th>\n      <td>0.000808</td>\n    </tr>\n    <tr>\n      <th>Laundry_Grouped</th>\n      <td>0.000724</td>\n    </tr>\n    <tr>\n      <th>changing_table</th>\n      <td>0.000712</td>\n    </tr>\n    <tr>\n      <th>breakfast</th>\n      <td>0.000705</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 20</th>\n      <td>0.000695</td>\n    </tr>\n    <tr>\n      <th>waterfront</th>\n      <td>0.000679</td>\n    </tr>\n    <tr>\n      <th>kitchen</th>\n      <td>0.000620</td>\n    </tr>\n    <tr>\n      <th>host_greets_you</th>\n      <td>0.000615</td>\n    </tr>\n    <tr>\n      <th>private_living_room</th>\n      <td>0.000550</td>\n    </tr>\n    <tr>\n      <th>pets_live_on_this_property</th>\n      <td>0.000536</td>\n    </tr>\n    <tr>\n      <th>property_type_Serviced apartment</th>\n      <td>0.000529</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 34</th>\n      <td>0.000519</td>\n    </tr>\n    <tr>\n      <th>heating</th>\n      <td>0.000498</td>\n    </tr>\n    <tr>\n      <th>ethernet_connection</th>\n      <td>0.000490</td>\n    </tr>\n    <tr>\n      <th>doorman</th>\n      <td>0.000483</td>\n    </tr>\n    <tr>\n      <th>wheelchair_accessible</th>\n      <td>0.000476</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 8</th>\n      <td>0.000472</td>\n    </tr>\n    <tr>\n      <th>crib</th>\n      <td>0.000462</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 25</th>\n      <td>0.000437</td>\n    </tr>\n    <tr>\n      <th>pack_’n_play/travel_crib</th>\n      <td>0.000428</td>\n    </tr>\n    <tr>\n      <th>room-darkening_shades</th>\n      <td>0.000417</td>\n    </tr>\n    <tr>\n      <th>wide_hallway_clearance</th>\n      <td>0.000416</td>\n    </tr>\n    <tr>\n      <th>dogs</th>\n      <td>0.000416</td>\n    </tr>\n    <tr>\n      <th>step-free_access</th>\n      <td>0.000409</td>\n    </tr>\n    <tr>\n      <th>game_console</th>\n      <td>0.000396</td>\n    </tr>\n    <tr>\n      <th>mobile_hoist</th>\n      <td>0.000385</td>\n    </tr>\n    <tr>\n      <th>smoking_allowed</th>\n      <td>0.000382</td>\n    </tr>\n    <tr>\n      <th>smart_tv</th>\n      <td>0.000380</td>\n    </tr>\n    <tr>\n      <th>wifi</th>\n      <td>0.000375</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 7</th>\n      <td>0.000359</td>\n    </tr>\n    <tr>\n      <th>cancellation_policy_super_strict_60</th>\n      <td>0.000350</td>\n    </tr>\n    <tr>\n      <th>cleaning_before_checkout</th>\n      <td>0.000347</td>\n    </tr>\n    <tr>\n      <th>other</th>\n      <td>0.000330</td>\n    </tr>\n    <tr>\n      <th>well-lit_path_to_entrance</th>\n      <td>0.000311</td>\n    </tr>\n    <tr>\n      <th>children’s_books_and_toys</th>\n      <td>0.000306</td>\n    </tr>\n    <tr>\n      <th>Bathroom_Grouped_Binary</th>\n      <td>0.000274</td>\n    </tr>\n    <tr>\n      <th>property_type_Guesthouse</th>\n      <td>0.000273</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 22</th>\n      <td>0.000264</td>\n    </tr>\n    <tr>\n      <th>toilet_paper</th>\n      <td>0.000257</td>\n    </tr>\n    <tr>\n      <th>single_level_home</th>\n      <td>0.000255</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 15</th>\n      <td>0.000244</td>\n    </tr>\n    <tr>\n      <th>stair_gates</th>\n      <td>0.000230</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 3</th>\n      <td>0.000225</td>\n    </tr>\n    <tr>\n      <th>property_type_Bungalow</th>\n      <td>0.000222</td>\n    </tr>\n    <tr>\n      <th>memory_foam_mattress</th>\n      <td>0.000220</td>\n    </tr>\n    <tr>\n      <th>property_type_Bed and breakfast</th>\n      <td>0.000203</td>\n    </tr>\n    <tr>\n      <th>hot_water_kettle</th>\n      <td>0.000198</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 2</th>\n      <td>0.000197</td>\n    </tr>\n    <tr>\n      <th>bedroom_comforts</th>\n      <td>0.000183</td>\n    </tr>\n    <tr>\n      <th>en_suite_bathroom</th>\n      <td>0.000183</td>\n    </tr>\n    <tr>\n      <th>buzzer/wireless_intercom</th>\n      <td>0.000170</td>\n    </tr>\n    <tr>\n      <th>tv</th>\n      <td>0.000168</td>\n    </tr>\n    <tr>\n      <th>accessible-height_toilet</th>\n      <td>0.000156</td>\n    </tr>\n    <tr>\n      <th>room_type_Shared room</th>\n      <td>0.000154</td>\n    </tr>\n    <tr>\n      <th>property_type_Resort</th>\n      <td>0.000154</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 13</th>\n      <td>0.000153</td>\n    </tr>\n    <tr>\n      <th>outlet_covers</th>\n      <td>0.000146</td>\n    </tr>\n    <tr>\n      <th>body_soap</th>\n      <td>0.000130</td>\n    </tr>\n    <tr>\n      <th>children’s_dinnerware</th>\n      <td>0.000121</td>\n    </tr>\n    <tr>\n      <th>flat_path_to_front_door</th>\n      <td>0.000116</td>\n    </tr>\n    <tr>\n      <th>cats</th>\n      <td>0.000104</td>\n    </tr>\n    <tr>\n      <th>fireplace_guards</th>\n      <td>0.000095</td>\n    </tr>\n    <tr>\n      <th>disabled_parking_spot</th>\n      <td>0.000092</td>\n    </tr>\n    <tr>\n      <th>pocket_wifi</th>\n      <td>0.000090</td>\n    </tr>\n    <tr>\n      <th>property_type_Villa</th>\n      <td>0.000087</td>\n    </tr>\n    <tr>\n      <th>property_type_Guest suite</th>\n      <td>0.000086</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 10</th>\n      <td>0.000083</td>\n    </tr>\n    <tr>\n      <th>paid_parking_on_premises</th>\n      <td>0.000076</td>\n    </tr>\n    <tr>\n      <th>wide_doorway</th>\n      <td>0.000067</td>\n    </tr>\n    <tr>\n      <th>netflix</th>\n      <td>0.000063</td>\n    </tr>\n    <tr>\n      <th>printer</th>\n      <td>0.000060</td>\n    </tr>\n    <tr>\n      <th>handheld_shower_head</th>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>accessible-height_bed</th>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 35</th>\n      <td>0.000057</td>\n    </tr>\n    <tr>\n      <th>wide_clearance_to_shower</th>\n      <td>0.000052</td>\n    </tr>\n    <tr>\n      <th>baby_bath</th>\n      <td>0.000051</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 23</th>\n      <td>0.000049</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 11</th>\n      <td>0.000048</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 4</th>\n      <td>0.000047</td>\n    </tr>\n    <tr>\n      <th>wide_clearance_to_bed</th>\n      <td>0.000045</td>\n    </tr>\n    <tr>\n      <th>wide_entryway</th>\n      <td>0.000036</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 33</th>\n      <td>0.000035</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 16</th>\n      <td>0.000031</td>\n    </tr>\n    <tr>\n      <th>window_guards</th>\n      <td>0.000026</td>\n    </tr>\n    <tr>\n      <th>building_staff</th>\n      <td>0.000025</td>\n    </tr>\n    <tr>\n      <th>_toilet</th>\n      <td>0.000025</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 14</th>\n      <td>0.000025</td>\n    </tr>\n    <tr>\n      <th>bed_type_Real Bed</th>\n      <td>0.000025</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 31</th>\n      <td>0.000020</td>\n    </tr>\n    <tr>\n      <th>ev_charger</th>\n      <td>0.000020</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 27</th>\n      <td>0.000016</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 12</th>\n      <td>0.000015</td>\n    </tr>\n    <tr>\n      <th>air_purifier</th>\n      <td>0.000015</td>\n    </tr>\n    <tr>\n      <th>lake_access</th>\n      <td>0.000015</td>\n    </tr>\n    <tr>\n      <th>property_type_Camper/RV</th>\n      <td>0.000014</td>\n    </tr>\n    <tr>\n      <th>property_type_Cottage</th>\n      <td>0.000012</td>\n    </tr>\n    <tr>\n      <th>baby_monitor</th>\n      <td>0.000011</td>\n    </tr>\n    <tr>\n      <th>firm_mattress</th>\n      <td>0.000011</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 9</th>\n      <td>0.000010</td>\n    </tr>\n    <tr>\n      <th>air_conditioning</th>\n      <td>0.000010</td>\n    </tr>\n    <tr>\n      <th>bed_type_Pull-out Sofa</th>\n      <td>0.000008</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 29</th>\n      <td>0.000006</td>\n    </tr>\n    <tr>\n      <th>ceiling_fan</th>\n      <td>0.000005</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 30</th>\n      <td>0.000005</td>\n    </tr>\n    <tr>\n      <th>property_type_Cabin</th>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>property_type_Tiny house</th>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>shower_chair</th>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 28</th>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>bed_type_Airbed</th>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>property_type_Hostel</th>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 32</th>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>property_type_Hotel</th>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>bed_type_Futon</th>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>fixed_grab_bars_for_shower</th>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>sound_system</th>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>espresso_machine</th>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 26</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>bathtub_with_bath_chair</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>outdoor_parking</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>breakfast_table</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>fixed_grab_bars_for_toilet</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>property_type_Boutique hotel</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>dvd_player</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>murphy_bed</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>kitchenette</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>roll-in_shower</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>property_type_Yurt</th>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>private_bathroom</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>central_air_conditioning</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>gas_oven</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>mini_fridge</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>beachfront</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>other_pets</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>fire_pit</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>walk-in_shower</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>ground_floor_access</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>ski-in/ski-out</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>convection_oven</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>sun_loungers</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>standing_valet</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>pool_with_pool_hoist</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>property_type_Chalet</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>property_type_Treehouse</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>bed_type_Couch</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>cancellation_policy_strict</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>jetted_tub</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>mudroom</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>high-resolution_computer_monitor</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>beach_view</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>property_type_Aparthotel</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>formal_dining_area</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>soaking_tub</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>wine_cooler</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>double_oven</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>steam_oven</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>terrace</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>alfresco_bathtub</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>day_bed</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>shared_pool</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>warming_drawer</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>property_type_Barn</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>balcony</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>heated_floors</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>rain_shower</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>hammock</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>amazon_echo</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>property_type_Bus</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>hbo_go</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>property_type_Farm stay</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>property_type_Nature lodge</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>electric_profiling_bed</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>outdoor_seating</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>table_corner_guards</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>property_type_Other</th>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>pillow-top_mattress</th>\n      <td>-0.000001</td>\n    </tr>\n    <tr>\n      <th>beach_essentials</th>\n      <td>-0.000002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "perm_importances_rfpimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = perm_importances_rfpimp[perm_importances_rfpimp['Importance'] < 0.01].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = merge1.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'price',\n",
       "       'security_deposit', 'cleaning_fee', 'guests_included', 'minimum_nights',\n",
       "       'maximum_nights', 'availability_30', 'availability_365',\n",
       "       'number_of_reviews', 'review_scores_rating', 'reviews_per_month',\n",
       "       'days_host', 'essentials', 'Kitchen_Grouped',\n",
       "       'neighbourhood_cleansed_District 19', 'room_type_Entire home/apt',\n",
       "       'cancellation_policy_strict_14_with_grace_period'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "merge2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = merge2[\"price\"].values\n",
    "X = merge2.drop(\"price\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "# Fit the RobustScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "# Test 1: Use one input layer and one hidden layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 80)                1680      \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                2430      \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 31        \n=================================================================\nTotal params: 4,141\nTrainable params: 4,141\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 1s 854us/step - loss: 193.8851 - mean_absolute_error: 193.8851\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 0s 845us/step - loss: 114.0955 - mean_absolute_error: 114.0955\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 0s 870us/step - loss: 88.3049 - mean_absolute_error: 88.3049\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 0s 863us/step - loss: 83.7347 - mean_absolute_error: 83.7347\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 0s 760us/step - loss: 81.0288 - mean_absolute_error: 81.0288\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 0s 767us/step - loss: 75.8649 - mean_absolute_error: 75.8649\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 0s 858us/step - loss: 74.4994 - mean_absolute_error: 74.4994\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 0s 830us/step - loss: 74.9909 - mean_absolute_error: 74.9909\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 0s 791us/step - loss: 73.2862 - mean_absolute_error: 73.2862\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 0s 781us/step - loss: 73.0401 - mean_absolute_error: 73.0401\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 0s 717us/step - loss: 68.6889 - mean_absolute_error: 68.6889\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 0s 762us/step - loss: 71.1849 - mean_absolute_error: 71.1849\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 0s 768us/step - loss: 70.0399 - mean_absolute_error: 70.0399\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 0s 748us/step - loss: 67.3308 - mean_absolute_error: 67.3308\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 0s 866us/step - loss: 68.0204 - mean_absolute_error: 68.0204\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 0s 811us/step - loss: 69.0122 - mean_absolute_error: 69.0122\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 0s 922us/step - loss: 68.8632 - mean_absolute_error: 68.8632\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 0s 973us/step - loss: 69.0090 - mean_absolute_error: 69.0090\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 70.3159 - mean_absolute_error: 70.3159\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 0s 916us/step - loss: 69.4676 - mean_absolute_error: 69.4676\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 0s 854us/step - loss: 68.2400 - mean_absolute_error: 68.2400\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 0s 766us/step - loss: 66.7305 - mean_absolute_error: 66.7305\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 0s 718us/step - loss: 68.4939 - mean_absolute_error: 68.4939\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 69.3521 - mean_absolute_error: 69.3521\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 0s 827us/step - loss: 68.0007 - mean_absolute_error: 68.0007\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 0s 776us/step - loss: 67.1460 - mean_absolute_error: 67.1460\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 0s 858us/step - loss: 64.7321 - mean_absolute_error: 64.7321\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 0s 815us/step - loss: 66.5420 - mean_absolute_error: 66.5420\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 0s 765us/step - loss: 69.6197 - mean_absolute_error: 69.6197\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 0s 748us/step - loss: 67.9916 - mean_absolute_error: 67.9916\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 0s 705us/step - loss: 67.4023 - mean_absolute_error: 67.4023\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 0s 702us/step - loss: 64.2034 - mean_absolute_error: 64.2034\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 0s 759us/step - loss: 67.3486 - mean_absolute_error: 67.3486\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.6706 - mean_absolute_error: 62.6706\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 0s 799us/step - loss: 68.7932 - mean_absolute_error: 68.7932\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 0s 770us/step - loss: 64.2830 - mean_absolute_error: 64.2830\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 0s 765us/step - loss: 66.0984 - mean_absolute_error: 66.0984\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 0s 728us/step - loss: 69.3104 - mean_absolute_error: 69.3104\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 0s 742us/step - loss: 64.1487 - mean_absolute_error: 64.1487\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 0s 760us/step - loss: 68.2491 - mean_absolute_error: 68.2491\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 0s 755us/step - loss: 64.2629 - mean_absolute_error: 64.2629\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 0s 741us/step - loss: 65.6026 - mean_absolute_error: 65.6026\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 0s 713us/step - loss: 64.5570 - mean_absolute_error: 64.5570\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 0s 752us/step - loss: 64.4504 - mean_absolute_error: 64.4504\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 0s 812us/step - loss: 64.3868 - mean_absolute_error: 64.3868\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 0s 703us/step - loss: 64.6110 - mean_absolute_error: 64.6110\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 0s 664us/step - loss: 62.2097 - mean_absolute_error: 62.2097\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 0s 689us/step - loss: 63.8594 - mean_absolute_error: 63.8594\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 64.7227 - mean_absolute_error: 64.7227\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 0s 784us/step - loss: 63.9943 - mean_absolute_error: 63.9943\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 0s 757us/step - loss: 66.0525 - mean_absolute_error: 66.0525\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 0s 800us/step - loss: 65.7984 - mean_absolute_error: 65.7984\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 0s 837us/step - loss: 66.0679 - mean_absolute_error: 66.0679\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 0s 885us/step - loss: 61.2050 - mean_absolute_error: 61.2050\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 0s 844us/step - loss: 65.5368 - mean_absolute_error: 65.5368\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 0s 810us/step - loss: 68.1830 - mean_absolute_error: 68.1830\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 0s 965us/step - loss: 65.2302 - mean_absolute_error: 65.2302\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 0s 772us/step - loss: 65.6057 - mean_absolute_error: 65.6057\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 0s 958us/step - loss: 61.7978 - mean_absolute_error: 61.7978\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 0s 816us/step - loss: 65.7441 - mean_absolute_error: 65.7441\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 0s 716us/step - loss: 65.2317 - mean_absolute_error: 65.2317\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 0s 980us/step - loss: 66.9470 - mean_absolute_error: 66.9470\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 0s 773us/step - loss: 61.7602 - mean_absolute_error: 61.7602\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 0s 770us/step - loss: 61.6197 - mean_absolute_error: 61.6197\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 64.3520 - mean_absolute_error: 64.3520\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 0s 781us/step - loss: 64.2439 - mean_absolute_error: 64.2439\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 0s 727us/step - loss: 64.6142 - mean_absolute_error: 64.6142\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 0s 742us/step - loss: 62.8654 - mean_absolute_error: 62.8654\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 0s 752us/step - loss: 62.9053 - mean_absolute_error: 62.9053\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 0s 799us/step - loss: 62.9006 - mean_absolute_error: 62.9006\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 0s 751us/step - loss: 61.9525 - mean_absolute_error: 61.9525\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 0s 719us/step - loss: 63.0690 - mean_absolute_error: 63.0690\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 0s 769us/step - loss: 62.9639 - mean_absolute_error: 62.9639\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 0s 798us/step - loss: 65.6062 - mean_absolute_error: 65.6062\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 0s 780us/step - loss: 63.1695 - mean_absolute_error: 63.1695\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 0s 782us/step - loss: 59.7070 - mean_absolute_error: 59.7070\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 0s 749us/step - loss: 63.9565 - mean_absolute_error: 63.9565\n",
      "Epoch 78/100\n",
      "116/116 [==============================] - 0s 766us/step - loss: 62.5219 - mean_absolute_error: 62.5219\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 0s 749us/step - loss: 60.1385 - mean_absolute_error: 60.1385\n",
      "Epoch 80/100\n",
      "116/116 [==============================] - 0s 751us/step - loss: 63.0104 - mean_absolute_error: 63.0104\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 0s 998us/step - loss: 64.8368 - mean_absolute_error: 64.8368\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 0s 729us/step - loss: 61.7134 - mean_absolute_error: 61.7134\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 0s 669us/step - loss: 58.2708 - mean_absolute_error: 58.2708\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 0s 680us/step - loss: 61.9276 - mean_absolute_error: 61.9276\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 0s 699us/step - loss: 62.4030 - mean_absolute_error: 62.4030\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 0s 739us/step - loss: 63.6554 - mean_absolute_error: 63.6554\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 0s 764us/step - loss: 62.0929 - mean_absolute_error: 62.0929\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 0s 753us/step - loss: 61.5363 - mean_absolute_error: 61.5363\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 0s 894us/step - loss: 61.8170 - mean_absolute_error: 61.8170\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 0s 758us/step - loss: 62.3203 - mean_absolute_error: 62.3203\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 0s 709us/step - loss: 59.4323 - mean_absolute_error: 59.4323\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 0s 727us/step - loss: 61.8977 - mean_absolute_error: 61.8977\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 0s 709us/step - loss: 63.1553 - mean_absolute_error: 63.1553\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 0s 849us/step - loss: 59.6635 - mean_absolute_error: 59.6635\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 0s 810us/step - loss: 62.1932 - mean_absolute_error: 62.1932\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 0s 729us/step - loss: 59.4612 - mean_absolute_error: 59.4612\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 0s 806us/step - loss: 60.1126 - mean_absolute_error: 60.1126\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 0s 835us/step - loss: 61.0223 - mean_absolute_error: 61.0223\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 0s 772us/step - loss: 62.1980 - mean_absolute_error: 62.1980\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 0s 734us/step - loss: 60.8705 - mean_absolute_error: 60.8705\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 68.6330 - mean_absolute_error: 68.6330\n",
      "Loss: 68.6330337524414, MAE: 68.6330337524414\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, MAE: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "# Test 2 Add more neurons to each layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 100)               2100      \n_________________________________________________________________\ndense_4 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 7,201\nTrainable params: 7,201\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 0s 811us/step - loss: 186.9073 - mean_absolute_error: 186.9073\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 796us/step - loss: 97.7574 - mean_absolute_error: 97.7574\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 909us/step - loss: 81.0450 - mean_absolute_error: 81.0450\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 853us/step - loss: 78.1047 - mean_absolute_error: 78.1047\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 870us/step - loss: 77.3695 - mean_absolute_error: 77.3695\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 858us/step - loss: 70.8982 - mean_absolute_error: 70.8982\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 867us/step - loss: 73.0048 - mean_absolute_error: 73.0048\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 909us/step - loss: 72.0775 - mean_absolute_error: 72.0775\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 803us/step - loss: 70.1653 - mean_absolute_error: 70.1653\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 849us/step - loss: 69.3137 - mean_absolute_error: 69.3137\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 848us/step - loss: 69.9761 - mean_absolute_error: 69.9761\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 842us/step - loss: 68.0577 - mean_absolute_error: 68.0577\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 988us/step - loss: 69.0172 - mean_absolute_error: 69.0172\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 857us/step - loss: 70.7141 - mean_absolute_error: 70.7141\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 805us/step - loss: 68.4095 - mean_absolute_error: 68.4095\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 885us/step - loss: 66.8817 - mean_absolute_error: 66.8817\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 802us/step - loss: 66.5118 - mean_absolute_error: 66.5118\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 806us/step - loss: 68.0511 - mean_absolute_error: 68.0511\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 762us/step - loss: 65.3123 - mean_absolute_error: 65.3123\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 794us/step - loss: 68.2101 - mean_absolute_error: 68.2101\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 849us/step - loss: 66.4518 - mean_absolute_error: 66.4518\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 904us/step - loss: 66.3121 - mean_absolute_error: 66.3121\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 985us/step - loss: 66.2697 - mean_absolute_error: 66.2697\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 795us/step - loss: 65.8714 - mean_absolute_error: 65.8714\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 823us/step - loss: 69.6513 - mean_absolute_error: 69.6513\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 811us/step - loss: 65.1022 - mean_absolute_error: 65.1022\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 787us/step - loss: 65.8082 - mean_absolute_error: 65.8082\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.3243 - mean_absolute_error: 67.3243\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 809us/step - loss: 67.5790 - mean_absolute_error: 67.5790\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 864us/step - loss: 65.3110 - mean_absolute_error: 65.3110\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 851us/step - loss: 63.7582 - mean_absolute_error: 63.7582\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 796us/step - loss: 66.2320 - mean_absolute_error: 66.2320\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 941us/step - loss: 67.2568 - mean_absolute_error: 67.2568\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 768us/step - loss: 63.4716 - mean_absolute_error: 63.4716\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 782us/step - loss: 65.2392 - mean_absolute_error: 65.2392\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 777us/step - loss: 64.6096 - mean_absolute_error: 64.6096\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 774us/step - loss: 64.9536 - mean_absolute_error: 64.9536\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 823us/step - loss: 62.6453 - mean_absolute_error: 62.6453\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 823us/step - loss: 67.2641 - mean_absolute_error: 67.2641\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 65.6294 - mean_absolute_error: 65.6294\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 811us/step - loss: 63.4551 - mean_absolute_error: 63.4551\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 791us/step - loss: 65.1965 - mean_absolute_error: 65.1965\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 988us/step - loss: 64.5290 - mean_absolute_error: 64.5290\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 872us/step - loss: 62.7549 - mean_absolute_error: 62.7549\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 786us/step - loss: 61.8332 - mean_absolute_error: 61.8332\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 761us/step - loss: 66.1446 - mean_absolute_error: 66.1446\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 760us/step - loss: 64.9537 - mean_absolute_error: 64.9537\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 825us/step - loss: 62.1898 - mean_absolute_error: 62.1898\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 839us/step - loss: 63.3098 - mean_absolute_error: 63.3098\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 817us/step - loss: 64.0910 - mean_absolute_error: 64.0910\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model2 = nn2.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 68.7910 - mean_absolute_error: 68.7910\n",
      "Loss: 68.79102325439453\n",
      "Mean Absolute Error: 68.79102325439453\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss2, model_accuracy2 = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss2}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy2}\")"
   ]
  },
  {
   "source": [
    "# Test 3:  Add an additional layer with 20 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 100)               2100      \n_________________________________________________________________\ndense_7 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_8 (Dense)              (None, 20)                1020      \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 21        \n=================================================================\nTotal params: 8,191\nTrainable params: 8,191\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 0s 846us/step - loss: 178.5340 - mean_absolute_error: 178.5340\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 879us/step - loss: 85.4905 - mean_absolute_error: 85.4905\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 855us/step - loss: 81.3677 - mean_absolute_error: 81.3677\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 962us/step - loss: 72.7265 - mean_absolute_error: 72.7265\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 854us/step - loss: 68.0118 - mean_absolute_error: 68.0118\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 841us/step - loss: 73.0456 - mean_absolute_error: 73.0456\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 68.0096 - mean_absolute_error: 68.0096\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 969us/step - loss: 68.0561 - mean_absolute_error: 68.0561\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 856us/step - loss: 68.3975 - mean_absolute_error: 68.3975\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 866us/step - loss: 68.1155 - mean_absolute_error: 68.1155\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 833us/step - loss: 65.9008 - mean_absolute_error: 65.9008\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 834us/step - loss: 68.7945 - mean_absolute_error: 68.7945\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 938us/step - loss: 69.3148 - mean_absolute_error: 69.3148\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 892us/step - loss: 68.1421 - mean_absolute_error: 68.1421\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 847us/step - loss: 66.0327 - mean_absolute_error: 66.0327\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.0932 - mean_absolute_error: 67.0932\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 807us/step - loss: 65.6779 - mean_absolute_error: 65.6779\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 791us/step - loss: 69.1136 - mean_absolute_error: 69.1136\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 813us/step - loss: 65.6060 - mean_absolute_error: 65.6060\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 936us/step - loss: 65.6003 - mean_absolute_error: 65.6003\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 855us/step - loss: 63.7299 - mean_absolute_error: 63.7299\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 837us/step - loss: 65.3039 - mean_absolute_error: 65.3039\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 887us/step - loss: 66.4669 - mean_absolute_error: 66.4669\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 842us/step - loss: 68.2275 - mean_absolute_error: 68.2275\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 850us/step - loss: 64.6578 - mean_absolute_error: 64.6578\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.8241 - mean_absolute_error: 62.8241\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 902us/step - loss: 62.4628 - mean_absolute_error: 62.4628\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 899us/step - loss: 70.2134 - mean_absolute_error: 70.2134\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 921us/step - loss: 62.3840 - mean_absolute_error: 62.3840\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 996us/step - loss: 65.1957 - mean_absolute_error: 65.1957\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 971us/step - loss: 62.9408 - mean_absolute_error: 62.9408\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 984us/step - loss: 64.5396 - mean_absolute_error: 64.5396\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 65.4567 - mean_absolute_error: 65.4567\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 60.8363 - mean_absolute_error: 60.8363\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 942us/step - loss: 63.1344 - mean_absolute_error: 63.1344\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 847us/step - loss: 61.3324 - mean_absolute_error: 61.3324\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 895us/step - loss: 63.7782 - mean_absolute_error: 63.7782\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 902us/step - loss: 64.3489 - mean_absolute_error: 64.3489\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 855us/step - loss: 63.3363 - mean_absolute_error: 63.3363\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 63.5944 - mean_absolute_error: 63.5944\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 832us/step - loss: 59.5892 - mean_absolute_error: 59.5892\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 819us/step - loss: 61.5426 - mean_absolute_error: 61.5426\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 818us/step - loss: 62.4915 - mean_absolute_error: 62.4915\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 60.6800 - mean_absolute_error: 60.6800\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 869us/step - loss: 60.3350 - mean_absolute_error: 60.3350\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 827us/step - loss: 63.8552 - mean_absolute_error: 63.8552\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 845us/step - loss: 59.4410 - mean_absolute_error: 59.4410\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 816us/step - loss: 60.0065 - mean_absolute_error: 60.0065\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 816us/step - loss: 59.9670 - mean_absolute_error: 59.9670\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 824us/step - loss: 59.8758 - mean_absolute_error: 59.8758\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn3.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model3 = nn3.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 68.4053 - mean_absolute_error: 68.4053\n",
      "Loss: 68.4052505493164\n",
      "Mean Absolute Error: 68.4052505493164\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss3, model_accuracy3 = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss3}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy3}\")"
   ]
  },
  {
   "source": [
    "# Test 4:  Add 50 neurons to the first layer and a 4th layer with 10 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 150\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn4.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 1s 1ms/step - loss: 191.5968 - mean_absolute_error: 191.5968\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 935us/step - loss: 93.6373 - mean_absolute_error: 93.6373\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 79.1668 - mean_absolute_error: 79.1668\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 74.0763 - mean_absolute_error: 74.0763\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 986us/step - loss: 70.8174 - mean_absolute_error: 70.8174\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 72.1354 - mean_absolute_error: 72.1354\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 952us/step - loss: 67.4896 - mean_absolute_error: 67.4896\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 905us/step - loss: 71.8846 - mean_absolute_error: 71.8846\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 888us/step - loss: 66.6467 - mean_absolute_error: 66.6467\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 860us/step - loss: 68.3053 - mean_absolute_error: 68.3053\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 853us/step - loss: 69.0740 - mean_absolute_error: 69.0740\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 912us/step - loss: 67.7459 - mean_absolute_error: 67.7459\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 912us/step - loss: 69.0754 - mean_absolute_error: 69.0754\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 889us/step - loss: 66.3969 - mean_absolute_error: 66.3969\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 64.9589 - mean_absolute_error: 64.9589\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 930us/step - loss: 64.4451 - mean_absolute_error: 64.4451\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 902us/step - loss: 65.1365 - mean_absolute_error: 65.1365\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 937us/step - loss: 64.5698 - mean_absolute_error: 64.5698\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 871us/step - loss: 67.8497 - mean_absolute_error: 67.8497\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 869us/step - loss: 66.6061 - mean_absolute_error: 66.6061\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 937us/step - loss: 65.0077 - mean_absolute_error: 65.0077\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 903us/step - loss: 67.1488 - mean_absolute_error: 67.1488\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 905us/step - loss: 65.6098 - mean_absolute_error: 65.6098\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 66.2038 - mean_absolute_error: 66.2038\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 889us/step - loss: 67.8736 - mean_absolute_error: 67.8736\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 883us/step - loss: 62.3692 - mean_absolute_error: 62.3692\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 854us/step - loss: 64.7565 - mean_absolute_error: 64.7565\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 881us/step - loss: 63.4268 - mean_absolute_error: 63.4268\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 63.8147 - mean_absolute_error: 63.8147\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 986us/step - loss: 65.5505 - mean_absolute_error: 65.5505\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 63.6900 - mean_absolute_error: 63.6900\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 930us/step - loss: 63.9866 - mean_absolute_error: 63.9866\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.7181 - mean_absolute_error: 62.7181\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 954us/step - loss: 64.9931 - mean_absolute_error: 64.9931\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 976us/step - loss: 62.1744 - mean_absolute_error: 62.1744\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 956us/step - loss: 63.1655 - mean_absolute_error: 63.1655\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 902us/step - loss: 66.8511 - mean_absolute_error: 66.8511\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 863us/step - loss: 63.5601 - mean_absolute_error: 63.5601\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 881us/step - loss: 64.8429 - mean_absolute_error: 64.8429\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 907us/step - loss: 63.6280 - mean_absolute_error: 63.6280\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 923us/step - loss: 63.6791 - mean_absolute_error: 63.6791\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 61.6197 - mean_absolute_error: 61.6197\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 864us/step - loss: 62.1212 - mean_absolute_error: 62.1212\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 883us/step - loss: 62.0986 - mean_absolute_error: 62.0986\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 854us/step - loss: 60.1637 - mean_absolute_error: 60.1637\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 921us/step - loss: 62.3693 - mean_absolute_error: 62.3693\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 935us/step - loss: 64.4053 - mean_absolute_error: 64.4053\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 913us/step - loss: 59.3272 - mean_absolute_error: 59.3272\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 914us/step - loss: 60.1581 - mean_absolute_error: 60.1581\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 866us/step - loss: 62.0074 - mean_absolute_error: 62.0074\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn4.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model4 = nn4.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 67.6342 - mean_absolute_error: 67.6342\n",
      "Loss: 67.63421630859375\n",
      "Mean Absolute Error: 67.63421630859375\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss4, model_accuracy4 = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss4}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy4}\")"
   ]
  },
  {
   "source": [
    "# Test 5:  Add 50 more neurons to the first layer and add a 5th layer with just 5 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_15 (Dense)             (None, 200)               4200      \n_________________________________________________________________\ndense_16 (Dense)             (None, 50)                10050     \n_________________________________________________________________\ndense_17 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_19 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_20 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 15,541\nTrainable params: 15,541\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 200\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 0s 963us/step - loss: 195.7772 - mean_absolute_error: 195.7772\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 991us/step - loss: 102.8977 - mean_absolute_error: 102.8977\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 995us/step - loss: 84.1755 - mean_absolute_error: 84.1755\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 81.4754 - mean_absolute_error: 81.4754\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 940us/step - loss: 76.7256 - mean_absolute_error: 76.7256\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 971us/step - loss: 72.6423 - mean_absolute_error: 72.6423\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 71.2200 - mean_absolute_error: 71.2200\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.9608 - mean_absolute_error: 67.9608\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 963us/step - loss: 70.3155 - mean_absolute_error: 70.3155\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 953us/step - loss: 68.4457 - mean_absolute_error: 68.4457\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 963us/step - loss: 68.8927 - mean_absolute_error: 68.8927\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 924us/step - loss: 68.4288 - mean_absolute_error: 68.4288\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 68.8247 - mean_absolute_error: 68.8247\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 939us/step - loss: 66.3663 - mean_absolute_error: 66.3663\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 956us/step - loss: 66.9693 - mean_absolute_error: 66.9693\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 901us/step - loss: 66.1236 - mean_absolute_error: 66.1236\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 944us/step - loss: 65.3913 - mean_absolute_error: 65.3913\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.1844 - mean_absolute_error: 67.1844\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.7401 - mean_absolute_error: 67.7401\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 979us/step - loss: 65.5799 - mean_absolute_error: 65.5799\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.3826 - mean_absolute_error: 67.3826\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 921us/step - loss: 61.7088 - mean_absolute_error: 61.7088\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 937us/step - loss: 64.8587 - mean_absolute_error: 64.8587\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 940us/step - loss: 65.1431 - mean_absolute_error: 65.1431\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 976us/step - loss: 64.2762 - mean_absolute_error: 64.2762\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 965us/step - loss: 64.1880 - mean_absolute_error: 64.1880\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 65.5211 - mean_absolute_error: 65.5211\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 987us/step - loss: 63.9999 - mean_absolute_error: 63.9999\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 946us/step - loss: 64.4509 - mean_absolute_error: 64.4509\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 64.8669 - mean_absolute_error: 64.8669\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 955us/step - loss: 63.7207 - mean_absolute_error: 63.7207\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 958us/step - loss: 63.8031 - mean_absolute_error: 63.8031\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.1082 - mean_absolute_error: 67.1082\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 65.2570 - mean_absolute_error: 65.2570\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 65.3697 - mean_absolute_error: 65.3697\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 65.5233 - mean_absolute_error: 65.5233\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.0415 - mean_absolute_error: 67.0415\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 66.1560 - mean_absolute_error: 66.1560\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.2059 - mean_absolute_error: 62.2059\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 64.5404 - mean_absolute_error: 64.5404\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 63.3386 - mean_absolute_error: 63.3386\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 64.2391 - mean_absolute_error: 64.2391\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.9450 - mean_absolute_error: 62.9450\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 955us/step - loss: 63.5123 - mean_absolute_error: 63.5123\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 925us/step - loss: 62.6646 - mean_absolute_error: 62.6646\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 61.6807 - mean_absolute_error: 61.6807\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 932us/step - loss: 62.7151 - mean_absolute_error: 62.7151\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 965us/step - loss: 62.0598 - mean_absolute_error: 62.0598\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 947us/step - loss: 61.6807 - mean_absolute_error: 61.6807\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 924us/step - loss: 62.3077 - mean_absolute_error: 62.3077\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn5.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model5 = nn5.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 68.8800 - mean_absolute_error: 68.8800\n",
      "Loss: 68.88004302978516\n",
      "Mean Absolute Error: 68.88004302978516\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss5, model_accuracy5 = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss5}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy5}\")"
   ]
  },
  {
   "source": [
    "# Test 6:  Add 150 neurons to first layer and change second activation function to tanh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_21 (Dense)             (None, 350)               7350      \n_________________________________________________________________\ndense_22 (Dense)             (None, 50)                17550     \n_________________________________________________________________\ndense_23 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_24 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_25 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_26 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 26,191\nTrainable params: 26,191\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 350\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 1s 1ms/step - loss: 198.5279 - mean_absolute_error: 198.5279\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 170.7915 - mean_absolute_error: 170.7915\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 101.1739 - mean_absolute_error: 101.1739\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 99.6999 - mean_absolute_error: 99.6999\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 76.0414 - mean_absolute_error: 76.0414\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 71.0702 - mean_absolute_error: 71.0702\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 68.6586 - mean_absolute_error: 68.6586\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 68.8919 - mean_absolute_error: 68.8919\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 71.0672 - mean_absolute_error: 71.0672\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 66.5705 - mean_absolute_error: 66.5705\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 66.6434 - mean_absolute_error: 66.6434\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 58.7880 - mean_absolute_error: 58.7880\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 61.9307 - mean_absolute_error: 61.9307\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.5734 - mean_absolute_error: 62.5734\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 58.6781 - mean_absolute_error: 58.6781\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 59.8035 - mean_absolute_error: 59.8035\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 57.9949 - mean_absolute_error: 57.9949\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 58.8154 - mean_absolute_error: 58.8154\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 57.0665 - mean_absolute_error: 57.0665\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 52.8253 - mean_absolute_error: 52.8253\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 56.5083 - mean_absolute_error: 56.5083\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.8169 - mean_absolute_error: 50.8169\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 55.0022 - mean_absolute_error: 55.0022\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 56.9346 - mean_absolute_error: 56.9346\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 54.1010 - mean_absolute_error: 54.1010\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.9052 - mean_absolute_error: 53.9052\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.4086 - mean_absolute_error: 53.4086\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.4373 - mean_absolute_error: 50.4373\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.6206 - mean_absolute_error: 53.6206\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 51.4093 - mean_absolute_error: 51.4093\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.9443 - mean_absolute_error: 50.9443\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.4743 - mean_absolute_error: 50.4743\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.9729 - mean_absolute_error: 50.9729\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 51.9356 - mean_absolute_error: 51.9356\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 48.9942 - mean_absolute_error: 48.9942\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 51.5552 - mean_absolute_error: 51.5552\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 46.4772 - mean_absolute_error: 46.4772\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 45.7065 - mean_absolute_error: 45.7065\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.4152 - mean_absolute_error: 49.4152\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.2238 - mean_absolute_error: 49.2238\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 46.6281 - mean_absolute_error: 46.6281\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 47.0240 - mean_absolute_error: 47.0240\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 47.5064 - mean_absolute_error: 47.5064\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.7421 - mean_absolute_error: 49.7421\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 46.5533 - mean_absolute_error: 46.5533\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 44.7135 - mean_absolute_error: 44.7135\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 45.4662 - mean_absolute_error: 45.4662\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 42.8270 - mean_absolute_error: 42.8270\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 44.1575 - mean_absolute_error: 44.1575\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 44.9692 - mean_absolute_error: 44.9692\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn6.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model6 = nn6.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 64.0260 - mean_absolute_error: 64.0260\n",
      "Loss: 64.02604675292969\n",
      "Mean Absolute Error: 64.02604675292969\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss6, model_accuracy6 = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss6}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy6}\")"
   ]
  },
  {
   "source": [
    "# From all these tests, the best performing Deep Neural Network (the last test), was off, on average, by about $64.02"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
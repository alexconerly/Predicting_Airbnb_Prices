{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythondata",
   "display_name": "PythonData",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# In this file, we pull in postgres data after the collinearity feature reduction adjustment and use Scikit-learn's random forest permutation feature importance method to reduce the features with weak predictive power.  Finally, we run the same Deep Neural Network tests as we did in the baseline tests again to see the new results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PostGres Download Duration: 0.8261852264404297 seconds\n"
     ]
    }
   ],
   "source": [
    "# Download raw data from postgres for stage 1 ETL\n",
    "\n",
    "conn_string = 'postgres://whnpmxwsiccrtg:53c453893549d2b1e6a4ff92e626a2a08ebcaff66678e50d33e3742f66e3e4f4@ec2-52-4-171-132.compute-1.amazonaws.com/d2ajro4cjr10lb'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "start_time = time.time()\n",
    "merge1 = pd.read_sql_query('select * from \"merged_no_cal\"',con=conn)\n",
    "print(\"PostGres Download Duration: {} seconds\".format(time.time() - start_time))\n",
    "conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = merge1[\"price\"]\n",
    "X = merge1.drop(\"price\",1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "source": [
    "# Perform RFR to evaluate feature importance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=200, random_state=78)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Get feature importances using RFR\n",
    "# import the regressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Instantiate the Decision Tree Regression model:\n",
    "random_forest_regression_model = RandomForestRegressor(n_estimators = 200, random_state = 78) \n",
    "random_forest_regression_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Measuring feature importance using permutation\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "r = permutation_importance(random_forest_regression_model, X_test, y_test, random_state = 78, n_jobs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 Importance\n",
       "bathrooms                                          0.326393\n",
       "cleaning_fee                                       0.136475\n",
       "accommodates                                       0.123314\n",
       "host_listings_count                                0.092135\n",
       "bedrooms                                           0.073703\n",
       "reviews_per_month                                  0.045878\n",
       "neighbourhood_cleansed_District 19                 0.033249\n",
       "security_deposit                                   0.022658\n",
       "number_of_reviews                                  0.017147\n",
       "guests_included                                    0.017023\n",
       "days_host                                          0.013073\n",
       "availability_365                                   0.012304\n",
       "cancellation_policy_strict_14_with_grace_period    0.008467\n",
       "room_type_Entire home/apt                          0.007513\n",
       "smoke_detector                                     0.006647\n",
       "minimum_nights                                     0.005648\n",
       "neighbourhood_cleansed_District 17                 0.005627\n",
       "free_parking_on_premises                           0.005382\n",
       "property_type_Loft                                 0.005255\n",
       "review_scores_rating                               0.005170\n",
       "elevator                                           0.004835\n",
       "maximum_nights                                     0.003327\n",
       "shampoo                                            0.003022\n",
       "hair_dryer                                         0.002775\n",
       "lock_on_bedroom_door                               0.002617"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bathrooms</th>\n      <td>0.326393</td>\n    </tr>\n    <tr>\n      <th>cleaning_fee</th>\n      <td>0.136475</td>\n    </tr>\n    <tr>\n      <th>accommodates</th>\n      <td>0.123314</td>\n    </tr>\n    <tr>\n      <th>host_listings_count</th>\n      <td>0.092135</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>0.073703</td>\n    </tr>\n    <tr>\n      <th>reviews_per_month</th>\n      <td>0.045878</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 19</th>\n      <td>0.033249</td>\n    </tr>\n    <tr>\n      <th>security_deposit</th>\n      <td>0.022658</td>\n    </tr>\n    <tr>\n      <th>number_of_reviews</th>\n      <td>0.017147</td>\n    </tr>\n    <tr>\n      <th>guests_included</th>\n      <td>0.017023</td>\n    </tr>\n    <tr>\n      <th>days_host</th>\n      <td>0.013073</td>\n    </tr>\n    <tr>\n      <th>availability_365</th>\n      <td>0.012304</td>\n    </tr>\n    <tr>\n      <th>cancellation_policy_strict_14_with_grace_period</th>\n      <td>0.008467</td>\n    </tr>\n    <tr>\n      <th>room_type_Entire home/apt</th>\n      <td>0.007513</td>\n    </tr>\n    <tr>\n      <th>smoke_detector</th>\n      <td>0.006647</td>\n    </tr>\n    <tr>\n      <th>minimum_nights</th>\n      <td>0.005648</td>\n    </tr>\n    <tr>\n      <th>neighbourhood_cleansed_District 17</th>\n      <td>0.005627</td>\n    </tr>\n    <tr>\n      <th>free_parking_on_premises</th>\n      <td>0.005382</td>\n    </tr>\n    <tr>\n      <th>property_type_Loft</th>\n      <td>0.005255</td>\n    </tr>\n    <tr>\n      <th>review_scores_rating</th>\n      <td>0.005170</td>\n    </tr>\n    <tr>\n      <th>elevator</th>\n      <td>0.004835</td>\n    </tr>\n    <tr>\n      <th>maximum_nights</th>\n      <td>0.003327</td>\n    </tr>\n    <tr>\n      <th>shampoo</th>\n      <td>0.003022</td>\n    </tr>\n    <tr>\n      <th>hair_dryer</th>\n      <td>0.002775</td>\n    </tr>\n    <tr>\n      <th>lock_on_bedroom_door</th>\n      <td>0.002617</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "sorted_idx = r.importances_mean.argsort()\n",
    "feat_imp_df = pd.DataFrame(data=r.importances_mean[sorted_idx], index = X_test.columns[sorted_idx], columns=['Importance'])\n",
    "feat_imp_df.sort_values(ascending=False, by='Importance').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = feat_imp_df[feat_imp_df['Importance'] < 0.015].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = merge1.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'price',\n",
       "       'security_deposit', 'cleaning_fee', 'guests_included',\n",
       "       'number_of_reviews', 'reviews_per_month',\n",
       "       'neighbourhood_cleansed_District 19'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "merge2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = merge2[\"price\"].values\n",
    "X = merge2.drop(\"price\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "# Fit the RobustScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "# Test 1: Use one input layer and one hidden layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 80)                880       \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                2430      \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 31        \n=================================================================\nTotal params: 3,341\nTrainable params: 3,341\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "117/117 [==============================] - 1s 1ms/step - loss: 191.4521 - mean_absolute_error: 191.4521\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 0s 896us/step - loss: 126.1267 - mean_absolute_error: 126.1267\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 0s 954us/step - loss: 90.7978 - mean_absolute_error: 90.7978\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 86.2892 - mean_absolute_error: 86.2892\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 81.4624 - mean_absolute_error: 81.4624\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 0s 920us/step - loss: 82.2438 - mean_absolute_error: 82.2438\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 0s 943us/step - loss: 75.7267 - mean_absolute_error: 75.7267\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 0s 955us/step - loss: 74.1156 - mean_absolute_error: 74.1156\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 0s 839us/step - loss: 74.0652 - mean_absolute_error: 74.0652\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 74.4813 - mean_absolute_error: 74.4813\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 73.3031 - mean_absolute_error: 73.3031\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.7271 - mean_absolute_error: 70.7271\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 0s 999us/step - loss: 70.9441 - mean_absolute_error: 70.9441\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 71.3619 - mean_absolute_error: 71.3619\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.4980 - mean_absolute_error: 70.4980\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 0s 959us/step - loss: 71.0245 - mean_absolute_error: 71.0245\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 0s 925us/step - loss: 71.8160 - mean_absolute_error: 71.8160\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 0s 926us/step - loss: 72.7521 - mean_absolute_error: 72.7521\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 0s 849us/step - loss: 68.0024 - mean_absolute_error: 68.0024\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 0s 970us/step - loss: 72.1460 - mean_absolute_error: 72.1460\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.3018 - mean_absolute_error: 68.3018\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 0s 801us/step - loss: 69.5673 - mean_absolute_error: 69.5673\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 0s 747us/step - loss: 73.2276 - mean_absolute_error: 73.2276\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 0s 715us/step - loss: 69.0870 - mean_absolute_error: 69.0870\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 0s 742us/step - loss: 70.9734 - mean_absolute_error: 70.9734\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 0s 806us/step - loss: 65.2991 - mean_absolute_error: 65.2991\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 0s 868us/step - loss: 70.3965 - mean_absolute_error: 70.3965\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 0s 929us/step - loss: 69.1302 - mean_absolute_error: 69.1302\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 0s 803us/step - loss: 71.1972 - mean_absolute_error: 71.1972\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 0s 845us/step - loss: 69.5742 - mean_absolute_error: 69.5742\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 0s 958us/step - loss: 70.2437 - mean_absolute_error: 70.2437\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 0s 759us/step - loss: 69.5824 - mean_absolute_error: 69.5824\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 0s 866us/step - loss: 68.6301 - mean_absolute_error: 68.6301\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 0s 828us/step - loss: 68.5810 - mean_absolute_error: 68.5810\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 0s 777us/step - loss: 66.8152 - mean_absolute_error: 66.8152\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 0s 903us/step - loss: 68.4517 - mean_absolute_error: 68.4517\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 0s 896us/step - loss: 69.2067 - mean_absolute_error: 69.2067\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 0s 866us/step - loss: 69.5116 - mean_absolute_error: 69.5116\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 0s 957us/step - loss: 71.0366 - mean_absolute_error: 71.0366\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.9457 - mean_absolute_error: 67.9457\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 0s 939us/step - loss: 67.7610 - mean_absolute_error: 67.7610\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.1820 - mean_absolute_error: 68.1820\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.8395 - mean_absolute_error: 66.8395\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 0s 851us/step - loss: 71.0035 - mean_absolute_error: 71.0035\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 0s 844us/step - loss: 68.8398 - mean_absolute_error: 68.8398\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 0s 875us/step - loss: 67.2922 - mean_absolute_error: 67.2922\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 0s 841us/step - loss: 64.3138 - mean_absolute_error: 64.3138\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 0s 882us/step - loss: 67.1001 - mean_absolute_error: 67.1001\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 0s 980us/step - loss: 68.8182 - mean_absolute_error: 68.8182\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 0s 876us/step - loss: 66.1426 - mean_absolute_error: 66.1426\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 0s 901us/step - loss: 69.5142 - mean_absolute_error: 69.5142\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 0s 801us/step - loss: 66.9709 - mean_absolute_error: 66.9709\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 0s 778us/step - loss: 69.3511 - mean_absolute_error: 69.3511\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 0s 829us/step - loss: 65.5243 - mean_absolute_error: 65.5243\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 0s 783us/step - loss: 69.4251 - mean_absolute_error: 69.4251\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 0s 787us/step - loss: 69.2671 - mean_absolute_error: 69.2671\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 0s 838us/step - loss: 65.6764 - mean_absolute_error: 65.6764\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 72.4174 - mean_absolute_error: 72.4174\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.8805 - mean_absolute_error: 66.8805\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 0s 886us/step - loss: 67.0004 - mean_absolute_error: 67.0004\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.2917 - mean_absolute_error: 67.2917\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.0579 - mean_absolute_error: 65.0579\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.3901 - mean_absolute_error: 70.3901\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.8112 - mean_absolute_error: 67.8112\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.5899 - mean_absolute_error: 64.5899\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.9671 - mean_absolute_error: 66.9671\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.5741 - mean_absolute_error: 67.5741\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.0278 - mean_absolute_error: 66.0278\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 71.4744 - mean_absolute_error: 71.4744\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 0s 857us/step - loss: 65.6770 - mean_absolute_error: 65.6770\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 0s 788us/step - loss: 63.4851 - mean_absolute_error: 63.4851\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 0s 838us/step - loss: 65.1244 - mean_absolute_error: 65.1244\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.1901 - mean_absolute_error: 67.1901\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 0s 862us/step - loss: 64.8568 - mean_absolute_error: 64.8568\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 0s 966us/step - loss: 68.0326 - mean_absolute_error: 68.0326\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 0s 983us/step - loss: 66.8030 - mean_absolute_error: 66.8030\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 0s 809us/step - loss: 65.7864 - mean_absolute_error: 65.7864\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 0s 767us/step - loss: 64.8120 - mean_absolute_error: 64.8120\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 0s 787us/step - loss: 66.1125 - mean_absolute_error: 66.1125\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.7897 - mean_absolute_error: 65.7897\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 62.9052 - mean_absolute_error: 62.9052\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.6240 - mean_absolute_error: 64.6240\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 0s 858us/step - loss: 66.1923 - mean_absolute_error: 66.1923\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.8951 - mean_absolute_error: 64.8951\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 0s 987us/step - loss: 63.5471 - mean_absolute_error: 63.5471\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.6702 - mean_absolute_error: 66.6702\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 0s 985us/step - loss: 63.6309 - mean_absolute_error: 63.6309\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.1890 - mean_absolute_error: 67.1890\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 0s 811us/step - loss: 68.2208 - mean_absolute_error: 68.2208\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 0s 802us/step - loss: 64.4637 - mean_absolute_error: 64.4637\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 0s 987us/step - loss: 65.9636 - mean_absolute_error: 65.9636\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 61.9291 - mean_absolute_error: 61.9291\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 0s 958us/step - loss: 62.5808 - mean_absolute_error: 62.5808\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 0s 864us/step - loss: 64.4578 - mean_absolute_error: 64.4578\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 0s 851us/step - loss: 65.3757 - mean_absolute_error: 65.3757\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 0s 825us/step - loss: 65.2416 - mean_absolute_error: 65.2416\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 62.9956 - mean_absolute_error: 62.9956\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.5020 - mean_absolute_error: 63.5020\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 0s 961us/step - loss: 65.6978 - mean_absolute_error: 65.6978\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 0s 802us/step - loss: 65.0472 - mean_absolute_error: 65.0472\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 65.1233 - mean_absolute_error: 65.1233\n",
      "Loss: 65.123291015625, MAE: 65.123291015625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, MAE: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "# Test 2 Add more neurons to each layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 100)               1900      \n_________________________________________________________________\ndense_4 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 7,001\nTrainable params: 7,001\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 0s 984us/step - loss: 190.5339 - mean_absolute_error: 190.5339\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 100.0951 - mean_absolute_error: 100.0951\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.9878 - mean_absolute_error: 85.9878\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 85.4927 - mean_absolute_error: 85.4927\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 0s 984us/step - loss: 77.6872 - mean_absolute_error: 77.6872\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 0s 923us/step - loss: 75.8674 - mean_absolute_error: 75.8674\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 0s 833us/step - loss: 71.3554 - mean_absolute_error: 71.3554\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 0s 936us/step - loss: 70.0703 - mean_absolute_error: 70.0703\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 0s 823us/step - loss: 70.4722 - mean_absolute_error: 70.4722\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 0s 804us/step - loss: 72.0402 - mean_absolute_error: 72.0402\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 0s 968us/step - loss: 69.4681 - mean_absolute_error: 69.4681\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 0s 846us/step - loss: 71.4047 - mean_absolute_error: 71.4047\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 0s 788us/step - loss: 70.8195 - mean_absolute_error: 70.8195\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 0s 841us/step - loss: 68.9039 - mean_absolute_error: 68.9039\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 0s 824us/step - loss: 69.5043 - mean_absolute_error: 69.5043\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 0s 848us/step - loss: 70.3387 - mean_absolute_error: 70.3387\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.4349 - mean_absolute_error: 68.4349\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 0s 919us/step - loss: 70.6537 - mean_absolute_error: 70.6537\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.8041 - mean_absolute_error: 68.8041\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 0s 856us/step - loss: 66.6492 - mean_absolute_error: 66.6492\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 0s 839us/step - loss: 69.5065 - mean_absolute_error: 69.5065\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 0s 988us/step - loss: 68.6765 - mean_absolute_error: 68.6765\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 0s 958us/step - loss: 70.0495 - mean_absolute_error: 70.0495\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 0s 933us/step - loss: 69.8573 - mean_absolute_error: 69.8573\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 0s 986us/step - loss: 67.4589 - mean_absolute_error: 67.4589\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.3196 - mean_absolute_error: 68.3196\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 72.6978 - mean_absolute_error: 72.6978\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.9215 - mean_absolute_error: 65.9215\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 0s 973us/step - loss: 65.7611 - mean_absolute_error: 65.7611\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.9280 - mean_absolute_error: 65.9280\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 0s 804us/step - loss: 70.5468 - mean_absolute_error: 70.5468\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 0s 937us/step - loss: 68.7687 - mean_absolute_error: 68.7687\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 0s 857us/step - loss: 66.7972 - mean_absolute_error: 66.7972\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 0s 810us/step - loss: 69.2652 - mean_absolute_error: 69.2652\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 0s 810us/step - loss: 69.5668 - mean_absolute_error: 69.5668\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 0s 958us/step - loss: 69.1461 - mean_absolute_error: 69.1461\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 0s 968us/step - loss: 66.4977 - mean_absolute_error: 66.4977\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 0s 855us/step - loss: 68.3350 - mean_absolute_error: 68.3350\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 0s 793us/step - loss: 67.0220 - mean_absolute_error: 67.0220\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.5806 - mean_absolute_error: 67.5806\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 0s 858us/step - loss: 67.9822 - mean_absolute_error: 67.9822\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 0s 819us/step - loss: 66.2369 - mean_absolute_error: 66.2369\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.9080 - mean_absolute_error: 68.9080\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 0s 899us/step - loss: 65.9750 - mean_absolute_error: 65.9750\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 0s 755us/step - loss: 69.9214 - mean_absolute_error: 69.9214\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 0s 878us/step - loss: 64.9786 - mean_absolute_error: 64.9786\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 0s 747us/step - loss: 65.7873 - mean_absolute_error: 65.7873\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 0s 731us/step - loss: 68.2191 - mean_absolute_error: 68.2191\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 0s 774us/step - loss: 63.5211 - mean_absolute_error: 63.5211\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 0s 762us/step - loss: 66.1457 - mean_absolute_error: 66.1457\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model2 = nn2.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 66.3587 - mean_absolute_error: 66.3587\n",
      "Loss: 66.35865020751953\n",
      "Mean Absolute Error: 66.35865020751953\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss2, model_accuracy2 = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss2}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy2}\")"
   ]
  },
  {
   "source": [
    "# Test 3:  Add an additional layer with 20 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 100)               1900      \n_________________________________________________________________\ndense_7 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_8 (Dense)              (None, 20)                1020      \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 21        \n=================================================================\nTotal params: 7,991\nTrainable params: 7,991\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 187.1350 - mean_absolute_error: 187.1350\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 93.1732 - mean_absolute_error: 93.1732\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 84.1385 - mean_absolute_error: 84.1385\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 77.3480 - mean_absolute_error: 77.3480\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 74.2579 - mean_absolute_error: 74.2579\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 71.3518 - mean_absolute_error: 71.3518\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 73.3742 - mean_absolute_error: 73.3742\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 0s 941us/step - loss: 69.4344 - mean_absolute_error: 69.4344\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 71.5332 - mean_absolute_error: 71.5332\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 0s 993us/step - loss: 68.7770 - mean_absolute_error: 68.7770\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 0s 995us/step - loss: 68.2929 - mean_absolute_error: 68.2929\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 0s 955us/step - loss: 68.2406 - mean_absolute_error: 68.2406\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.6302 - mean_absolute_error: 68.6302\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 69.3002 - mean_absolute_error: 69.3002\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 0s 941us/step - loss: 69.8781 - mean_absolute_error: 69.8781\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.8125 - mean_absolute_error: 68.8125\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 71.4577 - mean_absolute_error: 71.4577\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 0s 953us/step - loss: 70.7134 - mean_absolute_error: 70.7134\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 0s 903us/step - loss: 64.5516 - mean_absolute_error: 64.5516\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 0s 905us/step - loss: 70.7510 - mean_absolute_error: 70.7510\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 0s 848us/step - loss: 67.0184 - mean_absolute_error: 67.0184\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.7716 - mean_absolute_error: 67.7716\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.4091 - mean_absolute_error: 66.4091\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.1674 - mean_absolute_error: 67.1674\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.4143 - mean_absolute_error: 65.4143\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 0s 943us/step - loss: 68.4074 - mean_absolute_error: 68.4074\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 0s 938us/step - loss: 68.6546 - mean_absolute_error: 68.6546\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 0s 981us/step - loss: 70.9935 - mean_absolute_error: 70.9935\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.6291 - mean_absolute_error: 66.6291\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.5912 - mean_absolute_error: 67.5912\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 0s 863us/step - loss: 67.1678 - mean_absolute_error: 67.1678\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 0s 862us/step - loss: 64.5714 - mean_absolute_error: 64.5714\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 0s 934us/step - loss: 66.2933 - mean_absolute_error: 66.2933\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.7882 - mean_absolute_error: 64.7882\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 0s 976us/step - loss: 67.0699 - mean_absolute_error: 67.0699\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 0s 955us/step - loss: 66.7211 - mean_absolute_error: 66.7211\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 0s 970us/step - loss: 64.6753 - mean_absolute_error: 64.6753\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.6080 - mean_absolute_error: 63.6080\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.1997 - mean_absolute_error: 64.1997\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 0s 988us/step - loss: 63.2022 - mean_absolute_error: 63.2022\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 0s 880us/step - loss: 66.4938 - mean_absolute_error: 66.4938\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.0151 - mean_absolute_error: 65.0151\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 0s 955us/step - loss: 66.2422 - mean_absolute_error: 66.2422\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.3016 - mean_absolute_error: 66.3016\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.6803 - mean_absolute_error: 66.6803\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.8696 - mean_absolute_error: 65.8696\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.3378 - mean_absolute_error: 63.3378\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.5655 - mean_absolute_error: 65.5655\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.2365 - mean_absolute_error: 67.2365\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.2476 - mean_absolute_error: 65.2476\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn3.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model3 = nn3.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 64.9918 - mean_absolute_error: 64.9918\n",
      "Loss: 64.99178314208984\n",
      "Mean Absolute Error: 64.99178314208984\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss3, model_accuracy3 = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss3}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy3}\")"
   ]
  },
  {
   "source": [
    "# Test 4:  Add 50 neurons to the first layer and a 4th layer with 10 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 150\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn4.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 1s 1ms/step - loss: 187.0719 - mean_absolute_error: 187.0719\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 91.6559 - mean_absolute_error: 91.6559\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 79.8165 - mean_absolute_error: 79.8165\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 0s 982us/step - loss: 77.2750 - mean_absolute_error: 77.2750\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 74.4562 - mean_absolute_error: 74.4562\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.9308 - mean_absolute_error: 70.9308\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 69.6067 - mean_absolute_error: 69.6067\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 71.3516 - mean_absolute_error: 71.3516\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 0s 946us/step - loss: 70.2134 - mean_absolute_error: 70.2134\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 0s 978us/step - loss: 68.8257 - mean_absolute_error: 68.8257\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.4047 - mean_absolute_error: 70.4047\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.8294 - mean_absolute_error: 68.8294\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.3323 - mean_absolute_error: 66.3323\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.5846 - mean_absolute_error: 68.5846\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 71.1893 - mean_absolute_error: 71.1893\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 0s 981us/step - loss: 70.1578 - mean_absolute_error: 70.1578\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 0s 961us/step - loss: 67.5616 - mean_absolute_error: 67.5616\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.5372 - mean_absolute_error: 68.5372\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.5021 - mean_absolute_error: 66.5021\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 0s 883us/step - loss: 67.9847 - mean_absolute_error: 67.9847\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 0s 999us/step - loss: 67.1906 - mean_absolute_error: 67.1906\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.7123 - mean_absolute_error: 67.7123\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.2331 - mean_absolute_error: 70.2331\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.1265 - mean_absolute_error: 67.1265\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.3437 - mean_absolute_error: 65.3437\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.9996 - mean_absolute_error: 64.9996\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.3018 - mean_absolute_error: 65.3018\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 65.6467 - mean_absolute_error: 65.6467\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 68.4321 - mean_absolute_error: 68.4321\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 66.5419 - mean_absolute_error: 66.5419\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 68.9958 - mean_absolute_error: 68.9958\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 67.2062 - mean_absolute_error: 67.2062\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 65.3037 - mean_absolute_error: 65.3037\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.8284 - mean_absolute_error: 65.8284\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.9540 - mean_absolute_error: 64.9540\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.5369 - mean_absolute_error: 63.5369\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 0s 984us/step - loss: 66.3169 - mean_absolute_error: 66.3169\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.9004 - mean_absolute_error: 63.9004\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.4372 - mean_absolute_error: 64.4372\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.6342 - mean_absolute_error: 65.6342\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.0993 - mean_absolute_error: 68.0993\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 0s 987us/step - loss: 65.3744 - mean_absolute_error: 65.3744\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 62.9006 - mean_absolute_error: 62.9006\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.7322 - mean_absolute_error: 64.7322\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 64.4184 - mean_absolute_error: 64.4184\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 65.9056 - mean_absolute_error: 65.9056\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.9376 - mean_absolute_error: 65.9376\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.0756 - mean_absolute_error: 65.0756\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 62.9797 - mean_absolute_error: 62.9797\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 63.0710 - mean_absolute_error: 63.0710\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn4.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model4 = nn4.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 64.4242 - mean_absolute_error: 64.4242\n",
      "Loss: 64.42415618896484\n",
      "Mean Absolute Error: 64.42415618896484\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss4, model_accuracy4 = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss4}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy4}\")"
   ]
  },
  {
   "source": [
    "# Test 5:  Add 50 more neurons to the first layer and add a 5th layer with just 5 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_15 (Dense)             (None, 200)               3800      \n_________________________________________________________________\ndense_16 (Dense)             (None, 50)                10050     \n_________________________________________________________________\ndense_17 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_19 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_20 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 15,141\nTrainable params: 15,141\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 200\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 1s 1ms/step - loss: 192.1460 - mean_absolute_error: 192.1460\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 94.5303 - mean_absolute_error: 94.5303\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 80.2050 - mean_absolute_error: 80.2050\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 74.1033 - mean_absolute_error: 74.1033\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.3855 - mean_absolute_error: 68.3855\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.9930 - mean_absolute_error: 70.9930\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.7326 - mean_absolute_error: 68.7326\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.7847 - mean_absolute_error: 68.7847\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 69.3293 - mean_absolute_error: 69.3293\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.4123 - mean_absolute_error: 70.4123\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 69.2636 - mean_absolute_error: 69.2636\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 69.4579 - mean_absolute_error: 69.4579\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 73.3705 - mean_absolute_error: 73.3705\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.2162 - mean_absolute_error: 68.2162\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 0s 955us/step - loss: 67.9638 - mean_absolute_error: 67.9638\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 0s 857us/step - loss: 71.7273 - mean_absolute_error: 71.7273\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 0s 969us/step - loss: 68.0884 - mean_absolute_error: 68.0884\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 0s 915us/step - loss: 67.1369 - mean_absolute_error: 67.1369\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 0s 964us/step - loss: 67.8999 - mean_absolute_error: 67.8999\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.4882 - mean_absolute_error: 68.4882\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.8936 - mean_absolute_error: 66.8936\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 0s 965us/step - loss: 66.8129 - mean_absolute_error: 66.8129\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 0s 976us/step - loss: 69.6064 - mean_absolute_error: 69.6064\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 0s 996us/step - loss: 65.7918 - mean_absolute_error: 65.7918\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.6859 - mean_absolute_error: 66.6859\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 0s 913us/step - loss: 65.5557 - mean_absolute_error: 65.5557\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 66.1892 - mean_absolute_error: 66.1892\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.5046 - mean_absolute_error: 66.5046\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.0644 - mean_absolute_error: 66.0644\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.5671 - mean_absolute_error: 66.5671\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.6906 - mean_absolute_error: 66.6906\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.1398 - mean_absolute_error: 67.1398\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 0s 964us/step - loss: 69.2364 - mean_absolute_error: 69.2364\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.3894 - mean_absolute_error: 65.3894\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.6253 - mean_absolute_error: 66.6253\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.1228 - mean_absolute_error: 66.1228\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.9406 - mean_absolute_error: 66.9406\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.7082 - mean_absolute_error: 65.7082\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 66.1952 - mean_absolute_error: 66.1952\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.1834 - mean_absolute_error: 67.1834\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.3990 - mean_absolute_error: 64.3990\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.9036 - mean_absolute_error: 65.9036\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 0s 993us/step - loss: 66.6359 - mean_absolute_error: 66.6359\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 0s 932us/step - loss: 64.0747 - mean_absolute_error: 64.0747\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 67.1639 - mean_absolute_error: 67.1639\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 64.9593 - mean_absolute_error: 64.9593\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 65.5663 - mean_absolute_error: 65.5663\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 66.1476 - mean_absolute_error: 66.1476\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.4417 - mean_absolute_error: 63.4417\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.9323 - mean_absolute_error: 63.9323\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn5.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model5 = nn5.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 64.8520 - mean_absolute_error: 64.8520\n",
      "Loss: 64.85202026367188\n",
      "Mean Absolute Error: 64.85202026367188\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss5, model_accuracy5 = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss5}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy5}\")"
   ]
  },
  {
   "source": [
    "# Test 6:  Add 150 neurons to first layer and change second activation function to tanh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_21 (Dense)             (None, 350)               6650      \n_________________________________________________________________\ndense_22 (Dense)             (None, 50)                17550     \n_________________________________________________________________\ndense_23 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_24 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_25 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_26 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 25,491\nTrainable params: 25,491\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 350\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 1s 1ms/step - loss: 204.0117 - mean_absolute_error: 204.0117\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 125.9113 - mean_absolute_error: 125.9113\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 100.8778 - mean_absolute_error: 100.8778\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 80.9416 - mean_absolute_error: 80.9416\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.8528 - mean_absolute_error: 70.8528\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 70.2353 - mean_absolute_error: 70.2353\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 69.6332 - mean_absolute_error: 69.6332\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 68.6942 - mean_absolute_error: 68.6942\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 65.1020 - mean_absolute_error: 65.1020\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.0222 - mean_absolute_error: 63.0222\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 60.6080 - mean_absolute_error: 60.6080\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 63.6933 - mean_absolute_error: 63.6933\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 59.1609 - mean_absolute_error: 59.1609\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 62.9931 - mean_absolute_error: 62.9931\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 60.8361 - mean_absolute_error: 60.8361\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 57.8565 - mean_absolute_error: 57.8565\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 58.2476 - mean_absolute_error: 58.2476\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 60.9350 - mean_absolute_error: 60.9350\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 56.9936 - mean_absolute_error: 56.9936\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 57.3581 - mean_absolute_error: 57.3581\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 56.5397 - mean_absolute_error: 56.5397\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 56.2908 - mean_absolute_error: 56.2908\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 57.6893 - mean_absolute_error: 57.6893\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 51.7779 - mean_absolute_error: 51.7779\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 55.3612 - mean_absolute_error: 55.3612\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 54.3999 - mean_absolute_error: 54.3999\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 52.8680 - mean_absolute_error: 52.8680\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 53.1290 - mean_absolute_error: 53.1290\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 52.4941 - mean_absolute_error: 52.4941\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 51.7900 - mean_absolute_error: 51.7900\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 0s 997us/step - loss: 52.6362 - mean_absolute_error: 52.6362\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 49.6733 - mean_absolute_error: 49.6733\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 48.6683 - mean_absolute_error: 48.6683\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 54.0158 - mean_absolute_error: 54.0158\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 48.4232 - mean_absolute_error: 48.4232\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 54.5416 - mean_absolute_error: 54.5416\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 48.4455 - mean_absolute_error: 48.4455\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 48.5508 - mean_absolute_error: 48.5508\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 46.7578 - mean_absolute_error: 46.7578\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 47.9611 - mean_absolute_error: 47.9611\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 46.8554 - mean_absolute_error: 46.8554\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 46.8338 - mean_absolute_error: 46.8338\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 48.5632 - mean_absolute_error: 48.5632\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.6030 - mean_absolute_error: 44.6030\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 44.9279 - mean_absolute_error: 44.9279\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.1370 - mean_absolute_error: 44.1370\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.2573 - mean_absolute_error: 44.2573\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 44.8811 - mean_absolute_error: 44.8811\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 42.1351 - mean_absolute_error: 42.1351\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 43.5324 - mean_absolute_error: 43.5324\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn6.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model6 = nn6.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 59.1812 - mean_absolute_error: 59.1812\n",
      "Loss: 59.18115997314453\n",
      "Mean Absolute Error: 59.18115997314453\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss6, model_accuracy6 = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss6}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy6}\")"
   ]
  },
  {
   "source": [
    "# From all these tests, the best performing Deep Neural Network (the last test), was off, on average, by about $59.18"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
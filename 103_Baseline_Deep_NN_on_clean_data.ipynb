{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythondata",
   "display_name": "PythonData",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Here we'll do a baseline test on 6 Neural Network model variations on the cleaned data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PostGres Download Duration: 1.8421802520751953 seconds\n"
     ]
    }
   ],
   "source": [
    "# Download raw data from postgres for stage 1 ETL\n",
    "\n",
    "conn_string = 'postgres://whnpmxwsiccrtg:53c453893549d2b1e6a4ff92e626a2a08ebcaff66678e50d33e3742f66e3e4f4@ec2-52-4-171-132.compute-1.amazonaws.com/d2ajro4cjr10lb'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "start_time = time.time()\n",
    "df = pd.read_sql_query('select * from \"merged_no_cal\"',con=conn)\n",
    "print(\"PostGres Download Duration: {} seconds\".format(time.time() - start_time))\n",
    "conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4949, 256)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   host_is_superhost  host_listings_count  host_identity_verified  \\\n",
       "0                  1                  1.0                       1   \n",
       "1                  1                  2.0                       0   \n",
       "2                  1                  1.0                       1   \n",
       "3                  0                  1.0                       0   \n",
       "4                  1                  2.0                       1   \n",
       "\n",
       "   accommodates  bathrooms  bedrooms  price  security_deposit  cleaning_fee  \\\n",
       "0             2        1.0         2   40.0               0.0           0.0   \n",
       "1             2        1.0         1   65.0               0.0          25.0   \n",
       "2             2        1.0         1   93.0               0.0           0.0   \n",
       "3             2        1.0         1  105.0             200.0           0.0   \n",
       "4             2        1.0         1   55.0               0.0           0.0   \n",
       "\n",
       "   guests_included  ...  bed_type_Couch  bed_type_Futon  \\\n",
       "0                1  ...             0.0             0.0   \n",
       "1                1  ...             0.0             0.0   \n",
       "2                1  ...             0.0             0.0   \n",
       "3                1  ...             0.0             0.0   \n",
       "4                1  ...             0.0             0.0   \n",
       "\n",
       "   bed_type_Pull-out Sofa  bed_type_Real Bed  cancellation_policy_flexible  \\\n",
       "0                     0.0                1.0                           0.0   \n",
       "1                     0.0                1.0                           0.0   \n",
       "2                     0.0                1.0                           0.0   \n",
       "3                     0.0                1.0                           0.0   \n",
       "4                     0.0                1.0                           0.0   \n",
       "\n",
       "   cancellation_policy_moderate  cancellation_policy_strict  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           1.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           1.0                         0.0   \n",
       "\n",
       "   cancellation_policy_strict_14_with_grace_period  \\\n",
       "0                                              1.0   \n",
       "1                                              1.0   \n",
       "2                                              0.0   \n",
       "3                                              1.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   cancellation_policy_super_strict_30  cancellation_policy_super_strict_60  \n",
       "0                                  0.0                                  0.0  \n",
       "1                                  0.0                                  0.0  \n",
       "2                                  0.0                                  0.0  \n",
       "3                                  0.0                                  0.0  \n",
       "4                                  0.0                                  0.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host_is_superhost</th>\n      <th>host_listings_count</th>\n      <th>host_identity_verified</th>\n      <th>accommodates</th>\n      <th>bathrooms</th>\n      <th>bedrooms</th>\n      <th>price</th>\n      <th>security_deposit</th>\n      <th>cleaning_fee</th>\n      <th>guests_included</th>\n      <th>...</th>\n      <th>bed_type_Couch</th>\n      <th>bed_type_Futon</th>\n      <th>bed_type_Pull-out Sofa</th>\n      <th>bed_type_Real Bed</th>\n      <th>cancellation_policy_flexible</th>\n      <th>cancellation_policy_moderate</th>\n      <th>cancellation_policy_strict</th>\n      <th>cancellation_policy_strict_14_with_grace_period</th>\n      <th>cancellation_policy_super_strict_30</th>\n      <th>cancellation_policy_super_strict_60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>65.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>93.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>105.0</td>\n      <td>200.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>55.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 256 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"price\"].values\n",
    "X = df.drop(\"price\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['host_is_superhost', 'host_listings_count', 'host_identity_verified',\n",
       "       'accommodates', 'bathrooms', 'bedrooms', 'price', 'security_deposit',\n",
       "       'cleaning_fee', 'guests_included',\n",
       "       ...\n",
       "       'bed_type_Couch', 'bed_type_Futon', 'bed_type_Pull-out Sofa',\n",
       "       'bed_type_Real Bed', 'cancellation_policy_flexible',\n",
       "       'cancellation_policy_moderate', 'cancellation_policy_strict',\n",
       "       'cancellation_policy_strict_14_with_grace_period',\n",
       "       'cancellation_policy_super_strict_30',\n",
       "       'cancellation_policy_super_strict_60'],\n",
       "      dtype='object', length=256)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = RobustScaler()\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "source": [
    "# Test 1: Use one input layer and one hidden layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 80)                20480     \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                2430      \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 31        \n=================================================================\nTotal params: 22,941\nTrainable params: 22,941\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 1s 889us/step - loss: 183.8592 - mean_absolute_error: 183.8592\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 90.0112 - mean_absolute_error: 90.0112\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 856us/step - loss: 80.3731 - mean_absolute_error: 80.3731\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 857us/step - loss: 72.7551 - mean_absolute_error: 72.7551\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 72.5555 - mean_absolute_error: 72.5555\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 911us/step - loss: 69.1262 - mean_absolute_error: 69.1262\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 68.0666 - mean_absolute_error: 68.0666\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 795us/step - loss: 68.6957 - mean_absolute_error: 68.6957\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 843us/step - loss: 67.6753 - mean_absolute_error: 67.6753\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 933us/step - loss: 67.4028 - mean_absolute_error: 67.4028\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 834us/step - loss: 65.4811 - mean_absolute_error: 65.4811\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 823us/step - loss: 63.7866 - mean_absolute_error: 63.7866\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 830us/step - loss: 65.6641 - mean_absolute_error: 65.6641\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 905us/step - loss: 64.0371 - mean_absolute_error: 64.0371\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 843us/step - loss: 60.9868 - mean_absolute_error: 60.9868\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 856us/step - loss: 61.3899 - mean_absolute_error: 61.3899\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 961us/step - loss: 60.6590 - mean_absolute_error: 60.6590\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 834us/step - loss: 61.9067 - mean_absolute_error: 61.9067\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 801us/step - loss: 60.1474 - mean_absolute_error: 60.1474\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 804us/step - loss: 57.2274 - mean_absolute_error: 57.2274\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 824us/step - loss: 56.5982 - mean_absolute_error: 56.5982\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 805us/step - loss: 58.0453 - mean_absolute_error: 58.0453\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 803us/step - loss: 56.6960 - mean_absolute_error: 56.6960\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 869us/step - loss: 57.9056 - mean_absolute_error: 57.9056\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 851us/step - loss: 60.4583 - mean_absolute_error: 60.4583\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 851us/step - loss: 59.7103 - mean_absolute_error: 59.7103\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 60.7397 - mean_absolute_error: 60.7397\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 899us/step - loss: 55.0398 - mean_absolute_error: 55.0398\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 852us/step - loss: 55.0580 - mean_absolute_error: 55.0580\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 795us/step - loss: 58.1113 - mean_absolute_error: 58.1113\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 809us/step - loss: 56.3823 - mean_absolute_error: 56.3823\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 794us/step - loss: 54.0955 - mean_absolute_error: 54.0955\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 808us/step - loss: 55.2087 - mean_absolute_error: 55.2087\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 873us/step - loss: 55.3240 - mean_absolute_error: 55.3240\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 816us/step - loss: 56.6603 - mean_absolute_error: 56.6603\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 814us/step - loss: 53.7736 - mean_absolute_error: 53.7736\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 962us/step - loss: 52.9966 - mean_absolute_error: 52.9966\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 820us/step - loss: 52.6912 - mean_absolute_error: 52.6912\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 814us/step - loss: 52.7949 - mean_absolute_error: 52.7949\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 806us/step - loss: 54.1383 - mean_absolute_error: 54.1383\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 800us/step - loss: 53.1061 - mean_absolute_error: 53.1061\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 809us/step - loss: 52.1249 - mean_absolute_error: 52.1249\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 778us/step - loss: 53.4532 - mean_absolute_error: 53.4532\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 831us/step - loss: 53.0559 - mean_absolute_error: 53.0559\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 803us/step - loss: 52.8168 - mean_absolute_error: 52.8168\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 819us/step - loss: 49.8818 - mean_absolute_error: 49.8818\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.6456 - mean_absolute_error: 50.6456\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 825us/step - loss: 51.1661 - mean_absolute_error: 51.1661\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 813us/step - loss: 49.8058 - mean_absolute_error: 49.8058\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 807us/step - loss: 51.8909 - mean_absolute_error: 51.8909\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 64.0974 - mean_absolute_error: 64.0974\n",
      "Loss: 64.09737396240234\n",
      "Mean Absolute Error: 64.09737396240234\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "# Test 2.  Add more neurons to each layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 100)               25600     \n_________________________________________________________________\ndense_4 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 30,701\nTrainable params: 30,701\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 179.9674 - mean_absolute_error: 179.9674\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 911us/step - loss: 85.5946 - mean_absolute_error: 85.5946\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 985us/step - loss: 75.7549 - mean_absolute_error: 75.7549\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 891us/step - loss: 71.3882 - mean_absolute_error: 71.3882\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 862us/step - loss: 70.4062 - mean_absolute_error: 70.4062\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 861us/step - loss: 66.6180 - mean_absolute_error: 66.6180\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 940us/step - loss: 63.7886 - mean_absolute_error: 63.7886\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 870us/step - loss: 63.7697 - mean_absolute_error: 63.7697\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 893us/step - loss: 61.5787 - mean_absolute_error: 61.5787\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 59.7613 - mean_absolute_error: 59.7613\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 888us/step - loss: 62.6317 - mean_absolute_error: 62.6317\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 855us/step - loss: 60.1784 - mean_absolute_error: 60.1784\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 862us/step - loss: 61.3306 - mean_absolute_error: 61.3306\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 858us/step - loss: 60.5654 - mean_absolute_error: 60.5654\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 840us/step - loss: 62.0018 - mean_absolute_error: 62.0018\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 834us/step - loss: 57.5402 - mean_absolute_error: 57.5402\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 944us/step - loss: 57.1631 - mean_absolute_error: 57.1631\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 848us/step - loss: 57.3784 - mean_absolute_error: 57.3784\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 869us/step - loss: 56.7739 - mean_absolute_error: 56.7739\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 55.3405 - mean_absolute_error: 55.3405\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 58.6934 - mean_absolute_error: 58.6934\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 960us/step - loss: 56.4569 - mean_absolute_error: 56.4569\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 899us/step - loss: 57.5324 - mean_absolute_error: 57.5324\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 876us/step - loss: 53.7822 - mean_absolute_error: 53.7822\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 922us/step - loss: 56.7427 - mean_absolute_error: 56.7427\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 945us/step - loss: 54.5955 - mean_absolute_error: 54.5955\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 826us/step - loss: 55.4516 - mean_absolute_error: 55.4516\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 886us/step - loss: 53.8716 - mean_absolute_error: 53.8716\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 868us/step - loss: 54.5730 - mean_absolute_error: 54.5730\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 868us/step - loss: 56.8659 - mean_absolute_error: 56.8659\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 860us/step - loss: 53.6981 - mean_absolute_error: 53.6981\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 931us/step - loss: 55.4345 - mean_absolute_error: 55.4345\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 866us/step - loss: 52.7255 - mean_absolute_error: 52.7255\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.8161 - mean_absolute_error: 53.8161\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.6206 - mean_absolute_error: 50.6206\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 55.4689 - mean_absolute_error: 55.4689\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.4880 - mean_absolute_error: 50.4880\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 958us/step - loss: 51.2747 - mean_absolute_error: 51.2747\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 905us/step - loss: 48.7420 - mean_absolute_error: 48.7420\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 928us/step - loss: 51.3850 - mean_absolute_error: 51.3850\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 907us/step - loss: 49.0115 - mean_absolute_error: 49.0115\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 823us/step - loss: 49.5578 - mean_absolute_error: 49.5578\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 822us/step - loss: 50.2220 - mean_absolute_error: 50.2220\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 889us/step - loss: 49.5965 - mean_absolute_error: 49.5965\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 930us/step - loss: 46.6542 - mean_absolute_error: 46.6542\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.4632 - mean_absolute_error: 49.4632\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 944us/step - loss: 47.4692 - mean_absolute_error: 47.4692\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 48.6588 - mean_absolute_error: 48.6588\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 990us/step - loss: 47.5316 - mean_absolute_error: 47.5316\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 937us/step - loss: 48.9394 - mean_absolute_error: 48.9394\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model2 = nn2.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 62.5939 - mean_absolute_error: 62.5939\n",
      "Loss: 62.5938835144043\n",
      "Mean Absolute Error: 62.5938835144043\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss2, model_accuracy2 = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss2}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy2}\")"
   ]
  },
  {
   "source": [
    "# Test 3:  Add an additional layer with 20 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 100)               25600     \n_________________________________________________________________\ndense_7 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_8 (Dense)              (None, 20)                1020      \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 21        \n=================================================================\nTotal params: 31,691\nTrainable params: 31,691\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 176.6241 - mean_absolute_error: 176.6241\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 81.9639 - mean_absolute_error: 81.9639\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 71.6587 - mean_absolute_error: 71.6587\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 972us/step - loss: 66.6524 - mean_absolute_error: 66.6524\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 66.1766 - mean_absolute_error: 66.1766\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 1000us/step - loss: 64.1335 - mean_absolute_error: 64.1335\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 66.8806 - mean_absolute_error: 66.8806\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 928us/step - loss: 67.2354 - mean_absolute_error: 67.2354\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 60.9564 - mean_absolute_error: 60.9564\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 974us/step - loss: 60.6094 - mean_absolute_error: 60.6094\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 938us/step - loss: 61.5240 - mean_absolute_error: 61.5240\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 925us/step - loss: 59.6094 - mean_absolute_error: 59.6094\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 57.4322 - mean_absolute_error: 57.4322\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 962us/step - loss: 56.7895 - mean_absolute_error: 56.7895\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 56.2404 - mean_absolute_error: 56.2404\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 940us/step - loss: 56.9094 - mean_absolute_error: 56.9094\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 965us/step - loss: 52.0701 - mean_absolute_error: 52.0701\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 992us/step - loss: 52.1999 - mean_absolute_error: 52.1999\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 982us/step - loss: 54.0584 - mean_absolute_error: 54.0584\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 936us/step - loss: 55.1399 - mean_absolute_error: 55.1399\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.8714 - mean_absolute_error: 53.8714\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 958us/step - loss: 52.0868 - mean_absolute_error: 52.0868\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 922us/step - loss: 50.8248 - mean_absolute_error: 50.8248\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.9993 - mean_absolute_error: 50.9993\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 953us/step - loss: 51.5152 - mean_absolute_error: 51.5152\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 929us/step - loss: 47.5822 - mean_absolute_error: 47.5822\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 950us/step - loss: 49.6475 - mean_absolute_error: 49.6475\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 934us/step - loss: 49.6496 - mean_absolute_error: 49.6496\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 898us/step - loss: 51.1369 - mean_absolute_error: 51.1369\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 994us/step - loss: 48.0636 - mean_absolute_error: 48.0636\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 940us/step - loss: 47.5230 - mean_absolute_error: 47.5230\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 917us/step - loss: 48.3459 - mean_absolute_error: 48.3459\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.0980 - mean_absolute_error: 49.0980\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 978us/step - loss: 47.0532 - mean_absolute_error: 47.0532\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 45.7540 - mean_absolute_error: 45.7540\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 961us/step - loss: 45.8674 - mean_absolute_error: 45.8674\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 933us/step - loss: 45.9294 - mean_absolute_error: 45.9294\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 935us/step - loss: 46.7676 - mean_absolute_error: 46.7676\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 970us/step - loss: 44.2055 - mean_absolute_error: 44.2055\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 976us/step - loss: 43.1858 - mean_absolute_error: 43.1858\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 43.0010 - mean_absolute_error: 43.0010\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 982us/step - loss: 42.0461 - mean_absolute_error: 42.0461\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 950us/step - loss: 42.4406 - mean_absolute_error: 42.4406\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 899us/step - loss: 40.3407 - mean_absolute_error: 40.3407\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 919us/step - loss: 41.3781 - mean_absolute_error: 41.3781\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 925us/step - loss: 41.4913 - mean_absolute_error: 41.4913\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 41.0908 - mean_absolute_error: 41.0908\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 927us/step - loss: 39.5165 - mean_absolute_error: 39.5165\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 932us/step - loss: 39.8663 - mean_absolute_error: 39.8663\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 39.4997 - mean_absolute_error: 39.4997\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn3.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model3 = nn3.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 62.3583 - mean_absolute_error: 62.3583\n",
      "Loss: 62.358253479003906\n",
      "Mean Absolute Error: 62.358253479003906\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss3, model_accuracy3 = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss3}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy3}\")"
   ]
  },
  {
   "source": [
    "# Test 4:  Add 50 neurons to the first layer and a 4th layer with 10 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_10 (Dense)             (None, 150)               38400     \n_________________________________________________________________\ndense_11 (Dense)             (None, 50)                7550      \n_________________________________________________________________\ndense_12 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_13 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_14 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 47,191\nTrainable params: 47,191\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 150\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn4.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 1s 1ms/step - loss: 180.2736 - mean_absolute_error: 180.2736\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 82.1567 - mean_absolute_error: 82.1567\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 72.6155 - mean_absolute_error: 72.6155\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 71.0339 - mean_absolute_error: 71.0339\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 68.7225 - mean_absolute_error: 68.7225\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 67.6376 - mean_absolute_error: 67.6376\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 63.3419 - mean_absolute_error: 63.3419\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 61.9617 - mean_absolute_error: 61.9617\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 61.2553 - mean_absolute_error: 61.2553\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 60.8569 - mean_absolute_error: 60.8569\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.2638 - mean_absolute_error: 62.2638\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 57.8897 - mean_absolute_error: 57.8897\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 56.0427 - mean_absolute_error: 56.0427\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 56.7062 - mean_absolute_error: 56.7062\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 59.0224 - mean_absolute_error: 59.0224\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.5498 - mean_absolute_error: 53.5498\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 57.3810 - mean_absolute_error: 57.3810\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 52.8553 - mean_absolute_error: 52.8553\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 57.8862 - mean_absolute_error: 57.8862\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.5766 - mean_absolute_error: 53.5766\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 54.1124 - mean_absolute_error: 54.1124\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.9641 - mean_absolute_error: 49.9641\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.7204 - mean_absolute_error: 50.7204\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 52.1882 - mean_absolute_error: 52.1882\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.2549 - mean_absolute_error: 50.2549\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 48.6853 - mean_absolute_error: 48.6853\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.8528 - mean_absolute_error: 49.8528\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 46.9036 - mean_absolute_error: 46.9036\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 961us/step - loss: 47.5944 - mean_absolute_error: 47.5944\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 46.9070 - mean_absolute_error: 46.9070\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 48.2305 - mean_absolute_error: 48.2305\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 46.7976 - mean_absolute_error: 46.7976\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 990us/step - loss: 44.5169 - mean_absolute_error: 44.5169\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 47.8231 - mean_absolute_error: 47.8231\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 43.5130 - mean_absolute_error: 43.5130\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 989us/step - loss: 42.7157 - mean_absolute_error: 42.7157\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 989us/step - loss: 41.8369 - mean_absolute_error: 41.8369\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 41.0023 - mean_absolute_error: 41.0023\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 43.4938 - mean_absolute_error: 43.4938\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 42.4955 - mean_absolute_error: 42.4955\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 39.8171 - mean_absolute_error: 39.8171\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 39.5994 - mean_absolute_error: 39.5994\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 41.1232 - mean_absolute_error: 41.1232\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 39.7107 - mean_absolute_error: 39.7107\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 37.2357 - mean_absolute_error: 37.2357\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 38.6412 - mean_absolute_error: 38.6412\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 36.9053 - mean_absolute_error: 36.9053\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 36.8355 - mean_absolute_error: 36.8355\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 989us/step - loss: 36.8333 - mean_absolute_error: 36.8333\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 980us/step - loss: 35.7620 - mean_absolute_error: 35.7620\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn4.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model4 = nn4.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 63.1860 - mean_absolute_error: 63.1860\n",
      "Loss: 63.18601608276367\n",
      "Mean Absolute Error: 63.18601608276367\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss4, model_accuracy4 = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss4}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy4}\")"
   ]
  },
  {
   "source": [
    "# Test 5:  Add 50 more neurons to the first layer and add a 5th layer with just 5 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_15 (Dense)             (None, 200)               51200     \n_________________________________________________________________\ndense_16 (Dense)             (None, 50)                10050     \n_________________________________________________________________\ndense_17 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_19 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_20 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 62,541\nTrainable params: 62,541\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 200\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 1s 1ms/step - loss: 193.7341 - mean_absolute_error: 193.7341\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 85.6380 - mean_absolute_error: 85.6380\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 75.8783 - mean_absolute_error: 75.8783\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 70.6532 - mean_absolute_error: 70.6532\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 66.0273 - mean_absolute_error: 66.0273\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 66.9521 - mean_absolute_error: 66.9521\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 65.7451 - mean_absolute_error: 65.7451\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.2516 - mean_absolute_error: 62.2516\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 64.1361 - mean_absolute_error: 64.1361\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 59.9705 - mean_absolute_error: 59.9705\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 58.7303 - mean_absolute_error: 58.7303\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.3725 - mean_absolute_error: 62.3725\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 62.8713 - mean_absolute_error: 62.8713\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 58.5181 - mean_absolute_error: 58.5181\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 57.4028 - mean_absolute_error: 57.4028\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 57.4035 - mean_absolute_error: 57.4035\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 55.3156 - mean_absolute_error: 55.3156\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 56.9407 - mean_absolute_error: 56.9407\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 54.1879 - mean_absolute_error: 54.1879\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 56.7784 - mean_absolute_error: 56.7784\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 56.2131 - mean_absolute_error: 56.2131\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.7974 - mean_absolute_error: 53.7974\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.4551 - mean_absolute_error: 53.4551\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.3635 - mean_absolute_error: 50.3635\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.2031 - mean_absolute_error: 50.2031\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.3218 - mean_absolute_error: 53.3218\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 48.3696 - mean_absolute_error: 48.3696\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 53.8687 - mean_absolute_error: 53.8687\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.7267 - mean_absolute_error: 49.7267\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 48.5145 - mean_absolute_error: 48.5145\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.9129 - mean_absolute_error: 49.9129\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 47.2882 - mean_absolute_error: 47.2882\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 47.3370 - mean_absolute_error: 47.3370\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 47.4055 - mean_absolute_error: 47.4055\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 49.0414 - mean_absolute_error: 49.0414\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 42.7600 - mean_absolute_error: 42.7600\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 45.7994 - mean_absolute_error: 45.7994\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 44.7563 - mean_absolute_error: 44.7563\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 43.7079 - mean_absolute_error: 43.7079\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 46.1762 - mean_absolute_error: 46.1762\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 43.9535 - mean_absolute_error: 43.9535\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 41.5303 - mean_absolute_error: 41.5303\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 38.6680 - mean_absolute_error: 38.6680\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 40.3652 - mean_absolute_error: 40.3652\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 39.3784 - mean_absolute_error: 39.3784\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 39.8114 - mean_absolute_error: 39.8114\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 40.4295 - mean_absolute_error: 40.4295\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 38.7292 - mean_absolute_error: 38.7292\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 37.1753 - mean_absolute_error: 37.1753\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 35.7117 - mean_absolute_error: 35.7117\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn5.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model5 = nn5.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 63.3892 - mean_absolute_error: 63.3892\n",
      "Loss: 63.38916778564453\n",
      "Mean Absolute Error: 63.38916778564453\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss5, model_accuracy5 = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss5}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy5}\")"
   ]
  },
  {
   "source": [
    "# Test 6:  Add 150 neurons to first layer and change second activation function to tanh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_21 (Dense)             (None, 350)               89600     \n_________________________________________________________________\ndense_22 (Dense)             (None, 50)                17550     \n_________________________________________________________________\ndense_23 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_24 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_25 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_26 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 108,441\nTrainable params: 108,441\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 350\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 1s 1ms/step - loss: 200.1604 - mean_absolute_error: 200.1604\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 141.5072 - mean_absolute_error: 141.5072\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 99.2916 - mean_absolute_error: 99.2916\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 76.8852 - mean_absolute_error: 76.8852\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 64.6838 - mean_absolute_error: 64.6838\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 61.4869 - mean_absolute_error: 61.4869\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 54.6593 - mean_absolute_error: 54.6593\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 52.4966 - mean_absolute_error: 52.4966\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 50.1934 - mean_absolute_error: 50.1934\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 46.6400 - mean_absolute_error: 46.6400\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 43.2666 - mean_absolute_error: 43.2666\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 40.5931 - mean_absolute_error: 40.5931\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 38.0170 - mean_absolute_error: 38.0170\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 36.5757 - mean_absolute_error: 36.5757\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 33.1214 - mean_absolute_error: 33.1214\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 30.6709 - mean_absolute_error: 30.6709\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 30.5548 - mean_absolute_error: 30.5548\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 29.2236 - mean_absolute_error: 29.2236\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 26.1529 - mean_absolute_error: 26.1529\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 26.0742 - mean_absolute_error: 26.0742\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 26.1893 - mean_absolute_error: 26.1893\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 25.5585 - mean_absolute_error: 25.5585\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 24.5872 - mean_absolute_error: 24.5872\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 23.5336 - mean_absolute_error: 23.5336\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 22.8623 - mean_absolute_error: 22.8623\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 21.5755 - mean_absolute_error: 21.5755\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 20.8300 - mean_absolute_error: 20.8300\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 20.4838 - mean_absolute_error: 20.4838\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 19.1706 - mean_absolute_error: 19.1706\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 20.1166 - mean_absolute_error: 20.1166\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 19.7696 - mean_absolute_error: 19.7696\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18.0008 - mean_absolute_error: 18.0008\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18.6312 - mean_absolute_error: 18.6312\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 17.5339 - mean_absolute_error: 17.5339\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 17.5212 - mean_absolute_error: 17.5212\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 16.7435 - mean_absolute_error: 16.7435\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 16.0793 - mean_absolute_error: 16.0793\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 15.9248 - mean_absolute_error: 15.9248\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 15.4793 - mean_absolute_error: 15.4793\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 16.1497 - mean_absolute_error: 16.1497\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 15.2430 - mean_absolute_error: 15.2430\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 15.0628 - mean_absolute_error: 15.0628\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 14.3722 - mean_absolute_error: 14.3722\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 13.9832 - mean_absolute_error: 13.9832\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 12.8634 - mean_absolute_error: 12.8634\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 14.0798 - mean_absolute_error: 14.0798\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 12.5861 - mean_absolute_error: 12.5861\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 13.7600 - mean_absolute_error: 13.7600\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 12.9976 - mean_absolute_error: 12.9976\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 12.0419 - mean_absolute_error: 12.0419\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn6.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model6 = nn6.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "116/116 - 0s - loss: 12.4532 - mean_absolute_error: 12.4532\n",
      "Loss: 12.45322036743164\n",
      "Mean Absolute Error: 12.45322036743164\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss6, model_accuracy6 = nn6.evaluate(X_train_scaled,y_train,verbose=2)\n",
    "print(f\"Loss: {model_loss6}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "39/39 - 0s - loss: 61.0384 - mean_absolute_error: 61.0384\n",
      "Loss: 61.03842544555664\n",
      "Mean Absolute Error: 61.03842544555664\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss6, model_accuracy6 = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss6}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy6}\")"
   ]
  },
  {
   "source": [
    "# After lots of tests, our best Mean Squared Error Result is off, on average, by about $61.04 (according to the MAE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
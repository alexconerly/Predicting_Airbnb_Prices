{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythondata",
   "display_name": "PythonData",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Here we'll do a baseline test on 6 Neural Network model variations on the cleaned data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PostGres Download Duration: 1.9971599578857422 seconds\n"
     ]
    }
   ],
   "source": [
    "# Download raw data from postgres for stage 1 ETL\n",
    "\n",
    "conn_string = 'postgres://whnpmxwsiccrtg:53c453893549d2b1e6a4ff92e626a2a08ebcaff66678e50d33e3742f66e3e4f4@ec2-52-4-171-132.compute-1.amazonaws.com/d2ajro4cjr10lb'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "start_time = time.time()\n",
    "df = pd.read_sql_query('select * from \"merged_no_cal\"',con=conn)\n",
    "print(\"PostGres Download Duration: {} seconds\".format(time.time() - start_time))\n",
    "conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5242, 257)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   host_is_superhost  host_listings_count  host_identity_verified  \\\n",
       "0                  1             0.000000                       1   \n",
       "1                  1             0.693147                       0   \n",
       "2                  1             0.000000                       1   \n",
       "3                  0             0.000000                       0   \n",
       "4                  1             0.693147                       1   \n",
       "\n",
       "   accommodates  bathrooms  bedrooms  price  security_deposit  cleaning_fee  \\\n",
       "0             2        1.0         2   40.0               0.0           0.0   \n",
       "1             2        1.0         1   65.0               0.0          25.0   \n",
       "2             2        1.0         1   93.0               0.0           0.0   \n",
       "3             2        1.0         1  105.0             200.0           0.0   \n",
       "4             2        1.0         1   55.0               0.0           0.0   \n",
       "\n",
       "   guests_included  ...  bed_type_Futon  bed_type_Pull-out Sofa  \\\n",
       "0                1  ...             0.0                     0.0   \n",
       "1                1  ...             0.0                     0.0   \n",
       "2                1  ...             0.0                     0.0   \n",
       "3                1  ...             0.0                     0.0   \n",
       "4                1  ...             0.0                     0.0   \n",
       "\n",
       "   bed_type_Real Bed  cancellation_policy_flexible  \\\n",
       "0                1.0                           0.0   \n",
       "1                1.0                           0.0   \n",
       "2                1.0                           0.0   \n",
       "3                1.0                           0.0   \n",
       "4                1.0                           0.0   \n",
       "\n",
       "   cancellation_policy_moderate  cancellation_policy_strict  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           1.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           1.0                         0.0   \n",
       "\n",
       "   cancellation_policy_strict_14_with_grace_period  \\\n",
       "0                                              1.0   \n",
       "1                                              1.0   \n",
       "2                                              0.0   \n",
       "3                                              1.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   cancellation_policy_super_strict_30  cancellation_policy_super_strict_60  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "\n",
       "   baths_logs  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host_is_superhost</th>\n      <th>host_listings_count</th>\n      <th>host_identity_verified</th>\n      <th>accommodates</th>\n      <th>bathrooms</th>\n      <th>bedrooms</th>\n      <th>price</th>\n      <th>security_deposit</th>\n      <th>cleaning_fee</th>\n      <th>guests_included</th>\n      <th>...</th>\n      <th>bed_type_Futon</th>\n      <th>bed_type_Pull-out Sofa</th>\n      <th>bed_type_Real Bed</th>\n      <th>cancellation_policy_flexible</th>\n      <th>cancellation_policy_moderate</th>\n      <th>cancellation_policy_strict</th>\n      <th>cancellation_policy_strict_14_with_grace_period</th>\n      <th>cancellation_policy_super_strict_30</th>\n      <th>cancellation_policy_super_strict_60</th>\n      <th>baths_logs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.693147</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>65.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>93.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>105.0</td>\n      <td>200.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0.693147</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>55.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 257 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"price\"].values\n",
    "X = df.drop(\"price\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['host_is_superhost', 'host_listings_count', 'host_identity_verified',\n",
       "       'accommodates', 'bathrooms', 'bedrooms', 'price', 'security_deposit',\n",
       "       'cleaning_fee', 'guests_included',\n",
       "       ...\n",
       "       'bed_type_Futon', 'bed_type_Pull-out Sofa', 'bed_type_Real Bed',\n",
       "       'cancellation_policy_flexible', 'cancellation_policy_moderate',\n",
       "       'cancellation_policy_strict',\n",
       "       'cancellation_policy_strict_14_with_grace_period',\n",
       "       'cancellation_policy_super_strict_30',\n",
       "       'cancellation_policy_super_strict_60', 'baths_logs'],\n",
       "      dtype='object', length=257)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = RobustScaler()\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "source": [
    "# Test 1: Use one input layer and one hidden layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 80)                20560     \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                2430      \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 31        \n=================================================================\nTotal params: 23,021\nTrainable params: 23,021\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 213.7691 - mean_absolute_error: 213.7691\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 113.7109 - mean_absolute_error: 113.7109\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 94.4731 - mean_absolute_error: 94.4731\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 89.2472 - mean_absolute_error: 89.2472\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 89.3103 - mean_absolute_error: 89.3103\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 83.8577 - mean_absolute_error: 83.8577\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 87.9479 - mean_absolute_error: 87.9479\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 82.5225 - mean_absolute_error: 82.5225\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 79.9607 - mean_absolute_error: 79.9607\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 77.1372 - mean_absolute_error: 77.1372\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 77.1603 - mean_absolute_error: 77.1603\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 74.1736 - mean_absolute_error: 74.1736\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 70.6879 - mean_absolute_error: 70.6879\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 72.1830 - mean_absolute_error: 72.1830\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 69.6877 - mean_absolute_error: 69.6877\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 67.5566 - mean_absolute_error: 67.5566\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 66.6378 - mean_absolute_error: 66.6378\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 67.3454 - mean_absolute_error: 67.3454\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 63.8295 - mean_absolute_error: 63.8295\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 62.5092 - mean_absolute_error: 62.5092\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 65.6688 - mean_absolute_error: 65.6688\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 68.5118 - mean_absolute_error: 68.5118\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 64.1467 - mean_absolute_error: 64.1467\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 66.7122 - mean_absolute_error: 66.7122\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 62.3460 - mean_absolute_error: 62.3460\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 64.1340 - mean_absolute_error: 64.1340\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 62.0038 - mean_absolute_error: 62.0038\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 63.3316 - mean_absolute_error: 63.3316\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.4204 - mean_absolute_error: 60.4204\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 58.8264 - mean_absolute_error: 58.8264\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.5664 - mean_absolute_error: 57.5664\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.4890 - mean_absolute_error: 58.4890\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.6370 - mean_absolute_error: 58.6370\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.3405 - mean_absolute_error: 60.3405\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 59.4357 - mean_absolute_error: 59.4357\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.7732 - mean_absolute_error: 60.7732\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 56.4271 - mean_absolute_error: 56.4271\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.4309 - mean_absolute_error: 57.4309\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.5426 - mean_absolute_error: 57.5426\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.4589 - mean_absolute_error: 57.4589\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.4107 - mean_absolute_error: 55.4107\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 56.9873 - mean_absolute_error: 56.9873\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.3258 - mean_absolute_error: 57.3258\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.2150 - mean_absolute_error: 55.2150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 56.9367 - mean_absolute_error: 56.9367\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 53.8360 - mean_absolute_error: 53.8360\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.1787 - mean_absolute_error: 55.1787\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.8784 - mean_absolute_error: 55.8784\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 53.7661 - mean_absolute_error: 53.7661\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 54.2636 - mean_absolute_error: 54.2636\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41/41 - 0s - loss: 62.9081 - mean_absolute_error: 62.9081\n",
      "Loss: 62.908138275146484\n",
      "Mean Absolute Error: 62.908138275146484\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "# Test 2.  Add more neurons to each layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 100)               25700     \n_________________________________________________________________\ndense_4 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 30,801\nTrainable params: 30,801\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 204.3584 - mean_absolute_error: 204.3584\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 99.9447 - mean_absolute_error: 99.9447\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 93.6563 - mean_absolute_error: 93.6563\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 85.8535 - mean_absolute_error: 85.8535\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 85.3779 - mean_absolute_error: 85.3779\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 82.5940 - mean_absolute_error: 82.5940\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 82.2020 - mean_absolute_error: 82.2020\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 80.4297 - mean_absolute_error: 80.4297\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 77.3568 - mean_absolute_error: 77.3568\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 77.0586 - mean_absolute_error: 77.0586\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 77.6963 - mean_absolute_error: 77.6963\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 72.8236 - mean_absolute_error: 72.8236\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 70.4866 - mean_absolute_error: 70.4866\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 67.0280 - mean_absolute_error: 67.0280\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 65.7922 - mean_absolute_error: 65.7922\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 67.3529 - mean_absolute_error: 67.3529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 66.0554 - mean_absolute_error: 66.0554\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 64.9093 - mean_absolute_error: 64.9093\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 62.4120 - mean_absolute_error: 62.4120\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 62.6590 - mean_absolute_error: 62.6590\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 61.0293 - mean_absolute_error: 61.0293\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 64.8243 - mean_absolute_error: 64.8243\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 61.4578 - mean_absolute_error: 61.4578\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.0274 - mean_absolute_error: 60.0274\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 59.5523 - mean_absolute_error: 59.5523\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 63.0519 - mean_absolute_error: 63.0519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.4777 - mean_absolute_error: 58.4777\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.6485 - mean_absolute_error: 60.6485\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.8231 - mean_absolute_error: 57.8231\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.1345 - mean_absolute_error: 58.1345\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.9597 - mean_absolute_error: 60.9597\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.2524 - mean_absolute_error: 58.2524\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 58.4512 - mean_absolute_error: 58.4512\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 55.3049 - mean_absolute_error: 55.3049\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.0301 - mean_absolute_error: 58.0301\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.9323 - mean_absolute_error: 55.9323\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.8729 - mean_absolute_error: 55.8729\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 56.9474 - mean_absolute_error: 56.9474\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 56.0701 - mean_absolute_error: 56.0701\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 52.3205 - mean_absolute_error: 52.3205\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 54.5062 - mean_absolute_error: 54.5062\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 52.1822 - mean_absolute_error: 52.1822\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 51.6107 - mean_absolute_error: 51.6107\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 53.9792 - mean_absolute_error: 53.9792\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 54.2283 - mean_absolute_error: 54.2283\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 51.4098 - mean_absolute_error: 51.4098\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 51.5886 - mean_absolute_error: 51.5886\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.0889 - mean_absolute_error: 49.0889\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 51.9844 - mean_absolute_error: 51.9844\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.0611 - mean_absolute_error: 49.0611\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model2 = nn2.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41/41 - 0s - loss: 62.9004 - mean_absolute_error: 62.9004\n",
      "Loss: 62.9003791809082\n",
      "Mean Absolute Error: 62.9003791809082\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss2, model_accuracy2 = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss2}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy2}\")"
   ]
  },
  {
   "source": [
    "# Test 3:  Add an additional layer with 20 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 100)               25700     \n_________________________________________________________________\ndense_7 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_8 (Dense)              (None, 20)                1020      \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 21        \n=================================================================\nTotal params: 31,791\nTrainable params: 31,791\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 202.2847 - mean_absolute_error: 202.2847\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 98.2014 - mean_absolute_error: 98.2014\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 90.5785 - mean_absolute_error: 90.5785\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 85.1767 - mean_absolute_error: 85.1767\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 82.3409 - mean_absolute_error: 82.3409\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 79.8369 - mean_absolute_error: 79.8369\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 74.0322 - mean_absolute_error: 74.0322\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 70.6082 - mean_absolute_error: 70.6082\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 64.3354 - mean_absolute_error: 64.3354\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 62.9027 - mean_absolute_error: 62.9027\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 66.3735 - mean_absolute_error: 66.3735\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 64.1969 - mean_absolute_error: 64.1969\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 64.1494 - mean_absolute_error: 64.1494\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 63.4779 - mean_absolute_error: 63.4779\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 63.2678 - mean_absolute_error: 63.2678\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.6324 - mean_absolute_error: 60.6324\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.6521 - mean_absolute_error: 58.6521\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.0591 - mean_absolute_error: 58.0591\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 59.0983 - mean_absolute_error: 59.0983\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 59.9825 - mean_absolute_error: 59.9825\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.1576 - mean_absolute_error: 55.1576\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.6896 - mean_absolute_error: 55.6896\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 56.0765 - mean_absolute_error: 56.0765\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 53.5405 - mean_absolute_error: 53.5405\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.0121 - mean_absolute_error: 55.0121\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 53.2397 - mean_absolute_error: 53.2397\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 54.5506 - mean_absolute_error: 54.5506\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 54.9995 - mean_absolute_error: 54.9995\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 50.4820 - mean_absolute_error: 50.4820\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 53.5696 - mean_absolute_error: 53.5696\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.5612 - mean_absolute_error: 49.5612\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 48.9687 - mean_absolute_error: 48.9687\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.6840 - mean_absolute_error: 49.6840\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 45.5471 - mean_absolute_error: 45.5471\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.2744 - mean_absolute_error: 49.2744\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 47.3270 - mean_absolute_error: 47.3270\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 44.9566 - mean_absolute_error: 44.9566\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 46.5840 - mean_absolute_error: 46.5840\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 46.0666 - mean_absolute_error: 46.0666\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 45.6800 - mean_absolute_error: 45.6800\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 42.1073 - mean_absolute_error: 42.1073\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 45.8660 - mean_absolute_error: 45.8660\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 40.3915 - mean_absolute_error: 40.3915\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 39.7467 - mean_absolute_error: 39.7467\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 40.4301 - mean_absolute_error: 40.4301\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 39.8949 - mean_absolute_error: 39.8949\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 38.6716 - mean_absolute_error: 38.6716\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 37.5121 - mean_absolute_error: 37.5121\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 39.5189 - mean_absolute_error: 39.5189\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 38.5750 - mean_absolute_error: 38.5750\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn3.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model3 = nn3.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41/41 - 0s - loss: 62.9132 - mean_absolute_error: 62.9132\n",
      "Loss: 62.913211822509766\n",
      "Mean Absolute Error: 62.913211822509766\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss3, model_accuracy3 = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss3}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy3}\")"
   ]
  },
  {
   "source": [
    "# Test 4:  Add 50 neurons to the first layer and a 4th layer with 10 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_10 (Dense)             (None, 150)               38550     \n_________________________________________________________________\ndense_11 (Dense)             (None, 50)                7550      \n_________________________________________________________________\ndense_12 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_13 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_14 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 47,341\nTrainable params: 47,341\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 150\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn4.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 212.6248 - mean_absolute_error: 212.6248\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 103.2936 - mean_absolute_error: 103.2936\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 95.8309 - mean_absolute_error: 95.8309\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 89.5824 - mean_absolute_error: 89.5824\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 81.1621 - mean_absolute_error: 81.1621\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 83.1795 - mean_absolute_error: 83.1795\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 75.7787 - mean_absolute_error: 75.7787\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 72.1810 - mean_absolute_error: 72.1810\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 65.7320 - mean_absolute_error: 65.7320\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 66.0951 - mean_absolute_error: 66.0951\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 67.8776 - mean_absolute_error: 67.8776\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 64.1187 - mean_absolute_error: 64.1187\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 62.5436 - mean_absolute_error: 62.5436\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 66.3653 - mean_absolute_error: 66.3653\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.0600 - mean_absolute_error: 60.0600\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.4146 - mean_absolute_error: 57.4146\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 59.8939 - mean_absolute_error: 59.8939\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.6258 - mean_absolute_error: 60.6258\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 59.8074 - mean_absolute_error: 59.8074\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.6853 - mean_absolute_error: 58.6853\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.9223 - mean_absolute_error: 55.9223\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 56.5364 - mean_absolute_error: 56.5364\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.4654 - mean_absolute_error: 57.4654\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.0194 - mean_absolute_error: 55.0194\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 51.7195 - mean_absolute_error: 51.7195\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 55.0933 - mean_absolute_error: 55.0933\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 53.1717 - mean_absolute_error: 53.1717\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 51.0318 - mean_absolute_error: 51.0318\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 51.9013 - mean_absolute_error: 51.9013\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.8422 - mean_absolute_error: 49.8422\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 48.3026 - mean_absolute_error: 48.3026\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.4171 - mean_absolute_error: 49.4171\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 48.8746 - mean_absolute_error: 48.8746\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 46.4125 - mean_absolute_error: 46.4125\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 47.0930 - mean_absolute_error: 47.0930\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 42.9171 - mean_absolute_error: 42.9171\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 46.1363 - mean_absolute_error: 46.1363\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 42.0631 - mean_absolute_error: 42.0631\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 43.5412 - mean_absolute_error: 43.5412\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 41.8777 - mean_absolute_error: 41.8777\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 43.2430 - mean_absolute_error: 43.2430\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 45.8704 - mean_absolute_error: 45.8704\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 38.8861 - mean_absolute_error: 38.8861\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 42.0111 - mean_absolute_error: 42.0111\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 38.2286 - mean_absolute_error: 38.2286\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 36.7784 - mean_absolute_error: 36.7784\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 37.6809 - mean_absolute_error: 37.6809\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 37.6237 - mean_absolute_error: 37.6237\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 37.4598 - mean_absolute_error: 37.4598\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 35.4777 - mean_absolute_error: 35.4777\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn4.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model4 = nn4.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41/41 - 0s - loss: 65.0896 - mean_absolute_error: 65.0896\n",
      "Loss: 65.08956909179688\n",
      "Mean Absolute Error: 65.08956909179688\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss4, model_accuracy4 = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss4}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy4}\")"
   ]
  },
  {
   "source": [
    "# Test 5:  Add 50 more neurons to the first layer and add a 5th layer with just 5 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_15 (Dense)             (None, 200)               51400     \n_________________________________________________________________\ndense_16 (Dense)             (None, 50)                10050     \n_________________________________________________________________\ndense_17 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_19 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_20 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 62,741\nTrainable params: 62,741\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 200\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 216.2952 - mean_absolute_error: 216.2952\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 100.9685 - mean_absolute_error: 100.9685\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 94.5066 - mean_absolute_error: 94.5066\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 88.6352 - mean_absolute_error: 88.6352\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 87.2001 - mean_absolute_error: 87.2001\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 81.1338 - mean_absolute_error: 81.1338\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 74.9295 - mean_absolute_error: 74.9295\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 72.8776 - mean_absolute_error: 72.8776\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 67.5678 - mean_absolute_error: 67.5678\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 69.9182 - mean_absolute_error: 69.9182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 68.6581 - mean_absolute_error: 68.6581\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 66.8384 - mean_absolute_error: 66.8384\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.5961 - mean_absolute_error: 60.5961\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 60.9259 - mean_absolute_error: 60.9259\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.7774 - mean_absolute_error: 58.7774\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 59.5477 - mean_absolute_error: 59.5477\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 59.7029 - mean_absolute_error: 59.7029\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 58.8495 - mean_absolute_error: 58.8495\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 56.8494 - mean_absolute_error: 56.8494\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 57.0935 - mean_absolute_error: 57.0935\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 54.4121 - mean_absolute_error: 54.4121\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 58.6525 - mean_absolute_error: 58.6525\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 55.7193 - mean_absolute_error: 55.7193\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 52.1333 - mean_absolute_error: 52.1333\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 53.0055 - mean_absolute_error: 53.0055\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 52.7652 - mean_absolute_error: 52.7652\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.9028 - mean_absolute_error: 49.9028\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 49.1435 - mean_absolute_error: 49.1435\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 49.5768 - mean_absolute_error: 49.5768\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 51.8227 - mean_absolute_error: 51.8227\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 47.2717 - mean_absolute_error: 47.2717\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 48.5070 - mean_absolute_error: 48.5070\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 45.3688 - mean_absolute_error: 45.3688\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 44.6825 - mean_absolute_error: 44.6825\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 44.2881 - mean_absolute_error: 44.2881\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 44.3219 - mean_absolute_error: 44.3219\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 43.2362 - mean_absolute_error: 43.2362\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 40.5050 - mean_absolute_error: 40.5050\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 41.0046 - mean_absolute_error: 41.0046\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 41.0198 - mean_absolute_error: 41.0198\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 40.7326 - mean_absolute_error: 40.7326\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 38.5438 - mean_absolute_error: 38.5438\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 39.3732 - mean_absolute_error: 39.3732\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 37.2022 - mean_absolute_error: 37.2022\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 36.5800 - mean_absolute_error: 36.5800\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 35.2774 - mean_absolute_error: 35.2774\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 35.9453 - mean_absolute_error: 35.9453\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 34.9651 - mean_absolute_error: 34.9651\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 32.5678 - mean_absolute_error: 32.5678\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 32.8005 - mean_absolute_error: 32.8005\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn5.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model5 = nn5.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41/41 - 0s - loss: 63.0521 - mean_absolute_error: 63.0521\n",
      "Loss: 63.05207824707031\n",
      "Mean Absolute Error: 63.05207824707031\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss5, model_accuracy5 = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss5}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy5}\")"
   ]
  },
  {
   "source": [
    "# Test 6:  Add 150 neurons to first layer and change second activation function to tanh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_21 (Dense)             (None, 350)               89950     \n_________________________________________________________________\ndense_22 (Dense)             (None, 50)                17550     \n_________________________________________________________________\ndense_23 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_24 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_25 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_26 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 108,791\nTrainable params: 108,791\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 350\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 223.2890 - mean_absolute_error: 223.2890\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 132.8565 - mean_absolute_error: 132.8565\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 105.8483 - mean_absolute_error: 105.8483\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 84.5553 - mean_absolute_error: 84.5553\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 75.4862 - mean_absolute_error: 75.4862\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 66.5942 - mean_absolute_error: 66.5942\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 57.6730 - mean_absolute_error: 57.6730\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 49.6496 - mean_absolute_error: 49.6496\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 44.5215 - mean_absolute_error: 44.5215\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 42.5351 - mean_absolute_error: 42.5351\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 37.4461 - mean_absolute_error: 37.4461\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 35.3831 - mean_absolute_error: 35.3831\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 34.1458 - mean_absolute_error: 34.1458\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 30.7870 - mean_absolute_error: 30.7870\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 31.3496 - mean_absolute_error: 31.3496\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 28.3531 - mean_absolute_error: 28.3531\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 27.8357 - mean_absolute_error: 27.8357\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 26.6482 - mean_absolute_error: 26.6482\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 24.1148 - mean_absolute_error: 24.1148\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 22.9005 - mean_absolute_error: 22.9005\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 22.6008 - mean_absolute_error: 22.6008\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 22.8623 - mean_absolute_error: 22.8623\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 22.2284 - mean_absolute_error: 22.2284\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 21.4094 - mean_absolute_error: 21.4094\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 20.2283 - mean_absolute_error: 20.2283\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 20.5078 - mean_absolute_error: 20.5078\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 18.8940 - mean_absolute_error: 18.8940\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 19.5886 - mean_absolute_error: 19.5886\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 17.8401 - mean_absolute_error: 17.8401\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 17.3780 - mean_absolute_error: 17.3780\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 18.6150 - mean_absolute_error: 18.6150\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 18.2938 - mean_absolute_error: 18.2938\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 17.2875 - mean_absolute_error: 17.2875\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 16.8931 - mean_absolute_error: 16.8931\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 15.9077 - mean_absolute_error: 15.9077\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 14.9116 - mean_absolute_error: 14.9116\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 17.3591 - mean_absolute_error: 17.3591\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 14.4742 - mean_absolute_error: 14.4742\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 14.3946 - mean_absolute_error: 14.3946\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 13.6674 - mean_absolute_error: 13.6674\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 15.2426 - mean_absolute_error: 15.2426\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 14.3957 - mean_absolute_error: 14.3957\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 15.2591 - mean_absolute_error: 15.2591\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 14.7528 - mean_absolute_error: 14.7528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 14.8733 - mean_absolute_error: 14.8733\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 13.1781 - mean_absolute_error: 13.1781\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 14.2912 - mean_absolute_error: 14.2912\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 13.8773 - mean_absolute_error: 13.8773\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 13.2687 - mean_absolute_error: 13.2687\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 13.0310 - mean_absolute_error: 13.0310\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn6.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model6 = nn6.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "123/123 - 0s - loss: 12.6459 - mean_absolute_error: 12.6459\n",
      "Loss: 12.645925521850586\n",
      "Mean Absolute Error: 12.645925521850586\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss6, model_accuracy6 = nn6.evaluate(X_train_scaled,y_train,verbose=2)\n",
    "print(f\"Loss: {model_loss6}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41/41 - 0s - loss: 59.2770 - mean_absolute_error: 59.2770\n",
      "Loss: 59.27701187133789\n",
      "Mean Absolute Error: 59.27701187133789\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss6, model_accuracy6 = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss6}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy6}\")"
   ]
  },
  {
   "source": [
    "# After lots of tests, our best Mean Squared Error Result is off, on average, by about $59.27 (according to the MAE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
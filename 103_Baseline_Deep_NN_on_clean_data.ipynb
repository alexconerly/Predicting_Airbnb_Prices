{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythondata",
   "display_name": "PythonData",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Here we'll do a baseline test on 6 Neural Network model variations on the cleaned data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PostGres Download Duration: 1.5710148811340332 seconds\n"
     ]
    }
   ],
   "source": [
    "# Download raw data from postgres for stage 1 ETL\n",
    "\n",
    "conn_string = 'postgres://whnpmxwsiccrtg:53c453893549d2b1e6a4ff92e626a2a08ebcaff66678e50d33e3742f66e3e4f4@ec2-52-4-171-132.compute-1.amazonaws.com/d2ajro4cjr10lb'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "start_time = time.time()\n",
    "df = pd.read_sql_query('select * from \"merged_no_cal\"',con=conn)\n",
    "print(\"PostGres Download Duration: {} seconds\".format(time.time() - start_time))\n",
    "conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5268, 258)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   host_is_superhost  host_listings_count  host_identity_verified  \\\n",
       "0                  1             0.000000                       1   \n",
       "1                  1             0.693147                       0   \n",
       "2                  1             0.000000                       1   \n",
       "3                  0             0.000000                       0   \n",
       "4                  1             0.693147                       1   \n",
       "\n",
       "   accommodates  bathrooms  bedrooms  price  security_deposit  cleaning_fee  \\\n",
       "0             2        1.0         2   40.0               0.0           0.0   \n",
       "1             2        1.0         1   65.0               0.0          25.0   \n",
       "2             2        1.0         1   93.0               0.0           0.0   \n",
       "3             2        1.0         1  105.0             200.0           0.0   \n",
       "4             2        1.0         1   55.0               0.0           0.0   \n",
       "\n",
       "   guests_included  ...  bed_type_Futon  bed_type_Pull-out Sofa  \\\n",
       "0                1  ...             0.0                     0.0   \n",
       "1                1  ...             0.0                     0.0   \n",
       "2                1  ...             0.0                     0.0   \n",
       "3                1  ...             0.0                     0.0   \n",
       "4                1  ...             0.0                     0.0   \n",
       "\n",
       "   bed_type_Real Bed  cancellation_policy_flexible  \\\n",
       "0                1.0                           0.0   \n",
       "1                1.0                           0.0   \n",
       "2                1.0                           0.0   \n",
       "3                1.0                           0.0   \n",
       "4                1.0                           0.0   \n",
       "\n",
       "   cancellation_policy_moderate  cancellation_policy_strict  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           1.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           1.0                         0.0   \n",
       "\n",
       "   cancellation_policy_strict_14_with_grace_period  \\\n",
       "0                                              1.0   \n",
       "1                                              1.0   \n",
       "2                                              0.0   \n",
       "3                                              1.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   cancellation_policy_super_strict_30  cancellation_policy_super_strict_60  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "\n",
       "   baths_logs  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 258 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host_is_superhost</th>\n      <th>host_listings_count</th>\n      <th>host_identity_verified</th>\n      <th>accommodates</th>\n      <th>bathrooms</th>\n      <th>bedrooms</th>\n      <th>price</th>\n      <th>security_deposit</th>\n      <th>cleaning_fee</th>\n      <th>guests_included</th>\n      <th>...</th>\n      <th>bed_type_Futon</th>\n      <th>bed_type_Pull-out Sofa</th>\n      <th>bed_type_Real Bed</th>\n      <th>cancellation_policy_flexible</th>\n      <th>cancellation_policy_moderate</th>\n      <th>cancellation_policy_strict</th>\n      <th>cancellation_policy_strict_14_with_grace_period</th>\n      <th>cancellation_policy_super_strict_30</th>\n      <th>cancellation_policy_super_strict_60</th>\n      <th>baths_logs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.693147</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>65.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>93.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>105.0</td>\n      <td>200.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0.693147</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>55.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 258 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"price\"].values\n",
    "X = df.drop(\"price\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['host_is_superhost', 'host_listings_count', 'host_identity_verified',\n",
       "       'accommodates', 'bathrooms', 'bedrooms', 'price', 'security_deposit',\n",
       "       'cleaning_fee', 'guests_included',\n",
       "       ...\n",
       "       'bed_type_Futon', 'bed_type_Pull-out Sofa', 'bed_type_Real Bed',\n",
       "       'cancellation_policy_flexible', 'cancellation_policy_moderate',\n",
       "       'cancellation_policy_strict',\n",
       "       'cancellation_policy_strict_14_with_grace_period',\n",
       "       'cancellation_policy_super_strict_30',\n",
       "       'cancellation_policy_super_strict_60', 'baths_logs'],\n",
       "      dtype='object', length=258)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = RobustScaler()\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "source": [
    "# Test 1: Use one input layer and one hidden layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 80)                20640     \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                2430      \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 31        \n=================================================================\nTotal params: 23,101\nTrainable params: 23,101\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 0s 922us/step - loss: 206.3746 - mean_absolute_error: 206.3746\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 859us/step - loss: 104.0475 - mean_absolute_error: 104.0475\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 828us/step - loss: 101.6185 - mean_absolute_error: 101.6185\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 900us/step - loss: 94.6199 - mean_absolute_error: 94.6199\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 933us/step - loss: 90.8654 - mean_absolute_error: 90.8654\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 84.2660 - mean_absolute_error: 84.2660\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 929us/step - loss: 83.2183 - mean_absolute_error: 83.2183\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 860us/step - loss: 88.6492 - mean_absolute_error: 88.6492\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 994us/step - loss: 78.8829 - mean_absolute_error: 78.8829\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 808us/step - loss: 77.1028 - mean_absolute_error: 77.1028\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 812us/step - loss: 78.9806 - mean_absolute_error: 78.9806\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 800us/step - loss: 78.0609 - mean_absolute_error: 78.0609\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 939us/step - loss: 72.4749 - mean_absolute_error: 72.4749\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 861us/step - loss: 71.6434 - mean_absolute_error: 71.6434\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 842us/step - loss: 72.3307 - mean_absolute_error: 72.3307\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 940us/step - loss: 71.8332 - mean_absolute_error: 71.8332\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 823us/step - loss: 65.7957 - mean_absolute_error: 65.7957\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 861us/step - loss: 69.7037 - mean_absolute_error: 69.7037\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 797us/step - loss: 63.8961 - mean_absolute_error: 63.8961\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 766us/step - loss: 66.8147 - mean_absolute_error: 66.8147\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 780us/step - loss: 61.7341 - mean_absolute_error: 61.7341\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 845us/step - loss: 65.6137 - mean_absolute_error: 65.6137\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 802us/step - loss: 62.4077 - mean_absolute_error: 62.4077\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 827us/step - loss: 61.5424 - mean_absolute_error: 61.5424\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 935us/step - loss: 60.4430 - mean_absolute_error: 60.4430\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 804us/step - loss: 60.8788 - mean_absolute_error: 60.8788\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 854us/step - loss: 67.7526 - mean_absolute_error: 67.7526\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 813us/step - loss: 58.7787 - mean_absolute_error: 58.7787\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 790us/step - loss: 58.9337 - mean_absolute_error: 58.9337\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 797us/step - loss: 61.5359 - mean_absolute_error: 61.5359\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 828us/step - loss: 57.9115 - mean_absolute_error: 57.9115\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 862us/step - loss: 57.2545 - mean_absolute_error: 57.2545\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 925us/step - loss: 58.6197 - mean_absolute_error: 58.6197\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 890us/step - loss: 58.1581 - mean_absolute_error: 58.1581\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 795us/step - loss: 59.0479 - mean_absolute_error: 59.0479\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 772us/step - loss: 56.5978 - mean_absolute_error: 56.5978\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 766us/step - loss: 55.2688 - mean_absolute_error: 55.2688\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 767us/step - loss: 56.9666 - mean_absolute_error: 56.9666\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 794us/step - loss: 56.7761 - mean_absolute_error: 56.7761\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 777us/step - loss: 56.7940 - mean_absolute_error: 56.7940\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 861us/step - loss: 56.2173 - mean_absolute_error: 56.2173\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 977us/step - loss: 54.8863 - mean_absolute_error: 54.8863\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 55.7440 - mean_absolute_error: 55.7440\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 932us/step - loss: 53.5872 - mean_absolute_error: 53.5872\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 56.4754 - mean_absolute_error: 56.4754\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 53.6294 - mean_absolute_error: 53.6294\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 54.8663 - mean_absolute_error: 54.8663\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 937us/step - loss: 54.1259 - mean_absolute_error: 54.1259\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 979us/step - loss: 51.8011 - mean_absolute_error: 51.8011\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 896us/step - loss: 54.1436 - mean_absolute_error: 54.1436\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42/42 - 0s - loss: 70.3243 - mean_absolute_error: 70.3243\n",
      "Loss: 70.32430267333984\n",
      "Mean Absolute Error: 70.32430267333984\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "# Test 2.  Add more neurons to each layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 100)               25800     \n_________________________________________________________________\ndense_4 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 30,901\nTrainable params: 30,901\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 0s 873us/step - loss: 199.9449 - mean_absolute_error: 199.9449\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 924us/step - loss: 101.4094 - mean_absolute_error: 101.4094\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 941us/step - loss: 96.1036 - mean_absolute_error: 96.1036\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 950us/step - loss: 88.9324 - mean_absolute_error: 88.9324\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 84.8575 - mean_absolute_error: 84.8575\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 965us/step - loss: 80.8782 - mean_absolute_error: 80.8782\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 904us/step - loss: 77.0872 - mean_absolute_error: 77.0872\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 929us/step - loss: 78.8156 - mean_absolute_error: 78.8156\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 907us/step - loss: 76.2542 - mean_absolute_error: 76.2542\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 900us/step - loss: 77.6051 - mean_absolute_error: 77.6051\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 897us/step - loss: 72.7870 - mean_absolute_error: 72.7870\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 921us/step - loss: 70.6525 - mean_absolute_error: 70.6525\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 69.1758 - mean_absolute_error: 69.1758\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 885us/step - loss: 67.2100 - mean_absolute_error: 67.2100\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 940us/step - loss: 64.3621 - mean_absolute_error: 64.3621\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 829us/step - loss: 66.6238 - mean_absolute_error: 66.6238\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 830us/step - loss: 63.4764 - mean_absolute_error: 63.4764\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 913us/step - loss: 63.8194 - mean_absolute_error: 63.8194\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 64.2525 - mean_absolute_error: 64.2525\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 993us/step - loss: 63.7199 - mean_absolute_error: 63.7199\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 60.3132 - mean_absolute_error: 60.3132\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 938us/step - loss: 59.6019 - mean_absolute_error: 59.6019\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 957us/step - loss: 60.7145 - mean_absolute_error: 60.7145\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 60.4154 - mean_absolute_error: 60.4154\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 974us/step - loss: 58.5760 - mean_absolute_error: 58.5760\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 966us/step - loss: 59.9903 - mean_absolute_error: 59.9903\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 56.6229 - mean_absolute_error: 56.6229\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 928us/step - loss: 58.5367 - mean_absolute_error: 58.5367\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 57.5548 - mean_absolute_error: 57.5548\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 925us/step - loss: 59.5471 - mean_absolute_error: 59.5471\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 880us/step - loss: 56.3511 - mean_absolute_error: 56.3511\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 888us/step - loss: 56.4941 - mean_absolute_error: 56.4941\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 952us/step - loss: 58.0666 - mean_absolute_error: 58.0666\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 817us/step - loss: 56.5987 - mean_absolute_error: 56.5987\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 827us/step - loss: 55.0103 - mean_absolute_error: 55.0103\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 850us/step - loss: 54.8834 - mean_absolute_error: 54.8834\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 943us/step - loss: 55.7921 - mean_absolute_error: 55.7921\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 54.2844 - mean_absolute_error: 54.2844\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 873us/step - loss: 54.5684 - mean_absolute_error: 54.5684\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 885us/step - loss: 51.8752 - mean_absolute_error: 51.8752\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 896us/step - loss: 52.6435 - mean_absolute_error: 52.6435\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 818us/step - loss: 53.9598 - mean_absolute_error: 53.9598\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 811us/step - loss: 52.7247 - mean_absolute_error: 52.7247\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 859us/step - loss: 50.3316 - mean_absolute_error: 50.3316\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 853us/step - loss: 54.3229 - mean_absolute_error: 54.3229\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 848us/step - loss: 52.7772 - mean_absolute_error: 52.7772\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 50.4291 - mean_absolute_error: 50.4291\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 857us/step - loss: 50.2163 - mean_absolute_error: 50.2163\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 813us/step - loss: 48.4366 - mean_absolute_error: 48.4366\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 829us/step - loss: 52.5963 - mean_absolute_error: 52.5963\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model2 = nn2.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42/42 - 0s - loss: 69.8674 - mean_absolute_error: 69.8674\n",
      "Loss: 69.8674087524414\n",
      "Mean Absolute Error: 69.8674087524414\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss2, model_accuracy2 = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss2}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy2}\")"
   ]
  },
  {
   "source": [
    "# Test 3:  Add an additional layer with 20 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 100)               25800     \n_________________________________________________________________\ndense_7 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_8 (Dense)              (None, 20)                1020      \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 21        \n=================================================================\nTotal params: 31,891\nTrainable params: 31,891\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 0s 966us/step - loss: 198.6863 - mean_absolute_error: 198.6863\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 960us/step - loss: 97.0303 - mean_absolute_error: 97.0303\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 938us/step - loss: 91.2810 - mean_absolute_error: 91.2810\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 907us/step - loss: 81.7753 - mean_absolute_error: 81.7753\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 998us/step - loss: 85.8204 - mean_absolute_error: 85.8204\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 81.1161 - mean_absolute_error: 81.1161\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 75.5028 - mean_absolute_error: 75.5028\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 66.8621 - mean_absolute_error: 66.8621\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 922us/step - loss: 65.9590 - mean_absolute_error: 65.9590\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 890us/step - loss: 65.2162 - mean_absolute_error: 65.2162\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 882us/step - loss: 63.2804 - mean_absolute_error: 63.2804\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 959us/step - loss: 65.5619 - mean_absolute_error: 65.5619\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 930us/step - loss: 61.6840 - mean_absolute_error: 61.6840\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 947us/step - loss: 56.0382 - mean_absolute_error: 56.0382\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 890us/step - loss: 58.3518 - mean_absolute_error: 58.3518\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 57.6407 - mean_absolute_error: 57.6407\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 927us/step - loss: 59.1407 - mean_absolute_error: 59.1407\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 915us/step - loss: 55.1591 - mean_absolute_error: 55.1591\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 55.2348 - mean_absolute_error: 55.2348\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 878us/step - loss: 55.2812 - mean_absolute_error: 55.2812\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 924us/step - loss: 55.3699 - mean_absolute_error: 55.3699\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 51.4135 - mean_absolute_error: 51.4135\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 937us/step - loss: 51.9120 - mean_absolute_error: 51.9120\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 53.1368 - mean_absolute_error: 53.1368\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 964us/step - loss: 51.6402 - mean_absolute_error: 51.6402\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 943us/step - loss: 53.2708 - mean_absolute_error: 53.2708\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 940us/step - loss: 50.0774 - mean_absolute_error: 50.0774\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 907us/step - loss: 49.8555 - mean_absolute_error: 49.8555\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 905us/step - loss: 51.8598 - mean_absolute_error: 51.8598\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 980us/step - loss: 48.0806 - mean_absolute_error: 48.0806\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 907us/step - loss: 49.6251 - mean_absolute_error: 49.6251\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 46.6318 - mean_absolute_error: 46.6318\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 907us/step - loss: 45.6095 - mean_absolute_error: 45.6095\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 919us/step - loss: 47.4040 - mean_absolute_error: 47.4040\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 924us/step - loss: 46.3119 - mean_absolute_error: 46.3119\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 919us/step - loss: 43.8079 - mean_absolute_error: 43.8079\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 909us/step - loss: 43.6328 - mean_absolute_error: 43.6328\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 917us/step - loss: 43.1642 - mean_absolute_error: 43.1642\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 949us/step - loss: 45.8814 - mean_absolute_error: 45.8814\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 994us/step - loss: 42.2279 - mean_absolute_error: 42.2279\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 43.6163 - mean_absolute_error: 43.6163\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 923us/step - loss: 39.9431 - mean_absolute_error: 39.9431\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 928us/step - loss: 41.9663 - mean_absolute_error: 41.9663\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 892us/step - loss: 41.8280 - mean_absolute_error: 41.8280\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 898us/step - loss: 42.4073 - mean_absolute_error: 42.4073\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 888us/step - loss: 41.4019 - mean_absolute_error: 41.4019\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 992us/step - loss: 39.2745 - mean_absolute_error: 39.2745\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 921us/step - loss: 40.9052 - mean_absolute_error: 40.9052\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 41.4085 - mean_absolute_error: 41.4085\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 884us/step - loss: 36.4872 - mean_absolute_error: 36.4872\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn3.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model3 = nn3.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42/42 - 0s - loss: 67.0089 - mean_absolute_error: 67.0089\n",
      "Loss: 67.00892639160156\n",
      "Mean Absolute Error: 67.00892639160156\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss3, model_accuracy3 = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss3}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy3}\")"
   ]
  },
  {
   "source": [
    "# Test 4:  Add 50 neurons to the first layer and a 4th layer with 10 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_10 (Dense)             (None, 150)               38700     \n_________________________________________________________________\ndense_11 (Dense)             (None, 50)                7550      \n_________________________________________________________________\ndense_12 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_13 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_14 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 47,491\nTrainable params: 47,491\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 150\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn4.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 208.3267 - mean_absolute_error: 208.3267\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 109.3554 - mean_absolute_error: 109.3554\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 96.7431 - mean_absolute_error: 96.7431\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 88.9567 - mean_absolute_error: 88.9567\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 83.4599 - mean_absolute_error: 83.4599\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 77.5303 - mean_absolute_error: 77.5303\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 77.0707 - mean_absolute_error: 77.0707\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 75.0904 - mean_absolute_error: 75.0904\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 71.0031 - mean_absolute_error: 71.0031\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 67.0049 - mean_absolute_error: 67.0049\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 67.7679 - mean_absolute_error: 67.7679\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 61.6821 - mean_absolute_error: 61.6821\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 64.7676 - mean_absolute_error: 64.7676\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 60.2143 - mean_absolute_error: 60.2143\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 58.8466 - mean_absolute_error: 58.8466\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 58.6912 - mean_absolute_error: 58.6912\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 58.6175 - mean_absolute_error: 58.6175\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 1000us/step - loss: 60.5834 - mean_absolute_error: 60.5834\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 978us/step - loss: 58.8435 - mean_absolute_error: 58.8435\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 56.1994 - mean_absolute_error: 56.1994\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 959us/step - loss: 60.2210 - mean_absolute_error: 60.2210\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 52.5397 - mean_absolute_error: 52.5397\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 52.9802 - mean_absolute_error: 52.9802\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 53.6213 - mean_absolute_error: 53.6213\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 54.7829 - mean_absolute_error: 54.7829\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 992us/step - loss: 54.3403 - mean_absolute_error: 54.3403\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 54.3889 - mean_absolute_error: 54.3889\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 53.8772 - mean_absolute_error: 53.8772\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 51.8500 - mean_absolute_error: 51.8500\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 49.4820 - mean_absolute_error: 49.4820\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 49.9741 - mean_absolute_error: 49.9741\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 51.4146 - mean_absolute_error: 51.4146\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 50.6032 - mean_absolute_error: 50.6032\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 49.1940 - mean_absolute_error: 49.1940\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 47.2113 - mean_absolute_error: 47.2113\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 48.6922 - mean_absolute_error: 48.6922\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 48.2710 - mean_absolute_error: 48.2710\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 45.6688 - mean_absolute_error: 45.6688\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 46.7077 - mean_absolute_error: 46.7077\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 46.2728 - mean_absolute_error: 46.2728\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 989us/step - loss: 45.4610 - mean_absolute_error: 45.4610\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 45.5022 - mean_absolute_error: 45.5022\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 995us/step - loss: 46.3641 - mean_absolute_error: 46.3641\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 42.4311 - mean_absolute_error: 42.4311\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 41.7524 - mean_absolute_error: 41.7524\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 43.3925 - mean_absolute_error: 43.3925\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 40.5574 - mean_absolute_error: 40.5574\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 42.0510 - mean_absolute_error: 42.0510\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 40.0085 - mean_absolute_error: 40.0085\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 41.2250 - mean_absolute_error: 41.2250\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn4.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model4 = nn4.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42/42 - 0s - loss: 66.1691 - mean_absolute_error: 66.1691\n",
      "Loss: 66.16907501220703\n",
      "Mean Absolute Error: 66.16907501220703\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss4, model_accuracy4 = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss4}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy4}\")"
   ]
  },
  {
   "source": [
    "# Test 5:  Add 50 more neurons to the first layer and add a 5th layer with just 5 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_15 (Dense)             (None, 200)               51600     \n_________________________________________________________________\ndense_16 (Dense)             (None, 50)                10050     \n_________________________________________________________________\ndense_17 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_19 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_20 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 62,941\nTrainable params: 62,941\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 200\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 1ms/step - loss: 202.2760 - mean_absolute_error: 202.2760\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 101.9985 - mean_absolute_error: 101.9985\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 92.7089 - mean_absolute_error: 92.7089\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 88.9530 - mean_absolute_error: 88.9530\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 83.2495 - mean_absolute_error: 83.2495\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 77.5519 - mean_absolute_error: 77.5519\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 78.0333 - mean_absolute_error: 78.0333\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 71.2476 - mean_absolute_error: 71.2476\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 67.2287 - mean_absolute_error: 67.2287\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 64.9843 - mean_absolute_error: 64.9843\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 64.2570 - mean_absolute_error: 64.2570\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 63.4359 - mean_absolute_error: 63.4359\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 60.4479 - mean_absolute_error: 60.4479\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 60.4690 - mean_absolute_error: 60.4690\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 62.5241 - mean_absolute_error: 62.5241\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 59.6119 - mean_absolute_error: 59.6119\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 58.8973 - mean_absolute_error: 58.8973\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 55.8046 - mean_absolute_error: 55.8046\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 55.0284 - mean_absolute_error: 55.0284\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 58.5504 - mean_absolute_error: 58.5504\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 55.0400 - mean_absolute_error: 55.0400\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 55.3783 - mean_absolute_error: 55.3783\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 54.1309 - mean_absolute_error: 54.1309\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 56.2433 - mean_absolute_error: 56.2433\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 51.6944 - mean_absolute_error: 51.6944\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 49.9459 - mean_absolute_error: 49.9459\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 49.1887 - mean_absolute_error: 49.1887\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 52.7990 - mean_absolute_error: 52.7990\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 48.7696 - mean_absolute_error: 48.7696\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 47.4773 - mean_absolute_error: 47.4773\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 49.7685 - mean_absolute_error: 49.7685\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 49.6594 - mean_absolute_error: 49.6594\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 46.0460 - mean_absolute_error: 46.0460\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 44.3158 - mean_absolute_error: 44.3158\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 46.7894 - mean_absolute_error: 46.7894\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 45.6585 - mean_absolute_error: 45.6585\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 44.3034 - mean_absolute_error: 44.3034\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 44.6835 - mean_absolute_error: 44.6835\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 41.7332 - mean_absolute_error: 41.7332\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 43.3924 - mean_absolute_error: 43.3924\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 40.2467 - mean_absolute_error: 40.2467\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 41.3507 - mean_absolute_error: 41.3507\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 39.5285 - mean_absolute_error: 39.5285\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 39.9375 - mean_absolute_error: 39.9375\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 37.2389 - mean_absolute_error: 37.2389\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 36.5617 - mean_absolute_error: 36.5617\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 36.5362 - mean_absolute_error: 36.5362\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 34.4198 - mean_absolute_error: 34.4198\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 35.5105 - mean_absolute_error: 35.5105\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 33.3481 - mean_absolute_error: 33.3481\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn5.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model5 = nn5.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42/42 - 0s - loss: 66.7483 - mean_absolute_error: 66.7483\n",
      "Loss: 66.74826049804688\n",
      "Mean Absolute Error: 66.74826049804688\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss5, model_accuracy5 = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss5}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy5}\")"
   ]
  },
  {
   "source": [
    "# Test 6:  Add 150 neurons to first layer and change second activation function to tanh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_21 (Dense)             (None, 350)               90300     \n_________________________________________________________________\ndense_22 (Dense)             (None, 50)                17550     \n_________________________________________________________________\ndense_23 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_24 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_25 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_26 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 109,141\nTrainable params: 109,141\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 350\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 1ms/step - loss: 224.9228 - mean_absolute_error: 224.9228\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 175.9470 - mean_absolute_error: 175.9470\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 130.0872 - mean_absolute_error: 130.0872\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 95.1454 - mean_absolute_error: 95.1454\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 75.5472 - mean_absolute_error: 75.5472\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 72.1703 - mean_absolute_error: 72.1703\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 63.6672 - mean_absolute_error: 63.6672\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 60.8914 - mean_absolute_error: 60.8914\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 53.5323 - mean_absolute_error: 53.5323\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 49.6207 - mean_absolute_error: 49.6207\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 45.8654 - mean_absolute_error: 45.8654\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 38.1128 - mean_absolute_error: 38.1128\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 37.5993 - mean_absolute_error: 37.5993\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 35.7518 - mean_absolute_error: 35.7518\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 30.9034 - mean_absolute_error: 30.9034\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 32.6645 - mean_absolute_error: 32.6645\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 30.5260 - mean_absolute_error: 30.5260\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 27.4494 - mean_absolute_error: 27.4494\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 26.0520 - mean_absolute_error: 26.0520\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 24.5690 - mean_absolute_error: 24.5690\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 24.3758 - mean_absolute_error: 24.3758\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 22.9679 - mean_absolute_error: 22.9679\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 22.4353 - mean_absolute_error: 22.4353\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 22.1578 - mean_absolute_error: 22.1578\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 22.8687 - mean_absolute_error: 22.8687\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 20.0705 - mean_absolute_error: 20.0705\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 19.8306 - mean_absolute_error: 19.8306\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 19.3418 - mean_absolute_error: 19.3418\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 20.6489 - mean_absolute_error: 20.6489\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 18.3135 - mean_absolute_error: 18.3135\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 18.8345 - mean_absolute_error: 18.8345\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 17.3160 - mean_absolute_error: 17.3160\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 18.1918 - mean_absolute_error: 18.1918\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 17.9370 - mean_absolute_error: 17.9370\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 16.5221 - mean_absolute_error: 16.5221\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 17.0926 - mean_absolute_error: 17.0926\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 15.1644 - mean_absolute_error: 15.1644\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 16.0565 - mean_absolute_error: 16.0565\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 16.3792 - mean_absolute_error: 16.3792\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 16.7313 - mean_absolute_error: 16.7313\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 16.9804 - mean_absolute_error: 16.9804\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 14.9123 - mean_absolute_error: 14.9123\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 16.1943 - mean_absolute_error: 16.1943\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 15.6836 - mean_absolute_error: 15.6836\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 15.0651 - mean_absolute_error: 15.0651\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 14.4713 - mean_absolute_error: 14.4713\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 14.8661 - mean_absolute_error: 14.8661\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 13.3311 - mean_absolute_error: 13.3311\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 13.0610 - mean_absolute_error: 13.0610\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 14.6681 - mean_absolute_error: 14.6681\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn6.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model6 = nn6.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42/42 - 0s - loss: 60.6198 - mean_absolute_error: 60.6198\n",
      "Loss: 60.619808197021484\n",
      "Mean Absolute Error: 60.619808197021484\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss6, model_accuracy6 = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss6}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy6}\")"
   ]
  },
  {
   "source": [
    "# After lots of tests, our best Mean Squared Error Result is off, on average, by about $60.5 (according to the MAE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Here we'll do a baseline test on 6 Neural Network model variations on the cleaned data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PostGres Download Duration: 1.829629898071289 seconds\n"
     ]
    }
   ],
   "source": [
    "# Download raw data from postgres for stage 1 ETL\n",
    "\n",
    "conn_string = 'postgres://whnpmxwsiccrtg:53c453893549d2b1e6a4ff92e626a2a08ebcaff66678e50d33e3742f66e3e4f4@ec2-52-4-171-132.compute-1.amazonaws.com/d2ajro4cjr10lb'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "start_time = time.time()\n",
    "df = pd.read_sql_query('select * from \"merged_errors_corrected\"',con=conn)\n",
    "print(\"PostGres Download Duration: {} seconds\".format(time.time() - start_time))\n",
    "conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5553, 266)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   host_listings_count  accommodates  bathrooms  bedrooms  price  \\\n",
       "0                    1             2        1.0         2   40.0   \n",
       "1                    2             2        1.0         1   41.0   \n",
       "2                    2             2        1.0         1   65.0   \n",
       "3                    1             2        1.0         1   93.0   \n",
       "4                    1             2        1.0         1  105.0   \n",
       "\n",
       "   security_deposit  cleaning_fee  number_of_reviews  number_of_reviews_ltm  \\\n",
       "0               0.0           0.0                561                    131   \n",
       "1               0.0          25.0                138                     22   \n",
       "2               0.0          25.0                102                     20   \n",
       "3               0.0           0.0                454                     53   \n",
       "4             200.0           0.0                100                      1   \n",
       "\n",
       "   review_scores_rating  ...  cancellation_policy_flexible  \\\n",
       "0                  99.0  ...                           0.0   \n",
       "1                  94.0  ...                           0.0   \n",
       "2                  96.0  ...                           0.0   \n",
       "3                  97.0  ...                           0.0   \n",
       "4                  99.0  ...                           0.0   \n",
       "\n",
       "   cancellation_policy_moderate  cancellation_policy_strict  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         0.0   \n",
       "3                           1.0                         0.0   \n",
       "4                           0.0                         0.0   \n",
       "\n",
       "   cancellation_policy_strict_14_with_grace_period  \\\n",
       "0                                              1.0   \n",
       "1                                              1.0   \n",
       "2                                              1.0   \n",
       "3                                              0.0   \n",
       "4                                              1.0   \n",
       "\n",
       "   cancellation_policy_super_strict_30  cancellation_policy_super_strict_60  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "\n",
       "   require_guest_profile_picture_t  require_guest_phone_verification_t  \\\n",
       "0                              0.0                                 0.0   \n",
       "1                              1.0                                 1.0   \n",
       "2                              1.0                                 1.0   \n",
       "3                              1.0                                 1.0   \n",
       "4                              1.0                                 1.0   \n",
       "\n",
       "   has_availability_t  outlier  \n",
       "0                 1.0        1  \n",
       "1                 1.0        1  \n",
       "2                 1.0        1  \n",
       "3                 1.0        1  \n",
       "4                 1.0        1  \n",
       "\n",
       "[5 rows x 266 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host_listings_count</th>\n      <th>accommodates</th>\n      <th>bathrooms</th>\n      <th>bedrooms</th>\n      <th>price</th>\n      <th>security_deposit</th>\n      <th>cleaning_fee</th>\n      <th>number_of_reviews</th>\n      <th>number_of_reviews_ltm</th>\n      <th>review_scores_rating</th>\n      <th>...</th>\n      <th>cancellation_policy_flexible</th>\n      <th>cancellation_policy_moderate</th>\n      <th>cancellation_policy_strict</th>\n      <th>cancellation_policy_strict_14_with_grace_period</th>\n      <th>cancellation_policy_super_strict_30</th>\n      <th>cancellation_policy_super_strict_60</th>\n      <th>require_guest_profile_picture_t</th>\n      <th>require_guest_phone_verification_t</th>\n      <th>has_availability_t</th>\n      <th>outlier</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>561</td>\n      <td>131</td>\n      <td>99.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>138</td>\n      <td>22</td>\n      <td>94.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>65.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>102</td>\n      <td>20</td>\n      <td>96.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>93.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>454</td>\n      <td>53</td>\n      <td>97.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>105.0</td>\n      <td>200.0</td>\n      <td>0.0</td>\n      <td>100</td>\n      <td>1</td>\n      <td>99.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 266 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"price\"].values\n",
    "X = df.drop(\"price\",1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'price',\n",
       "       'security_deposit', 'cleaning_fee', 'number_of_reviews',\n",
       "       'number_of_reviews_ltm', 'review_scores_rating',\n",
       "       ...\n",
       "       'cancellation_policy_flexible', 'cancellation_policy_moderate',\n",
       "       'cancellation_policy_strict',\n",
       "       'cancellation_policy_strict_14_with_grace_period',\n",
       "       'cancellation_policy_super_strict_30',\n",
       "       'cancellation_policy_super_strict_60',\n",
       "       'require_guest_profile_picture_t', 'require_guest_phone_verification_t',\n",
       "       'has_availability_t', 'outlier'],\n",
       "      dtype='object', length=266)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = RobustScaler()\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "source": [
    "# Test 1: Use one input layer and one hidden layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 80)                21280     \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                2430      \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 31        \n=================================================================\nTotal params: 23,741\nTrainable params: 23,741\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 1s 932us/step - loss: 199.0205 - mean_absolute_error: 199.0205\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 0s 895us/step - loss: 103.9814 - mean_absolute_error: 103.9814\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 0s 892us/step - loss: 90.9621 - mean_absolute_error: 90.9621\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 0s 905us/step - loss: 88.4032 - mean_absolute_error: 88.4032\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 0s 912us/step - loss: 84.7087 - mean_absolute_error: 84.7087\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 0s 899us/step - loss: 85.4314 - mean_absolute_error: 85.4314\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 0s 954us/step - loss: 84.3872 - mean_absolute_error: 84.3872\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 81.1773 - mean_absolute_error: 81.1773\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 0s 944us/step - loss: 83.6628 - mean_absolute_error: 83.6628\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 0s 848us/step - loss: 74.1566 - mean_absolute_error: 74.1566\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 0s 874us/step - loss: 78.2481 - mean_absolute_error: 78.2481\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 0s 906us/step - loss: 76.9552 - mean_absolute_error: 76.9552\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 0s 869us/step - loss: 74.8989 - mean_absolute_error: 74.8989\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 0s 908us/step - loss: 72.3570 - mean_absolute_error: 72.3570\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 0s 939us/step - loss: 73.1207 - mean_absolute_error: 73.1207\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 71.5393 - mean_absolute_error: 71.5393\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 0s 901us/step - loss: 71.2542 - mean_absolute_error: 71.2542\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 72.3492 - mean_absolute_error: 72.3492\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 0s 948us/step - loss: 69.1157 - mean_absolute_error: 69.1157\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 0s 845us/step - loss: 72.2272 - mean_absolute_error: 72.2272\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 0s 871us/step - loss: 66.6342 - mean_absolute_error: 66.6342\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 0s 868us/step - loss: 67.6239 - mean_absolute_error: 67.6239\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 0s 886us/step - loss: 66.0384 - mean_absolute_error: 66.0384\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 67.0941 - mean_absolute_error: 67.0941\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 0s 919us/step - loss: 67.3788 - mean_absolute_error: 67.3788\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 0s 832us/step - loss: 62.7142 - mean_absolute_error: 62.7142\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 0s 877us/step - loss: 67.5327 - mean_absolute_error: 67.5327\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 0s 867us/step - loss: 64.5323 - mean_absolute_error: 64.5323\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 0s 847us/step - loss: 63.1205 - mean_absolute_error: 63.1205\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 0s 918us/step - loss: 62.8171 - mean_absolute_error: 62.8171\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 0s 900us/step - loss: 61.6797 - mean_absolute_error: 61.6797\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 0s 991us/step - loss: 59.7768 - mean_absolute_error: 59.7768\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 0s 830us/step - loss: 59.8443 - mean_absolute_error: 59.8443\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 0s 820us/step - loss: 63.0892 - mean_absolute_error: 63.0892\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 0s 821us/step - loss: 65.8528 - mean_absolute_error: 65.8528\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 0s 834us/step - loss: 61.3491 - mean_absolute_error: 61.3491\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 0s 836us/step - loss: 60.5538 - mean_absolute_error: 60.5538\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 0s 808us/step - loss: 62.0520 - mean_absolute_error: 62.0520\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 0s 859us/step - loss: 61.7181 - mean_absolute_error: 61.7181\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 0s 797us/step - loss: 62.1507 - mean_absolute_error: 62.1507\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 0s 868us/step - loss: 60.5928 - mean_absolute_error: 60.5928\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 0s 795us/step - loss: 58.6117 - mean_absolute_error: 58.6117\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 0s 785us/step - loss: 59.8634 - mean_absolute_error: 59.8634\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 767us/step - loss: 57.1746 - mean_absolute_error: 57.1746\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 0s 769us/step - loss: 60.7693 - mean_absolute_error: 60.7693\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 0s 753us/step - loss: 57.6615 - mean_absolute_error: 57.6615\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 0s 753us/step - loss: 58.7553 - mean_absolute_error: 58.7553\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 59.1878 - mean_absolute_error: 59.1878\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 0s 819us/step - loss: 58.1847 - mean_absolute_error: 58.1847\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 0s 851us/step - loss: 57.3424 - mean_absolute_error: 57.3424\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "44/44 - 0s - loss: 59.8599 - mean_absolute_error: 59.8599\n",
      "Loss: 59.85993194580078\n",
      "Mean Absolute Error: 59.85993194580078\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "# Test 2.  Add more neurons to each layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 100)               26600     \n_________________________________________________________________\ndense_4 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 31,701\nTrainable params: 31,701\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 0s 887us/step - loss: 193.1178 - mean_absolute_error: 193.1178\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 0s 907us/step - loss: 97.9357 - mean_absolute_error: 97.9357\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 0s 855us/step - loss: 91.1235 - mean_absolute_error: 91.1235\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 0s 957us/step - loss: 87.6060 - mean_absolute_error: 87.6060\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 0s 851us/step - loss: 85.1315 - mean_absolute_error: 85.1315\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 0s 873us/step - loss: 87.9488 - mean_absolute_error: 87.9488\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 0s 844us/step - loss: 79.9202 - mean_absolute_error: 79.9202\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 0s 835us/step - loss: 81.1689 - mean_absolute_error: 81.1689\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 0s 832us/step - loss: 78.0937 - mean_absolute_error: 78.0937\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 0s 869us/step - loss: 74.5286 - mean_absolute_error: 74.5286\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 0s 885us/step - loss: 75.3615 - mean_absolute_error: 75.3615\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 0s 887us/step - loss: 73.9183 - mean_absolute_error: 73.9183\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 0s 971us/step - loss: 73.1427 - mean_absolute_error: 73.1427\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 0s 834us/step - loss: 68.8446 - mean_absolute_error: 68.8446\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 0s 838us/step - loss: 69.6937 - mean_absolute_error: 69.6937\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 0s 884us/step - loss: 66.5610 - mean_absolute_error: 66.5610\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 0s 870us/step - loss: 65.4521 - mean_absolute_error: 65.4521\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 0s 835us/step - loss: 62.2555 - mean_absolute_error: 62.2555\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 0s 814us/step - loss: 64.7421 - mean_absolute_error: 64.7421\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 0s 803us/step - loss: 66.7420 - mean_absolute_error: 66.7420\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 0s 874us/step - loss: 64.8618 - mean_absolute_error: 64.8618\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 0s 806us/step - loss: 66.1829 - mean_absolute_error: 66.1829\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 0s 836us/step - loss: 64.4087 - mean_absolute_error: 64.4087\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 0s 871us/step - loss: 61.2972 - mean_absolute_error: 61.2972\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 0s 803us/step - loss: 60.3732 - mean_absolute_error: 60.3732\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 0s 792us/step - loss: 61.8144 - mean_absolute_error: 61.8144\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 0s 832us/step - loss: 61.6015 - mean_absolute_error: 61.6015\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 0s 875us/step - loss: 62.1431 - mean_absolute_error: 62.1431\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 0s 826us/step - loss: 58.3710 - mean_absolute_error: 58.3710\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 0s 894us/step - loss: 59.8011 - mean_absolute_error: 59.8011\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 0s 806us/step - loss: 57.3324 - mean_absolute_error: 57.3324\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 0s 818us/step - loss: 59.7310 - mean_absolute_error: 59.7310\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 0s 806us/step - loss: 61.3168 - mean_absolute_error: 61.3168\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 0s 814us/step - loss: 59.1290 - mean_absolute_error: 59.1290\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 0s 786us/step - loss: 58.5059 - mean_absolute_error: 58.5059\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 0s 825us/step - loss: 57.0376 - mean_absolute_error: 57.0376\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 0s 847us/step - loss: 56.4533 - mean_absolute_error: 56.4533\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 0s 858us/step - loss: 56.2118 - mean_absolute_error: 56.2118\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 0s 917us/step - loss: 59.2617 - mean_absolute_error: 59.2617\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 0s 846us/step - loss: 55.4271 - mean_absolute_error: 55.4271\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 0s 821us/step - loss: 55.8831 - mean_absolute_error: 55.8831\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 0s 824us/step - loss: 53.6296 - mean_absolute_error: 53.6296\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 0s 792us/step - loss: 55.6128 - mean_absolute_error: 55.6128\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 837us/step - loss: 57.0627 - mean_absolute_error: 57.0627\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 0s 840us/step - loss: 56.8125 - mean_absolute_error: 56.8125\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 0s 827us/step - loss: 57.0721 - mean_absolute_error: 57.0721\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 0s 821us/step - loss: 53.9676 - mean_absolute_error: 53.9676\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 0s 860us/step - loss: 53.5572 - mean_absolute_error: 53.5572\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 0s 805us/step - loss: 52.5778 - mean_absolute_error: 52.5778\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 0s 807us/step - loss: 53.1896 - mean_absolute_error: 53.1896\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model2 = nn2.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "44/44 - 0s - loss: 59.9744 - mean_absolute_error: 59.9744\n",
      "Loss: 59.97441482543945\n",
      "Mean Absolute Error: 59.97441482543945\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss2, model_accuracy2 = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss2}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy2}\")"
   ]
  },
  {
   "source": [
    "# Test 3:  Add an additional layer with 20 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 100)               26600     \n_________________________________________________________________\ndense_7 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_8 (Dense)              (None, 20)                1020      \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 21        \n=================================================================\nTotal params: 32,691\nTrainable params: 32,691\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 185.8083 - mean_absolute_error: 185.8083\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 0s 924us/step - loss: 90.4279 - mean_absolute_error: 90.4279\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 0s 929us/step - loss: 87.3693 - mean_absolute_error: 87.3693\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 0s 899us/step - loss: 84.5110 - mean_absolute_error: 84.5110\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 0s 907us/step - loss: 79.9631 - mean_absolute_error: 79.9631\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 0s 967us/step - loss: 79.7438 - mean_absolute_error: 79.7438\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 0s 928us/step - loss: 78.5081 - mean_absolute_error: 78.5081\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 0s 898us/step - loss: 78.5220 - mean_absolute_error: 78.5220\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 75.4159 - mean_absolute_error: 75.4159\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 0s 895us/step - loss: 69.9679 - mean_absolute_error: 69.9679\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 0s 948us/step - loss: 67.7384 - mean_absolute_error: 67.7384\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 0s 923us/step - loss: 65.9326 - mean_absolute_error: 65.9326\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 0s 915us/step - loss: 64.9039 - mean_absolute_error: 64.9039\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 61.6236 - mean_absolute_error: 61.6236\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 0s 980us/step - loss: 61.3352 - mean_absolute_error: 61.3352\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 0s 907us/step - loss: 63.6856 - mean_absolute_error: 63.6856\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 0s 994us/step - loss: 61.3095 - mean_absolute_error: 61.3095\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 0s 878us/step - loss: 60.2054 - mean_absolute_error: 60.2054\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 0s 873us/step - loss: 59.8614 - mean_absolute_error: 59.8614\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 0s 874us/step - loss: 61.2459 - mean_absolute_error: 61.2459\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 0s 876us/step - loss: 58.7465 - mean_absolute_error: 58.7465\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 0s 894us/step - loss: 60.1471 - mean_absolute_error: 60.1471\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 0s 897us/step - loss: 56.3075 - mean_absolute_error: 56.3075\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 0s 909us/step - loss: 55.7845 - mean_absolute_error: 55.7845\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 56.2219 - mean_absolute_error: 56.2219\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 0s 892us/step - loss: 59.2344 - mean_absolute_error: 59.2344\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 0s 913us/step - loss: 54.0825 - mean_absolute_error: 54.0825\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 0s 947us/step - loss: 54.3031 - mean_absolute_error: 54.3031\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 0s 932us/step - loss: 54.0905 - mean_absolute_error: 54.0905\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 0s 932us/step - loss: 51.9781 - mean_absolute_error: 51.9781\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 51.3903 - mean_absolute_error: 51.3903\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 0s 928us/step - loss: 53.2613 - mean_absolute_error: 53.2613\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 52.3254 - mean_absolute_error: 52.3254\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 0s 999us/step - loss: 51.1547 - mean_absolute_error: 51.1547\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 50.7172 - mean_absolute_error: 50.7172\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 0s 989us/step - loss: 50.8374 - mean_absolute_error: 50.8374\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 0s 957us/step - loss: 49.9984 - mean_absolute_error: 49.9984\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 48.6836 - mean_absolute_error: 48.6836\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 48.1245 - mean_absolute_error: 48.1245\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 50.2396 - mean_absolute_error: 50.2396\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 47.3870 - mean_absolute_error: 47.3870\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 0s 987us/step - loss: 47.7439 - mean_absolute_error: 47.7439\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 48.5189 - mean_absolute_error: 48.5189\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 995us/step - loss: 43.9039 - mean_absolute_error: 43.9039\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 47.8400 - mean_absolute_error: 47.8400\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 0s 981us/step - loss: 44.0436 - mean_absolute_error: 44.0436\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 0s 989us/step - loss: 44.2406 - mean_absolute_error: 44.2406\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 41.8234 - mean_absolute_error: 41.8234\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 0s 960us/step - loss: 43.0664 - mean_absolute_error: 43.0664\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 0s 976us/step - loss: 41.1219 - mean_absolute_error: 41.1219\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn3.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model3 = nn3.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "44/44 - 0s - loss: 60.7458 - mean_absolute_error: 60.7458\n",
      "Loss: 60.74576950073242\n",
      "Mean Absolute Error: 60.74576950073242\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss3, model_accuracy3 = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss3}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy3}\")"
   ]
  },
  {
   "source": [
    "# Test 4:  Add 50 neurons to the first layer and a 4th layer with 10 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_10 (Dense)             (None, 150)               39900     \n_________________________________________________________________\ndense_11 (Dense)             (None, 50)                7550      \n_________________________________________________________________\ndense_12 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_13 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_14 (Dense)             (None, 1)                 11        \n=================================================================\nTotal params: 48,691\nTrainable params: 48,691\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 150\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn4.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 183.3469 - mean_absolute_error: 183.3469\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 94.4479 - mean_absolute_error: 94.4479\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 0s 995us/step - loss: 85.9662 - mean_absolute_error: 85.9662\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 83.1787 - mean_absolute_error: 83.1787\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 79.2486 - mean_absolute_error: 79.2486\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 0s 995us/step - loss: 80.6275 - mean_absolute_error: 80.6275\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 71.9787 - mean_absolute_error: 71.9787\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 68.4172 - mean_absolute_error: 68.4172\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 68.9822 - mean_absolute_error: 68.9822\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 67.1857 - mean_absolute_error: 67.1857\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 0s 992us/step - loss: 63.3672 - mean_absolute_error: 63.3672\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 64.3339 - mean_absolute_error: 64.3339\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 63.0569 - mean_absolute_error: 63.0569\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 60.9106 - mean_absolute_error: 60.9106\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 60.3061 - mean_absolute_error: 60.3061\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 57.1847 - mean_absolute_error: 57.1847\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 0s 946us/step - loss: 56.8781 - mean_absolute_error: 56.8781\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 0s 989us/step - loss: 61.3738 - mean_absolute_error: 61.3738\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 0s 961us/step - loss: 56.4191 - mean_absolute_error: 56.4191\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 54.5357 - mean_absolute_error: 54.5357\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 58.2731 - mean_absolute_error: 58.2731\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 51.7325 - mean_absolute_error: 51.7325\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 0s 987us/step - loss: 51.2518 - mean_absolute_error: 51.2518\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 0s 957us/step - loss: 53.5940 - mean_absolute_error: 53.5940\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 0s 946us/step - loss: 52.4320 - mean_absolute_error: 52.4320\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 0s 936us/step - loss: 50.5624 - mean_absolute_error: 50.5624\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 0s 947us/step - loss: 48.4649 - mean_absolute_error: 48.4649\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 0s 959us/step - loss: 47.0135 - mean_absolute_error: 47.0135\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 0s 972us/step - loss: 47.3286 - mean_absolute_error: 47.3286\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 47.8689 - mean_absolute_error: 47.8689\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 0s 950us/step - loss: 44.8003 - mean_absolute_error: 44.8003\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 0s 972us/step - loss: 47.2758 - mean_absolute_error: 47.2758\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 0s 952us/step - loss: 43.6010 - mean_absolute_error: 43.6010\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 0s 934us/step - loss: 42.1836 - mean_absolute_error: 42.1836\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 0s 982us/step - loss: 43.6723 - mean_absolute_error: 43.6723\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 0s 965us/step - loss: 39.7083 - mean_absolute_error: 39.7083\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 40.8696 - mean_absolute_error: 40.8696\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 40.6166 - mean_absolute_error: 40.6166\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 0s 976us/step - loss: 39.5252 - mean_absolute_error: 39.5252\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 0s 976us/step - loss: 39.4936 - mean_absolute_error: 39.4936\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 0s 955us/step - loss: 38.7412 - mean_absolute_error: 38.7412\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 0s 953us/step - loss: 39.9358 - mean_absolute_error: 39.9358\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 0s 953us/step - loss: 37.4214 - mean_absolute_error: 37.4214\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 958us/step - loss: 37.8400 - mean_absolute_error: 37.8400\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 37.1780 - mean_absolute_error: 37.1780\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 0s 959us/step - loss: 35.0632 - mean_absolute_error: 35.0632\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 0s 948us/step - loss: 33.8319 - mean_absolute_error: 33.8319\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 0s 967us/step - loss: 34.9251 - mean_absolute_error: 34.9251\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 0s 942us/step - loss: 31.2789 - mean_absolute_error: 31.2789\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 0s 936us/step - loss: 34.0295 - mean_absolute_error: 34.0295\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn4.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model4 = nn4.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "44/44 - 0s - loss: 59.3186 - mean_absolute_error: 59.3186\n",
      "Loss: 59.31858444213867\n",
      "Mean Absolute Error: 59.31858444213867\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss4, model_accuracy4 = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss4}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy4}\")"
   ]
  },
  {
   "source": [
    "# Test 5:  Add 50 more neurons to the first layer and add a 5th layer with just 5 neurons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_15 (Dense)             (None, 200)               53200     \n_________________________________________________________________\ndense_16 (Dense)             (None, 50)                10050     \n_________________________________________________________________\ndense_17 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_19 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_20 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 64,541\nTrainable params: 64,541\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 200\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 1s 1ms/step - loss: 194.5036 - mean_absolute_error: 194.5036\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 99.8136 - mean_absolute_error: 99.8136\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 84.2598 - mean_absolute_error: 84.2598\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 83.1546 - mean_absolute_error: 83.1546\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 88.0070 - mean_absolute_error: 88.0070\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 77.3374 - mean_absolute_error: 77.3374\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 80.1431 - mean_absolute_error: 80.1431\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 79.1153 - mean_absolute_error: 79.1153\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 78.1005 - mean_absolute_error: 78.1005\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 71.5721 - mean_absolute_error: 71.5721\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 67.3567 - mean_absolute_error: 67.3567\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 68.1176 - mean_absolute_error: 68.1176\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 62.8073 - mean_absolute_error: 62.8073\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 65.0843 - mean_absolute_error: 65.0843\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 67.3587 - mean_absolute_error: 67.3587\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 63.6205 - mean_absolute_error: 63.6205\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 63.8206 - mean_absolute_error: 63.8206\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 60.9998 - mean_absolute_error: 60.9998\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 63.3229 - mean_absolute_error: 63.3229\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 60.4122 - mean_absolute_error: 60.4122\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 60.6562 - mean_absolute_error: 60.6562\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 59.5825 - mean_absolute_error: 59.5825\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 58.3204 - mean_absolute_error: 58.3204\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 60.9412 - mean_absolute_error: 60.9412\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 60.5698 - mean_absolute_error: 60.5698\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 54.9187 - mean_absolute_error: 54.9187\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 57.4137 - mean_absolute_error: 57.4137\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 54.8591 - mean_absolute_error: 54.8591\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 56.6513 - mean_absolute_error: 56.6513\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 53.6278 - mean_absolute_error: 53.6278\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 57.0322 - mean_absolute_error: 57.0322\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 51.7955 - mean_absolute_error: 51.7955\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 53.3860 - mean_absolute_error: 53.3860\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 54.2155 - mean_absolute_error: 54.2155\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 52.9962 - mean_absolute_error: 52.9962\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 52.1750 - mean_absolute_error: 52.1750\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 52.2041 - mean_absolute_error: 52.2041\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 49.1580 - mean_absolute_error: 49.1580\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 50.0395 - mean_absolute_error: 50.0395\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 47.9145 - mean_absolute_error: 47.9145\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 47.6288 - mean_absolute_error: 47.6288\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 45.8110 - mean_absolute_error: 45.8110\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 46.2104 - mean_absolute_error: 46.2104\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 48.3138 - mean_absolute_error: 48.3138\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 45.5276 - mean_absolute_error: 45.5276\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 48.0204 - mean_absolute_error: 48.0204\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 45.5147 - mean_absolute_error: 45.5147\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 45.5619 - mean_absolute_error: 45.5619\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 49.2142 - mean_absolute_error: 49.2142\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 44.1880 - mean_absolute_error: 44.1880\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn5.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model5 = nn5.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "44/44 - 0s - loss: 59.7014 - mean_absolute_error: 59.7014\n",
      "Loss: 59.70137023925781\n",
      "Mean Absolute Error: 59.70137023925781\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss5, model_accuracy5 = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss5}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy5}\")"
   ]
  },
  {
   "source": [
    "# Test 6:  Add 150 neurons to first layer and change second activation function to tanh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_21 (Dense)             (None, 350)               93100     \n_________________________________________________________________\ndense_22 (Dense)             (None, 50)                17550     \n_________________________________________________________________\ndense_23 (Dense)             (None, 20)                1020      \n_________________________________________________________________\ndense_24 (Dense)             (None, 10)                210       \n_________________________________________________________________\ndense_25 (Dense)             (None, 5)                 55        \n_________________________________________________________________\ndense_26 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 111,941\nTrainable params: 111,941\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_in_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 350\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 20\n",
    "hidden_nodes_layer4 = 10\n",
    "hidden_nodes_layer5 = 5\n",
    "\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,kernel_initializer='normal', input_dim=number_in_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,kernel_initializer='normal', activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer4,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer5,kernel_initializer='normal', activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 1s 1ms/step - loss: 223.9949 - mean_absolute_error: 223.9949\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 184.5464 - mean_absolute_error: 184.5464\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 113.1100 - mean_absolute_error: 113.1100\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 83.5332 - mean_absolute_error: 83.5332\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 83.2537 - mean_absolute_error: 83.2537\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 75.6553 - mean_absolute_error: 75.6553\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 74.4633 - mean_absolute_error: 74.4633\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 69.3041 - mean_absolute_error: 69.3041\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 63.4732 - mean_absolute_error: 63.4732\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 58.8139 - mean_absolute_error: 58.8139\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 55.6727 - mean_absolute_error: 55.6727\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 50.0096 - mean_absolute_error: 50.0096\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 47.3235 - mean_absolute_error: 47.3235\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 44.3409 - mean_absolute_error: 44.3409\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 41.4194 - mean_absolute_error: 41.4194\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 39.4603 - mean_absolute_error: 39.4603\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 35.1193 - mean_absolute_error: 35.1193\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 35.6200 - mean_absolute_error: 35.6200\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 31.2799 - mean_absolute_error: 31.2799\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 29.4876 - mean_absolute_error: 29.4876\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 28.9148 - mean_absolute_error: 28.9148\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 28.4093 - mean_absolute_error: 28.4093\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 27.8752 - mean_absolute_error: 27.8752\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 23.7853 - mean_absolute_error: 23.7853\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 26.6195 - mean_absolute_error: 26.6195\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 25.3799 - mean_absolute_error: 25.3799\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 23.8621 - mean_absolute_error: 23.8621\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 22.2881 - mean_absolute_error: 22.2881\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 21.8973 - mean_absolute_error: 21.8973\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 23.4138 - mean_absolute_error: 23.4138\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 18.9464 - mean_absolute_error: 18.9464\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 20.5842 - mean_absolute_error: 20.5842\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 20.0527 - mean_absolute_error: 20.0527\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 18.5914 - mean_absolute_error: 18.5914\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 18.7399 - mean_absolute_error: 18.7399\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 19.7698 - mean_absolute_error: 19.7698\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 21.4174 - mean_absolute_error: 21.4174\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 18.3291 - mean_absolute_error: 18.3291\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 17.3450 - mean_absolute_error: 17.3450\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 17.2052 - mean_absolute_error: 17.2052\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 16.8274 - mean_absolute_error: 16.8274\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 16.5535 - mean_absolute_error: 16.5535\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 18.2986 - mean_absolute_error: 18.2986\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 17.8875 - mean_absolute_error: 17.8875\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 16.0833 - mean_absolute_error: 16.0833\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 16.1833 - mean_absolute_error: 16.1833\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 16.2556 - mean_absolute_error: 16.2556\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 15.8676 - mean_absolute_error: 15.8676\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 16.9789 - mean_absolute_error: 16.9789\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 14.5868 - mean_absolute_error: 14.5868\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn6.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "fit_model6 = nn6.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "44/44 - 0s - loss: 54.5875 - mean_absolute_error: 54.5875\n",
      "Loss: 54.58751678466797\n",
      "Mean Absolute Error: 54.58751678466797\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss6, model_accuracy6 = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss6}\")\n",
    "print(f\"Mean Absolute Error: {model_accuracy6}\")"
   ]
  },
  {
   "source": [
    "# After lots of tests, our best Mean Squared Error Result is off, on average, by about $54.59 (according to the MAE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
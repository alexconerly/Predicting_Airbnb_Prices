{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PostGres Download Duration: 1.018995761871338 seconds\n"
     ]
    }
   ],
   "source": [
    "# Download raw data from postgres for stage 1 ETL\n",
    "\n",
    "conn_string = 'postgres://whnpmxwsiccrtg:53c453893549d2b1e6a4ff92e626a2a08ebcaff66678e50d33e3742f66e3e4f4@ec2-52-4-171-132.compute-1.amazonaws.com/d2ajro4cjr10lb'\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "start_time = time.time()\n",
    "clean_listing = pd.read_sql_query('select * from \"clean_listing_remove_somereviews\"',con=conn)\n",
    "amenities = pd.read_sql_query('select * from \"amenities_bucketed\"',con=conn)\n",
    "print(\"PostGres Download Duration: {} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated variables.\n",
    "listing = clean_listing.drop(columns = ['last_scraped', 'host_since', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge amenities table to full listings.\n",
    "merged = listing.merge(amenities, how='left', on ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tables and drop 'id' (unique identifier - not relevant)\n",
    "merged = merged.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = merged.dtypes[merged.dtypes == 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False, drop='if_binary')\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(merged[objects]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "merged = merged.merge(encode_df,left_index=True, right_index=True)\n",
    "merged = merged.drop(columns=objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set erroneous 30 bedroom listings for apartments to 1\n",
    "merged.loc[merged['bedrooms'] > 29, 'bedrooms'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert zero bedrooms with more than 4 accommodates to 2 bedrooms\n",
    "merged.loc[(merged['bedrooms'] == 0) & (merged['accommodates'] > 4), 'bedrooms'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert zero bedrooms with more than 4 accommodates to 1 bedroom\n",
    "merged.loc[(merged['bedrooms'] == 0) & (merged['accommodates'] < 5), 'bedrooms'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5899, 266)"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "from scipy import stats\n",
    "merged['accommodates_logs'] = np.log(merged['accommodates'])\n",
    "merged = merged[(np.abs(stats.zscore(merged['accommodates_logs'])) < 2)]\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5831, 267)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "merged.loc[merged.bathrooms == 0, 'bathrooms'] = .001\n",
    "merged['baths_logs'] = np.log(merged['bathrooms'])\n",
    "merged = merged[(np.abs(stats.zscore(merged['baths_logs'])) < 2)]\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop(columns=['baths_logs', 'accommodates_logs'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5831, 265)"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    5831.000000\n",
       "mean       83.447608\n",
       "std        33.504199\n",
       "min         0.000000\n",
       "25%        93.000000\n",
       "50%        98.000000\n",
       "75%        99.000000\n",
       "max       100.000000\n",
       "Name: review_scores_rating, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "merged['review_scores_rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'price',\n",
       "       'security_deposit', 'cleaning_fee', 'number_of_reviews',\n",
       "       'number_of_reviews_ltm', 'review_scores_rating',\n",
       "       ...\n",
       "       'is_business_travel_ready_f', 'cancellation_policy_flexible',\n",
       "       'cancellation_policy_moderate', 'cancellation_policy_strict',\n",
       "       'cancellation_policy_strict_14_with_grace_period',\n",
       "       'cancellation_policy_super_strict_30',\n",
       "       'cancellation_policy_super_strict_60',\n",
       "       'require_guest_profile_picture_t', 'require_guest_phone_verification_t',\n",
       "       'has_availability_t'],\n",
       "      dtype='object', length=265)"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5831, 265)\n"
     ]
    }
   ],
   "source": [
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[(np.abs(stats.zscore(merged['host_listings_count'])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5531, 265)\n"
     ]
    }
   ],
   "source": [
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "host_listings_count_logs\n",
      "(5522, 266)\n",
      "accommodates_logs\n",
      "(5522, 267)\n",
      "bathrooms_logs\n",
      "(5522, 268)\n",
      "bedrooms_logs\n",
      "(5514, 269)\n",
      "price_logs\n",
      "(5468, 270)\n",
      "security_deposit_logs\n",
      "(5468, 271)\n",
      "cleaning_fee_logs\n",
      "(5468, 272)\n",
      "number_of_reviews_logs\n",
      "(5468, 273)\n",
      "number_of_reviews_ltm_logs\n",
      "(5468, 274)\n",
      "review_scores_rating_logs\n",
      "(5468, 275)\n",
      "review_scores_accuracy_logs\n",
      "(5468, 276)\n",
      "guests_included_logs\n",
      "(5468, 277)\n",
      "availability_30_logs\n",
      "(5468, 278)\n",
      "availability_60_logs\n",
      "(5468, 279)\n",
      "availability_90_logs\n",
      "(5468, 280)\n",
      "availability_365_logs\n",
      "(5468, 281)\n",
      "reviews_per_month_logs\n",
      "(5468, 282)\n",
      "days_host_logs\n",
      "(5377, 283)\n"
     ]
    }
   ],
   "source": [
    "# For loop to delete any rows with outliers in any row (3 SD) \n",
    "from scipy import stats\n",
    "log_column_list = []\n",
    "\n",
    "for column in merged.columns:\n",
    "    log_col_name = column + \"_logs\"\n",
    "    # Ignore columns with max less than or equal to 1 (binary)\n",
    "    if merged[column].max() > 1:\n",
    "        # natural log transform (+1 to handle 0 values)\n",
    "        merged[log_col_name] = np.log(merged[column]+1)\n",
    "        merged = merged[(np.abs(stats.zscore(merged[log_col_name])) < 3)]\n",
    "        log_column_list.append(log_col_name)\n",
    "        print(log_col_name)\n",
    "        print(merged.shape)\n",
    "\n",
    "merged.drop(columns=log_column_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5377, 265)\n"
     ]
    }
   ],
   "source": [
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop additional outliers using IsolationForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "X = merged.drop(columns=['price']).values\n",
    "iso = IsolationForest(contamination='auto')\n",
    "yhat = iso.fit_predict(X)\n",
    "merged['outlier'] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5377, 266)\n"
     ]
    }
   ],
   "source": [
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete any rows with outliers in any row (3 SD) using calculated field log(price/accommodates)\n",
    "merged = merged[(np.abs(stats.zscore(np.log(merged['price']/merged['accommodates']))) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5331, 266)\n"
     ]
    }
   ],
   "source": [
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged.drop(columns=['price']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[merged['outlier']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5277, 266)\n"
     ]
    }
   ],
   "source": [
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop(columns=['outlier'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PostGres Upload Duration: 135.25171089172363 seconds\n"
     ]
    }
   ],
   "source": [
    "# Upload Merged dataset with errors corrected to PostGres\n",
    "start_time = time.time()\n",
    "merged.to_sql('merged_errors_corrected', con=conn, if_exists='replace', index=False)\n",
    "print(\"PostGres Upload Duration: {} seconds\".format(time.time() - start_time))\n",
    "conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}